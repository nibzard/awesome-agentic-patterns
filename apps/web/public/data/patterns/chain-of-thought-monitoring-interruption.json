{
  "title": "Chain-of-Thought Monitoring & Interruption",
  "status": "emerging",
  "authors": ["Nikola Balic (@nibzard)"],
  "based_on": ["Tanner Jones (Vulcan)"],
  "category": "UX & Collaboration",
  "source": "https://claude.com/blog/building-companies-with-claude-code",
  "tags": ["monitoring", "intervention", "debugging", "reasoning", "ux"],
  "slug": "chain-of-thought-monitoring-interruption",
  "id": "chain-of-thought-monitoring-interruption",
  "summary": "Implement active surveillance of agent reasoning with capability to interrupt and redirect before completing flawed execution sequences, preventing wasted time on fundamentally wrong approaches.",
  "updated_at": "2026-01-05",
  "body": "\n## Problem\n\nAI agents can pursue misguided reasoning paths for extended periods before producing final outputs. By the time developers realize the approach is wrong, significant time and tokens have been wasted on a fundamentally flawed direction. Traditional \"fire and forget\" agent execution provides no opportunity for early course correction.\n\n## Solution\n\nImplement active surveillance of the agent's intermediate reasoning steps with the capability to interrupt and redirect before completing full execution sequences. Monitor chain-of-thought outputs, tool calls, and intermediate results in real-time, maintaining a \"finger on the trigger\" to catch wrong directions early.\n\n**Key mechanisms:**\n\n**Real-time reasoning visibility:**\n\n- Expose agent's thinking process as it unfolds\n- Display tool use decisions and intermediate results\n- Show planning steps before code execution\n\n**Low-friction interruption:**\n\n- Enable quick halt capability (keyboard shortcuts, UI controls)\n- Preserve partial work when interrupting\n- Allow mid-execution context injection\n\n**Early detection signals:**\n\n- Wrong file selections\n- Flawed assumptions in initial tool calls\n- Misunderstanding of requirements evident in first reasoning steps\n\n```mermaid\nsequenceDiagram\n    participant Dev as Developer\n    participant Agent as AI Agent\n    participant Tools as Tool Execution\n\n    Agent->>Dev: Display reasoning: \"I'll modify auth.ts...\"\n    Agent->>Tools: Start file read\n    Dev->>Agent: INTERRUPT! (Wrong file)\n    Dev->>Agent: \"Use oauth.ts instead\"\n    Agent->>Tools: Read oauth.ts\n    Agent->>Dev: Display updated reasoning\n    Note over Dev,Agent: Correction caught within<br/>first tool call\n```\n\n## How to use it\n\n**When to apply:**\n\n- Complex refactoring where wrong file choices are costly\n- Tasks requiring deep codebase understanding\n- High-stakes operations (database migrations, API changes)\n- When agent might misinterpret ambiguous requirements\n- Development workflows where iteration speed matters\n\n**Implementation approaches:**\n\n**UI-level implementation:**\n\n- Show streaming agent reasoning in real-time\n- Provide prominent interrupt/stop controls\n- Display tool use before execution when possible\n- Allow inline corrections without restarting\n\n**CLI-level implementation:**\n\n- Stream verbose output showing reasoning\n- Ctrl+C to interrupt with context preservation\n- Ability to redirect with additional context\n- Resume capability after corrections\n\n**Best practices:**\n\n1. **Monitor first tool calls closely** - First actions reveal understanding\n2. **Watch for assumption declarations** - \"Based on X, I'll do Y\" statements\n3. **Interrupt early** - Don't wait for completion of flawed sequences\n4. **Provide specific corrections** - Help agent understand what went wrong\n5. **Use clarifying questions** - Sometimes better to pause and clarify than redirect\n\n## Trade-offs\n\n**Pros:**\n\n- Prevents wasted time on fundamentally wrong approaches\n- Maximizes value from expensive model calls\n- Enables collaborative human-AI problem solving\n- Reduces frustration from watching preventable mistakes\n- Catches misunderstandings within initial tool calls\n\n**Cons:**\n\n- Requires active human attention (not fully autonomous)\n- Can interrupt productive exploration if triggered prematurely\n- May create dependency on human oversight for routine tasks\n- Adds cognitive load to monitor agent reasoning\n- Risk of over-correcting and preventing valid creative approaches\n\n## References\n\n- [Building Companies with Claude Code](https://claude.com/blog/building-companies-with-claude-code) - Tanner Jones (Vulcan) advises: \"Have your finger on the trigger to escape and interrupt any bad behavior.\"\n- Related patterns: [Spectrum of Control / Blended Initiative](spectrum-of-control.md), [Verbose Reasoning Transparency](verbose-reasoning-transparency.md)\n"
}
