{
  "title": "Graph of Thoughts (GoT)",
  "status": "emerging",
  "authors": [
    "Nikola Balic (@nibzard)"
  ],
  "based_on": [
    "Besta et al.",
    "ETH Zurich"
  ],
  "category": "Feedback Loops",
  "source": "https://arxiv.org/abs/2308.09687",
  "tags": [
    "reasoning",
    "graph-based",
    "problem-solving",
    "thought-exploration",
    "backtracking",
    "aggregation"
  ],
  "slug": "graph-of-thoughts",
  "id": "graph-of-thoughts-got",
  "summary": "Extend reasoning frameworks by representing thoughts as a directed graph with nodes, edges, and arbitrary relationships, enabling complex operations like branching, aggregation, refinement, and looping for problems with interdependencies.",
  "updated_at": "2026-01-05",
  "body": "\n## Problem\n\nLinear reasoning approaches like Chain-of-Thought (CoT) and even tree-based methods like Tree-of-Thoughts (ToT) have limitations when dealing with problems that require complex interdependencies between reasoning steps. Many real-world problems involve reasoning paths that merge, split, and recombine in ways that don't fit neatly into linear or tree structures. These problems need a more flexible approach that can represent arbitrary relationships between thoughts.\n\n## Solution\n\nGraph of Thoughts (GoT) extends reasoning frameworks by representing the thought process as a directed graph where:\n\n- **Nodes** represent individual thoughts or reasoning states\n- **Edges** represent transformations or reasoning steps between thoughts\n- **Multiple paths** can lead to and from each node\n- **Aggregation operations** can combine multiple thoughts\n- **Backtracking** allows revisiting and refining previous thoughts\n\nThis enables operations like:\n1. **Branching**: Generate multiple thoughts from one\n2. **Aggregation**: Combine insights from multiple reasoning paths\n3. **Refinement**: Improve thoughts based on later insights\n4. **Looping**: Revisit and refine thoughts iteratively\n\n## Example\n\n```python\nclass GraphOfThoughts:\n    def __init__(self, llm, max_thoughts=50):\n        self.llm = llm\n        self.max_thoughts = max_thoughts\n        self.thought_graph = nx.DiGraph()\n        self.thought_scores = {}\n        \n    def solve(self, problem):\n        # Initialize with root thought\n        root = self.generate_initial_thought(problem)\n        self.add_thought(root, score=1.0)\n        \n        # Iteratively expand the graph\n        while len(self.thought_graph) < self.max_thoughts:\n            # Select promising thoughts to expand\n            thoughts_to_expand = self.select_thoughts_for_expansion()\n            \n            for thought in thoughts_to_expand:\n                # Generate new thoughts through different operations\n                self.branch_thought(thought, problem)\n                self.aggregate_related_thoughts(thought)\n                self.refine_thought(thought, problem)\n        \n        # Find best solution path through the graph\n        return self.extract_best_solution()\n    \n    def branch_thought(self, thought, problem):\n        \"\"\"Generate multiple new thoughts from current thought\"\"\"\n        prompt = f\"\"\"\n        Problem: {problem}\n        Current thought: {thought.content}\n        \n        Generate 2-3 different ways to continue or branch this reasoning:\n        \"\"\"\n        branches = self.llm.generate(prompt).split('\\n')\n        \n        for branch in branches:\n            new_thought = Thought(branch)\n            self.add_thought(new_thought)\n            self.add_edge(thought, new_thought, operation='branch')\n    \n    def aggregate_related_thoughts(self, thought):\n        \"\"\"Combine insights from multiple related thoughts\"\"\"\n        # Find thoughts that could be meaningfully combined\n        related = self.find_related_thoughts(thought)\n        \n        if len(related) >= 2:\n            prompt = f\"\"\"\n            Combine insights from these thoughts:\n            {[t.content for t in related]}\n            \n            Create a unified thought that incorporates the best of each:\n            \"\"\"\n            aggregated = self.llm.generate(prompt)\n            new_thought = Thought(aggregated)\n            self.add_thought(new_thought)\n            \n            # Add edges from all source thoughts\n            for source in related:\n                self.add_edge(source, new_thought, operation='aggregate')\n    \n    def refine_thought(self, thought, problem):\n        \"\"\"Improve a thought based on graph context\"\"\"\n        # Get neighboring thoughts for context\n        context = self.get_thought_context(thought)\n        \n        prompt = f\"\"\"\n        Problem: {problem}\n        Current thought: {thought.content}\n        Related context: {context}\n        \n        Refine this thought to be more accurate/useful:\n        \"\"\"\n        refined = self.llm.generate(prompt)\n        \n        if self.is_improvement(refined, thought.content):\n            new_thought = Thought(refined)\n            self.add_thought(new_thought)\n            self.add_edge(thought, new_thought, operation='refine')\n    \n    def evaluate_thought(self, thought, problem):\n        \"\"\"Score a thought's quality and relevance\"\"\"\n        prompt = f\"\"\"\n        Problem: {problem}\n        Thought: {thought.content}\n        \n        Rate this thought on:\n        1. Relevance to problem (0-1)\n        2. Logical correctness (0-1)\n        3. Novelty/insight (0-1)\n        4. Progress toward solution (0-1)\n        \n        Overall score (0-1):\n        \"\"\"\n        evaluation = self.llm.generate(prompt)\n        return self.parse_score(evaluation)\n    \n    def extract_best_solution(self):\n        \"\"\"Find the highest-scoring path through the graph\"\"\"\n        # Use graph algorithms to find optimal path\n        terminal_thoughts = [n for n in self.thought_graph.nodes() \n                           if self.thought_graph.out_degree(n) == 0]\n        \n        best_path = None\n        best_score = -1\n        \n        for terminal in terminal_thoughts:\n            paths = nx.all_simple_paths(\n                self.thought_graph, \n                source=self.get_root(), \n                target=terminal\n            )\n            for path in paths:\n                score = self.score_path(path)\n                if score > best_score:\n                    best_score = score\n                    best_path = path\n        \n        return self.format_solution(best_path)\n```\n\n```mermaid\ngraph TD\n    A[Initial Problem] --> B[Thought 1]\n    A --> C[Thought 2]\n    \n    B --> D[Thought 3]\n    B --> E[Thought 4]\n    C --> F[Thought 5]\n    C --> G[Thought 6]\n    \n    D --> H[Refined Thought 3]\n    E --> I[Thought 7]\n    F --> I\n    \n    I --> J[Aggregated Insight]\n    G --> J\n    H --> J\n    \n    J --> K[Final Solution]\n    \n    style A fill:#ffebee,stroke:#d32f2f,stroke-width:2px\n    style J fill:#e8f5e9,stroke:#388e3c,stroke-width:2px\n    style K fill:#e3f2fd,stroke:#1976d2,stroke-width:2px\n```\n\n## Benefits\n\n- **Flexibility**: Can represent complex, non-linear reasoning patterns\n- **Reusability**: Thoughts can be referenced and built upon multiple times\n- **Robustness**: Multiple paths to solution increase success probability\n- **Insight Aggregation**: Combines best aspects of different reasoning paths\n\n## Trade-offs\n\n**Pros:**\n- Handles complex problems with interdependent reasoning steps\n- Can discover non-obvious connections between ideas\n- Supports iterative refinement and backtracking\n- More expressive than linear or tree-based approaches\n\n**Cons:**\n- Significantly higher computational cost\n- Complex to implement and debug\n- May generate many redundant thoughts\n- Requires sophisticated scoring and path-finding algorithms\n- Can be overkill for simple problems\n\n## References\n\n- [Graph of Thoughts: Solving Elaborate Problems with Large Language Models (AAAI 2024)](https://arxiv.org/abs/2308.09687)\n- [Presentation at AAAI '24 Vancouver](https://aaai.org/aaai-conference/)\n- [Code Implementation](https://github.com/spcl/graph-of-thoughts)\n"
}