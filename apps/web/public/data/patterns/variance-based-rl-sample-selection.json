{
  "title": "Variance-Based RL Sample Selection",
  "status": "emerging",
  "authors": ["Nikola Balic (@nibzard)"],
  "based_on": ["Theo (OpenAI Solutions Architect)", "Prashant (OpenAI RFT Team)"],
  "category": "Learning & Adaptation",
  "source": "https://youtu.be/1s_7RMG4O4U",
  "tags": ["reinforcement-learning", "sample-efficiency", "variance", "data-quality", "agent-rft"],
  "slug": "variance-based-rl-sample-selection",
  "id": "variance-based-rl-sample-selection",
  "summary": "TODO: Add a concise summary for \"Variance-Based RL Sample Selection\" describing the pattern's purpose and key benefits.",
  "updated_at": "2026-01-05",
  "body": "\n## Problem\n\nNot all training samples are equally valuable for reinforcement learning:\n\n- **Zero-variance samples**: Model gets same score every time (always correct or always wrong) → no learning signal\n- **Wasted compute**: Training on samples where the model has no uncertainty wastes expensive RL exploration\n- **Poor data utilization**: With limited training budgets, you want to maximize learning from each sample\n- **Unclear training potential**: Hard to know if your dataset will support effective RL training\n\nWhen Theo ran baseline evaluations on the FinQA benchmark, he discovered that ~85% of samples had zero variance (model always got them right or always wrong), meaning only ~15% of samples could actually contribute to learning.\n\n## Solution\n\n**Run multiple baseline evaluations per sample to identify variance, then prioritize high-variance samples for training.**\n\n**The Variance Plot Methodology:**\n\n1. **Baseline Evaluation**: Run your base model 3-5 times on each sample\n2. **Visualize Variance**: Plot results to identify which samples have variance\n3. **Categorize Samples**:\n   \n- **Always correct** (variance = 0): Model already knows this\n   - **Always incorrect** (variance = 0): Model can't learn this (too hard or needs different approach)\n   - **Sometimes correct** (variance > 0): **Prime candidates for RL**\n4. **Focus Training**: Prioritize or exclusively use high-variance samples\n\n**Understanding the Variance Plot:**\n\n```\nScore\n1.0 ●━━━━━━━●━━━━━━●━━━━━━━●    ← Always correct (no learning)\n    ┃       ┃      ┃       ┃\n0.5 ┃   ●━━━●━━━●  ┃   ●━━━●━━━●    ← High variance (learn here!)\n    ┃   ┃   ▼       ┃   ┃\n0.0 ●━━━●━━━━━━●━━━●━━━━━━●━━━━━━●    ← Always wrong (no learning)\n    └───┴───┴───┴───┴───┴───┴───→\n        Sample Index\n\n    ● = Best score (red cross in plots)\n    ━ = Mean score (thick blue bar)\n    ▼ = Variance range (thin blue bar)\n```\n\n**Implementation:**\n\n```python\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom collections import defaultdict\n\nclass VarianceAnalyzer:\n    \"\"\"\n    Analyze baseline variance to identify high-value training samples\n    \"\"\"\n    def __init__(self, agent, dataset, n_runs=3):\n        self.agent = agent\n        self.dataset = dataset\n        self.n_runs = n_runs\n        self.results = defaultdict(list)\n\n    def run_baseline_evals(self):\n        \"\"\"\n        Run agent multiple times on each sample\n        \"\"\"\n        print(f\"Running {self.n_runs} evaluations per sample...\")\n\n        for sample_idx, sample in enumerate(self.dataset):\n            for run_idx in range(self.n_runs):\n                score = self.agent.evaluate(sample)\n                self.results[sample_idx].append(score)\n\n            if sample_idx % 10 == 0:\n                print(f\"Completed {sample_idx}/{len(self.dataset)} samples\")\n\n        return self.results\n\n    def compute_variance_metrics(self):\n        \"\"\"\n        Calculate variance statistics for each sample\n        \"\"\"\n        metrics = []\n\n        for sample_idx in sorted(self.results.keys()):\n            scores = self.results[sample_idx]\n\n            metrics.append({\n                'sample_idx': sample_idx,\n                'mean_score': np.mean(scores),\n                'best_score': np.max(scores),\n                'worst_score': np.min(scores),\n                'variance': np.var(scores),\n                'std_dev': np.std(scores),\n                'scores': scores\n            })\n\n        return metrics\n\n    def plot_variance(self, metrics, title=\"Baseline Variance Analysis\"):\n        \"\"\"\n        Create variance visualization (like Theo's plots)\n        \"\"\"\n        sample_indices = [m['sample_idx'] for m in metrics]\n        mean_scores = [m['mean_score'] for m in metrics]\n        best_scores = [m['best_score'] for m in metrics]\n        std_devs = [m['std_dev'] for m in metrics]\n\n        plt.figure(figsize=(14, 6))\n\n        # Plot mean scores with error bars (variance)\n        plt.errorbar(\n            sample_indices,\n            mean_scores,\n            yerr=std_devs,\n            fmt='o',\n            linewidth=2,\n            markersize=3,\n            label='Mean ± Std Dev',\n            color='cornflowerblue',\n            elinewidth=1\n        )\n\n        # Overlay best scores\n        plt.scatter(\n            sample_indices,\n            best_scores,\n            marker='x',\n            s=50,\n            color='red',\n            label='Best Score',\n            alpha=0.7\n        )\n\n        plt.xlabel('Sample Index')\n        plt.ylabel('Score')\n        plt.title(title)\n        plt.legend()\n        plt.grid(True, alpha=0.3)\n        plt.tight_layout()\n\n        return plt\n\n    def identify_high_variance_samples(self, metrics, variance_threshold=0.01):\n        \"\"\"\n        Filter samples with meaningful variance\n        \"\"\"\n        high_variance = [\n            m for m in metrics\n            if m['variance'] > variance_threshold\n            and 0 < m['mean_score'] < 1.0  # Not always right or wrong\n        ]\n\n        print(f\"\\nVariance Analysis:\")\n        print(f\"  Total samples: {len(metrics)}\")\n        print(f\"  High variance samples: {len(high_variance)} \"\n              f\"({100*len(high_variance)/len(metrics):.1f}%)\")\n        print(f\"  Always correct: {sum(1 for m in metrics if m['best_score'] == 1.0 and m['variance'] == 0)}\")\n        print(f\"  Always incorrect: {sum(1 for m in metrics if m['best_score'] == 0.0)}\")\n\n        return high_variance\n\n    def compute_improvement_potential(self, metrics):\n        \"\"\"\n        Calculate how much performance could improve if model\n        always achieves best-of-N performance\n        \"\"\"\n        current_avg = np.mean([m['mean_score'] for m in metrics])\n        best_of_n_avg = np.mean([m['best_score'] for m in metrics])\n\n        potential_gain = best_of_n_avg - current_avg\n\n        print(f\"\\nImprovement Potential:\")\n        print(f\"  Current average: {current_avg:.3f}\")\n        print(f\"  Best-of-{self.n_runs} average: {best_of_n_avg:.3f}\")\n        print(f\"  Potential gain: {potential_gain:.3f} \"\n              f\"({100*potential_gain/current_avg:.1f}% relative improvement)\")\n\n        return {\n            'current': current_avg,\n            'best_of_n': best_of_n_avg,\n            'potential_gain': potential_gain\n        }\n\n\n# Usage example\nanalyzer = VarianceAnalyzer(\n    agent=my_agent,\n    dataset=validation_set,\n    n_runs=3\n)\n\n# Run baseline evaluations\nresults = analyzer.run_baseline_evals()\n\n# Analyze variance\nmetrics = analyzer.compute_variance_metrics()\n\n# Visualize\nanalyzer.plot_variance(metrics)\n\n# Identify high-value samples\nhigh_var_samples = analyzer.identify_high_variance_samples(metrics)\n\n# Calculate improvement potential\npotential = analyzer.compute_improvement_potential(metrics)\n\n# Use high-variance samples for training\ntraining_data = [\n    dataset[m['sample_idx']]\n    for m in high_var_samples\n]\n```\n\n## How to use it\n\n**Step 1: Baseline Evaluation (Before Training)**\n\nRun your base model 3-5 times on each sample in your training and validation sets:\n\n```python\n# Run multiple times per sample\nfor sample in dataset:\n    for run in range(3):\n        score = agent.evaluate(sample)\n        record_score(sample.id, score)\n```\n\n**Step 2: Create Variance Plot**\n\nVisualize to understand your data:\n\n- **X-axis**: Sample index\n- **Y-axis**: Score (0-1)\n- **Red crosses**: Best score achieved across runs\n- **Blue bars**: Mean score (thick) and variance (thin)\n\n**Step 3: Interpret Results**\n\nGood indicators for RL:\n\n- **15-30% high variance samples**: Enough learning opportunities\n- **Best-of-N >> Mean**: Model has potential to improve with RL\n- **Variance distributed across dataset**: Not concentrated in few samples\n\nWarning signs:\n\n- **<10% high variance**: Dataset may be too easy or too hard\n- **Best-of-N ≈ Mean**: Model is very consistent (low improvement potential)\n- **All variance in tail**: Most samples don't offer learning signal\n\n**Step 4: Set Compute Multiplier**\n\nThe compute multiplier controls exploration during training:\n\n- **Low variance (10-15%)**: Use compute multiplier 2-4 for more exploration\n- **Medium variance (15-30%)**: Use compute multiplier 1-2\n- **High variance (>30%)**: Compute multiplier 1 may suffice\n\n**Step 5: Monitor During Training**\n\nTrack how variance evolves:\n\n- Early training: Variance should decrease as model learns\n- Plateau: Variance may increase as model explores new strategies\n- Convergence: Variance should stabilize at lower level\n\n## Real-World Example: FinQA Benchmark\n\n**Task**: Answer financial questions using tool-based search (not given context)\n\n**Baseline Analysis:**\n\n- Dataset: 100 validation samples, 1000 training samples\n- Runs per sample: 3\n- Base model: GPT-4o\n\n**Results:**\n\n```\nVariance Analysis:\n  Total samples: 100\n  High variance samples: 15 (15%)\n  Always correct: 40 samples\n  Always incorrect: 45 samples\n\nImprovement Potential:\n  Current average: 0.59\n  Best-of-3 average: 0.73\n  Potential gain: +0.14 (24% relative improvement)\n```\n\n**Interpretation:**\n\n- Only 15% of samples had variance → training will focus learning on those\n- 24% potential improvement if model learns to consistently hit best-of-3 performance\n- Good candidate for RL despite low variance percentage (quality over quantity)\n\n**Training Results:**\n\nAfter 10 steps of agent RFT:\n\n- Validation reward: 0.59 → 0.63 (+7%)\n- Tool calls per rollout: 6.9 → 4.2 (-39%)\n- Latency: ~10% reduction\n\nThe model improved toward the best-of-3 ceiling while also becoming more efficient.\n\n## Trade-offs\n\n**Pros:**\n\n- **Data efficiency**: Focus training on samples that actually contribute to learning\n- **Predictive**: Estimate improvement potential before expensive training\n- **Diagnostic**: Understand if your task is suitable for RL\n- **Guides hyperparameters**: Informs compute multiplier and training duration decisions\n\n**Cons:**\n\n- **Upfront cost**: Requires 3-5x baseline evaluations before training\n- **Small samples**: With few samples (<50), variance estimates may be noisy\n- **Doesn't guarantee success**: High variance is necessary but not sufficient\n- **Dynamic variance**: Variance changes during training, so initial analysis may not hold\n\n## References\n\n- [OpenAI Build Hour: Agent RFT - Variance Analysis Demo (November 2025)](https://youtu.be/1s_7RMG4O4U)\n- [Prior RFT Build Hour with Prashant](https://www.youtube.com/openai-build-hours)\n- Related patterns: Agent Reinforcement Fine-Tuning, Inference-Time Scaling\n"
}
