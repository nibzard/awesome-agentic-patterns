[
  {
    "title": "Reflection Loop",
    "status": "established",
    "authors": [
      "Nikola Balic (@nibzard)"
    ],
    "based_on": [
      "Shinn et al. (2023)"
    ],
    "category": "Feedback Loops",
    "source": "https://arxiv.org/abs/2303.11366",
    "tags": [
      "self-feedback",
      "iterative-improvement",
      "evaluation"
    ],
    "id": "reflection-loop",
    "slug": "reflection",
    "updated_at": "2026-01-05",
    "excerpt": "\n## Problem\nGenerative models may produce subpar output if they never review or critique their own work."
  },
  {
    "title": "Continuous Autonomous Task Loop Pattern",
    "status": "established",
    "authors": [
      "Nikola Balic (@nibzard)"
    ],
    "based_on": [
      "Internal Practice"
    ],
    "category": "Orchestration & Control",
    "source": "https://gist.github.com/nibzard/a97ef0a1919328bcbc6a224a5d2cfc78",
    "tags": [
      "autonomous-execution",
      "task-loop",
      "rate-limiting",
      "git-automation",
      "cli-driven",
      "stream-processing"
    ],
    "id": "continuous-autonomous-task-loop-pattern",
    "slug": "continuous-autonomous-task-loop-pattern",
    "updated_at": "2026-01-05",
    "excerpt": "\n## Problem"
  },
  {
    "title": "Tool Use Incentivization via Reward Shaping",
    "status": "emerging",
    "authors": [
      "Nikola Balic (@nibzard)"
    ],
    "based_on": [
      "Will Brown (Prime Intellect Talk)"
    ],
    "category": "Feedback Loops",
    "source": "https://www.youtube.com/watch?v=Xkwok_XXQgw",
    "tags": [
      "tool-use",
      "reward-shaping",
      "coding-agent",
      "RL"
    ],
    "id": "tool-use-incentivization-via-reward-shaping",
    "slug": "tool-use-incentivization-via-reward-shaping",
    "updated_at": "2026-01-05",
    "excerpt": "\n## Problem"
  },
  {
    "title": "Asynchronous Coding Agent Pipeline",
    "status": "proposed",
    "authors": [
      "Nikola Balic (@nibzard)"
    ],
    "based_on": [
      "Will Brown (Prime Intellect Talk)"
    ],
    "category": "Reliability & Eval",
    "source": "https://www.youtube.com/watch?v=Xkwok_XXQgw",
    "tags": [
      "asynchronous",
      "pipeline",
      "code-agent",
      "parallelism"
    ],
    "id": "asynchronous-coding-agent-pipeline",
    "slug": "asynchronous-coding-agent-pipeline",
    "updated_at": "2026-01-05",
    "excerpt": "\n## Problem"
  },
  {
    "title": "Agent-Friendly Workflow Design",
    "status": "best-practice",
    "authors": [
      "Nikola Balic (@nibzard)"
    ],
    "based_on": [
      "Amjad Masad"
    ],
    "category": "UX & Collaboration",
    "source": "https://www.nibzard.com/silent-revolution",
    "tags": [
      "human-agent collaboration",
      "workflow design",
      "agent autonomy",
      "task decomposition",
      "HCI"
    ],
    "id": "agent-friendly-workflow-design",
    "slug": "agent-friendly-workflow-design",
    "updated_at": "2026-01-05",
    "excerpt": "\n## Problem\nSimply providing an AI agent with a task is often not enough for optimal performance. If workflows are too rigid, or if humans micromanage the agent's technical decisions, the agent may st"
  },
  {
    "title": "Isolated VM per RL Rollout",
    "status": "emerging",
    "authors": [
      "Nikola Balic (@nibzard)"
    ],
    "based_on": [
      "Sam Pretty (Cognition)",
      "Devon Engineering Team"
    ],
    "category": "Security & Safety",
    "source": "https://youtu.be/1s_7RMG4O4U",
    "tags": [
      "isolation",
      "security",
      "reinforcement-learning",
      "infrastructure",
      "state-management",
      "agent-rft"
    ],
    "id": "isolated-vm-per-rl-rollout",
    "slug": "isolated-vm-per-rl-rollout",
    "updated_at": "2026-01-05",
    "excerpt": "\n## Problem"
  },
  {
    "title": "No-Token-Limit Magic",
    "status": "experimental-but-awesome",
    "authors": [
      "Nikola Balic (@nibzard)"
    ],
    "based_on": [
      "Thorsten Ball",
      "Quinn Slack"
    ],
    "category": "Reliability & Eval",
    "source": "https://www.nibzard.com/ampcode",
    "tags": [
      "performance",
      "cost",
      "experimentation"
    ],
    "id": "no-token-limit-magic",
    "slug": "no-token-limit-magic",
    "updated_at": "2026-01-05",
    "excerpt": "\n## Problem\nAggressive prompt compression to save tokens stifles reasoning depth and self-correction."
  },
  {
    "title": "Human-in-the-Loop Approval Framework",
    "status": "validated-in-production",
    "authors": [
      "Nikola Balic (@nibzard)"
    ],
    "based_on": [
      "Dexter Horthy (HumanLayer)"
    ],
    "category": "UX & Collaboration",
    "source": "https://claude.com/blog/building-companies-with-claude-code",
    "tags": [
      "human-oversight",
      "safety",
      "approvals",
      "risk-management",
      "collaboration",
      "slack-integration"
    ],
    "id": "human-in-the-loop-approval-framework",
    "slug": "human-in-loop-approval-framework",
    "updated_at": "2026-01-05",
    "excerpt": "\n## Problem"
  },
  {
    "title": "Stop Hook Auto-Continue Pattern",
    "status": "emerging",
    "authors": [
      "Nikola Balic (@nibzard)"
    ],
    "based_on": [
      "Boris Cherny (Anthropic)",
      "Claude Code Users"
    ],
    "category": "Orchestration & Control",
    "source": "https://every.to/podcast/transcript-how-to-use-claude-code-like-the-people-who-built-it",
    "tags": [
      "hooks",
      "automation",
      "testing",
      "determinism",
      "success-criteria",
      "continuous-execution"
    ],
    "id": "stop-hook-auto-continue-pattern",
    "slug": "stop-hook-auto-continue-pattern",
    "updated_at": "2026-01-05",
    "excerpt": "\n## Problem"
  },
  {
    "title": "Structured Output Specification",
    "status": "established",
    "authors": [
      "Nikola Balic (@nibzard)"
    ],
    "based_on": [
      "Vercel AI Team"
    ],
    "category": "Reliability & Eval",
    "source": "https://vercel.com/blog/what-we-learned-building-agents-at-vercel",
    "tags": [
      "structured-output",
      "schema",
      "validation",
      "reliability",
      "type-safety",
      "integration"
    ],
    "id": "structured-output-specification",
    "slug": "structured-output-specification",
    "updated_at": "2026-01-05",
    "excerpt": "\n## Problem"
  },
  {
    "title": "Shell Command Contextualization",
    "status": "established",
    "authors": [
      "Nikola Balic (@nibzard)"
    ],
    "based_on": [
      "Boris Cherny (via Claude Code)"
    ],
    "category": "Tool Use & Environment",
    "source": "https://www.nibzard.com/claude-code",
    "tags": [
      "shell integration",
      "context management",
      "local execution",
      "bash",
      "cli",
      "interactive tools"
    ],
    "id": "shell-command-contextualization",
    "slug": "shell-command-contextualization",
    "updated_at": "2026-01-05",
    "excerpt": "\n## Problem\nWhen an AI agent interacts with a local development environment, it often needs to execute shell commands (e.g., run linters, check git status, list files) and then use the output of these"
  },
  {
    "title": "Context-Minimization Pattern",
    "status": "emerging",
    "authors": [
      "Nikola Balic (@nibzard)"
    ],
    "based_on": [
      "Luca Beurer-Kellner et al. (2025)"
    ],
    "category": "Context & Memory",
    "source": "https://arxiv.org/abs/2506.08837",
    "tags": [
      "context-hygiene",
      "taint-removal",
      "prompt-injection"
    ],
    "id": "context-minimization-pattern",
    "slug": "context-minimization-pattern",
    "updated_at": "2026-01-05",
    "excerpt": "\n## Problem\nUser-supplied or tainted text lingers in the conversation, enabling it to influence later generations."
  },
  {
    "title": "Code Mode MCP Tool Interface Improvement Pattern",
    "status": "established",
    "authors": [
      "Nikola Balic (@nibzard)"
    ],
    "based_on": [
      "Cloudflare Team"
    ],
    "category": "Tool Use & Environment",
    "source": "https://blog.cloudflare.com/code-mode/",
    "tags": [
      "tool-interface",
      "code-generation",
      "sandboxing",
      "mcp",
      "mcp-improvement",
      "typescript",
      "v8-isolates",
      "token-optimization"
    ],
    "id": "code-mode-mcp-tool-interface-improvement-pattern",
    "slug": "code-first-tool-interface-pattern",
    "updated_at": "2026-01-05",
    "excerpt": "\n## Problem"
  },
  {
    "title": "Filesystem-Based Agent State",
    "status": "established",
    "authors": [
      "Nikola Balic (@nibzard)"
    ],
    "based_on": [
      "Anthropic Engineering Team"
    ],
    "category": "Context & Memory",
    "source": "https://www.anthropic.com/engineering/code-execution-with-mcp",
    "tags": [
      "state-management",
      "persistence",
      "resumption",
      "long-running-tasks"
    ],
    "id": "filesystem-based-agent-state",
    "slug": "filesystem-based-agent-state",
    "updated_at": "2026-01-05",
    "excerpt": "\n## Problem"
  },
  {
    "title": "Anti-Reward-Hacking Grader Design",
    "status": "emerging",
    "authors": [
      "Nikola Balic (@nibzard)"
    ],
    "based_on": [
      "Rogo Engineering Team",
      "Will Brown (OpenAI)"
    ],
    "category": "Reliability & Eval",
    "source": "https://youtu.be/1s_7RMG4O4U",
    "tags": [
      "reward-hacking",
      "grading",
      "reinforcement-learning",
      "adversarial-robustness",
      "agent-rft"
    ],
    "id": "anti-reward-hacking-grader-design",
    "slug": "anti-reward-hacking-grader-design",
    "updated_at": "2026-01-05",
    "excerpt": "\n## Problem"
  },
  {
    "title": "Team-Shared Agent Configuration as Code",
    "status": "best-practice",
    "authors": [
      "Nikola Balic (@nibzard)"
    ],
    "based_on": [
      "Boris Cherny (Anthropic)",
      "Enterprise Claude Code Users"
    ],
    "category": "UX & Collaboration",
    "source": "https://every.to/podcast/transcript-how-to-use-claude-code-like-the-people-who-built-it",
    "tags": [
      "configuration",
      "version-control",
      "team-collaboration",
      "permissions",
      "consistency",
      "onboarding"
    ],
    "id": "team-shared-agent-configuration-as-code",
    "slug": "team-shared-agent-configuration",
    "updated_at": "2026-01-05",
    "excerpt": "\n## Problem"
  },
  {
    "title": "Self-Critique Evaluator Loop",
    "status": "emerging",
    "authors": [
      "Nikola Balic (@nibzard)"
    ],
    "based_on": [
      "Meta AI (Self-Taught Evaluators)"
    ],
    "category": "Feedback Loops",
    "source": "https://arxiv.org/abs/2408.02666",
    "tags": [
      "self-critique",
      "evaluator",
      "reward-model",
      "synthetic-data"
    ],
    "id": "self-critique-evaluator-loop",
    "slug": "self-critique-evaluator-loop",
    "updated_at": "2026-01-05",
    "excerpt": "\n## Problem\nHuman preference labels are costly and quickly become outdated as base models improve."
  },
  {
    "title": "CLI-Native Agent Orchestration",
    "status": "proposed",
    "authors": [
      "Nikola Balic (@nibzard)"
    ],
    "based_on": [
      "Jory Pestorious"
    ],
    "category": "Tool Use & Environment",
    "source": "http://jorypestorious.com/blog/ai-engineer-spec/",
    "tags": [
      "cli",
      "automation",
      "local-dev",
      "headless"
    ],
    "id": "cli-native-agent-orchestration",
    "slug": "cli-native-agent-orchestration",
    "updated_at": "2026-01-05",
    "excerpt": "\n## Problem\nWeb chat UIs are awkward for repeat runs, local file edits, or scripting inside CI pipelines."
  },
  {
    "title": "Democratization of Tooling via Agents",
    "status": "emerging",
    "authors": [
      "Nikola Balic (@nibzard)"
    ],
    "based_on": [
      "Jacob Jackson (Cursor)",
      "Alex Albert (Anthropic)"
    ],
    "category": "UX & Collaboration",
    "source": "https://www.youtube.com/watch?v=BGgsoIgbT_Y",
    "tags": [
      "no-code",
      "low-code",
      "citizen-developer",
      "tool-creation",
      "business-users",
      "automation",
      "custom-software"
    ],
    "id": "democratization-of-tooling-via-agents",
    "slug": "democratization-of-tooling-via-agents",
    "updated_at": "2026-01-05",
    "excerpt": "\n## Problem\nMany individuals in non-software engineering roles (e.g., sales, marketing, operations, communications) could benefit from custom software tools, scripts, or dashboards tailored to their s"
  },
  {
    "title": "Chain-of-Thought Monitoring & Interruption",
    "status": "emerging",
    "authors": [
      "Nikola Balic (@nibzard)"
    ],
    "based_on": [
      "Tanner Jones (Vulcan)"
    ],
    "category": "UX & Collaboration",
    "source": "https://claude.com/blog/building-companies-with-claude-code",
    "tags": [
      "monitoring",
      "intervention",
      "debugging",
      "reasoning",
      "ux"
    ],
    "id": "chain-of-thought-monitoring-interruption",
    "slug": "chain-of-thought-monitoring-interruption",
    "updated_at": "2026-01-05",
    "excerpt": "\n## Problem"
  },
  {
    "title": "Swarm Migration Pattern",
    "status": "validated-in-production",
    "authors": [
      "Nikola Balic (@nibzard)"
    ],
    "based_on": [
      "Boris Cherny (Anthropic)",
      "Anthropic Internal Users"
    ],
    "category": "Orchestration & Control",
    "source": "https://every.to/podcast/transcript-how-to-use-claude-code-like-the-people-who-built-it",
    "tags": [
      "swarm",
      "map-reduce",
      "migration",
      "parallelization",
      "sub-agents",
      "scalability",
      "framework-migration"
    ],
    "id": "swarm-migration-pattern",
    "slug": "swarm-migration-pattern",
    "updated_at": "2026-01-05",
    "excerpt": "\n## Problem"
  },
  {
    "title": "Code-Then-Execute Pattern",
    "status": "emerging",
    "authors": [
      "Nikola Balic (@nibzard)"
    ],
    "based_on": [
      "DeepMind CaMeL (orig.)",
      "Luca Beurer-Kellner et al. (2025)"
    ],
    "category": "Tool Use & Environment",
    "source": "https://arxiv.org/abs/2506.08837",
    "tags": [
      "dsl",
      "sandbox",
      "program-synthesis",
      "auditability"
    ],
    "id": "code-then-execute-pattern",
    "slug": "code-then-execute-pattern",
    "updated_at": "2026-01-05",
    "excerpt": "\n## Problem\nPlan lists are opaque; we want **full data-flow analysis** and taint tracking."
  },
  {
    "title": "Skill Library Evolution",
    "status": "established",
    "authors": [
      "Nikola Balic (@nibzard)"
    ],
    "based_on": [
      "Anthropic Engineering Team",
      "Will Larson (Imprint)",
      "Amp (Nicolay)"
    ],
    "category": "Learning & Adaptation",
    "source": "https://www.anthropic.com/engineering/code-execution-with-mcp",
    "tags": [
      "code-reuse",
      "skills",
      "learning",
      "capabilities",
      "evolution",
      "progressive-disclosure",
      "on-demand-loading",
      "mcp",
      "lazy-loading"
    ],
    "id": "skill-library-evolution",
    "slug": "skill-library-evolution",
    "updated_at": "2026-01-13",
    "excerpt": "\n## Problem"
  },
  {
    "title": "LLM Map-Reduce Pattern",
    "status": "emerging",
    "authors": [
      "Nikola Balic (@nibzard)"
    ],
    "based_on": [
      "Luca Beurer-Kellner et al. (2025)"
    ],
    "category": "Orchestration & Control",
    "source": "https://arxiv.org/abs/2506.08837",
    "tags": [
      "map-reduce",
      "sub-agents",
      "isolation",
      "untrusted-data"
    ],
    "id": "llm-map-reduce-pattern",
    "slug": "llm-map-reduce-pattern",
    "updated_at": "2026-01-05",
    "excerpt": "\n## Problem\nInjecting a single poisoned document can manipulate global reasoning if all data is processed in one context."
  },
  {
    "title": "Graph of Thoughts (GoT)",
    "status": "emerging",
    "authors": [
      "Nikola Balic (@nibzard)"
    ],
    "based_on": [
      "Besta et al.",
      "ETH Zurich"
    ],
    "category": "Feedback Loops",
    "source": "https://arxiv.org/abs/2308.09687",
    "tags": [
      "reasoning",
      "graph-based",
      "problem-solving",
      "thought-exploration",
      "backtracking",
      "aggregation"
    ],
    "id": "graph-of-thoughts-got",
    "slug": "graph-of-thoughts",
    "updated_at": "2026-01-05",
    "excerpt": "\n## Problem"
  },
  {
    "title": "Context Window Anxiety Management",
    "status": "emerging",
    "authors": [
      "Nikola Balic (@nibzard)"
    ],
    "based_on": [
      "Cognition AI (2025)"
    ],
    "category": "Context & Memory",
    "source": "https://cognition.ai/blog/devin-sonnet-4-5-lessons-and-challenges",
    "tags": [
      "context-anxiety",
      "token-management",
      "premature-completion",
      "model-behavior"
    ],
    "id": "context-window-anxiety-management",
    "slug": "context-window-anxiety-management",
    "updated_at": "2026-01-05",
    "excerpt": "\n## Problem\nModels like Claude Sonnet 4.5 exhibit \"context anxiety\"—they become aware of approaching context window limits and proactively summarize progress or make decisive moves to close tasks, eve"
  },
  {
    "title": "Multi-Platform Webhook Triggers",
    "status": "emerging",
    "authors": [
      "Nikola Balic (@nibzard)"
    ],
    "based_on": [
      "Will Larson (lethain.com)"
    ],
    "category": "Tool Use & Environment",
    "source": "https://lethain.com/agents-triggers/",
    "tags": [
      "webhooks",
      "triggers",
      "integrations",
      "slack",
      "notion",
      "jira",
      "scheduled-events",
      "event-driven"
    ],
    "id": "multi-platform-webhook-triggers",
    "slug": "multi-platform-webhook-triggers",
    "updated_at": "2026-01-13",
    "excerpt": "\n## Problem"
  },
  {
    "title": "Tree-of-Thought Reasoning",
    "status": "established",
    "authors": [
      "Nikola Balic (@nibzard)"
    ],
    "based_on": [
      "Yao et al. (2023)"
    ],
    "category": "Orchestration & Control",
    "source": "https://arxiv.org/abs/2305.10601",
    "tags": [
      "branching",
      "deliberate-reasoning",
      "search"
    ],
    "id": "tree-of-thought-reasoning",
    "slug": "tree-of-thought-reasoning",
    "updated_at": "2026-01-05",
    "excerpt": "\n## Problem\nLinear chain-of-thought reasoning can get stuck on complex problems, missing alternative approaches or failing to backtrack."
  },
  {
    "title": "Specification-Driven Agent Development",
    "status": "proposed",
    "authors": [
      "Nikola Balic (@nibzard)"
    ],
    "based_on": [
      "Jory Pestorious (AI Engineer World's Fair 2025)"
    ],
    "category": "Orchestration & Control",
    "source": "http://jorypestorious.com/blog/ai-engineer-spec/",
    "tags": [
      "spec-first",
      "scaffolding",
      "contract",
      "requirements"
    ],
    "id": "specification-driven-agent-development",
    "slug": "specification-driven-agent-development",
    "updated_at": "2026-01-05",
    "excerpt": "\n## Problem\nHand-crafted prompts or loose user stories leave room for ambiguity; agents can wander, over-interpret, or produce code that conflicts with stakeholder intent."
  },
  {
    "title": "Proactive Agent State Externalization",
    "status": "emerging",
    "authors": [
      "Nikola Balic (@nibzard)"
    ],
    "based_on": [
      "Cognition AI (2025)"
    ],
    "category": "Context & Memory",
    "source": "https://cognition.ai/blog/devin-sonnet-4-5-lessons-and-challenges",
    "tags": [
      "state-externalization",
      "memory-management",
      "self-documentation",
      "note-taking"
    ],
    "id": "proactive-agent-state-externalization",
    "slug": "proactive-agent-state-externalization",
    "updated_at": "2026-01-05",
    "excerpt": "\n## Problem\nModern models like Claude Sonnet 4.5 proactively attempt to externalize their state by writing summaries and notes (e.g., `CHANGELOG.md`, `SUMMARY.md`) to the file system without explicit "
  },
  {
    "title": "Initializer-Maintainer Dual Agent Architecture",
    "status": "emerging",
    "authors": [
      "Nikola Balic (@nibzard)"
    ],
    "based_on": [
      "Anthropic Engineering Team"
    ],
    "category": "Orchestration & Control",
    "source": "https://www.anthropic.com/engineering/effective-harnesses-for-long-running-agents",
    "tags": [
      "long-running-agents",
      "session-handoff",
      "lifecycle-specialization",
      "project-bootstrap",
      "incremental-development"
    ],
    "id": "initializer-maintainer-dual-agent-architecture",
    "slug": "initializer-maintainer-dual-agent",
    "updated_at": "2026-01-05",
    "excerpt": "\n## Problem"
  },
  {
    "title": "Spec-As-Test Feedback Loop",
    "status": "proposed",
    "authors": [
      "Nikola Balic (@nibzard)"
    ],
    "based_on": [
      "Jory Pestorious"
    ],
    "category": "Feedback Loops",
    "source": "http://jorypestorious.com/blog/ai-engineer-spec/",
    "tags": [
      "validation",
      "drift-detection",
      "continuous-testing"
    ],
    "id": "spec-as-test-feedback-loop",
    "slug": "spec-as-test-feedback-loop",
    "updated_at": "2026-01-05",
    "excerpt": "\n## Problem\nEven in spec-first projects, implementations can drift as code evolves and the spec changes (or vice-versa). Silent divergence erodes trust."
  },
  {
    "title": "PII Tokenization",
    "status": "established",
    "authors": [
      "Nikola Balic (@nibzard)"
    ],
    "based_on": [
      "Anthropic Engineering Team"
    ],
    "category": "Security & Safety",
    "source": "https://www.anthropic.com/engineering/code-execution-with-mcp",
    "tags": [
      "privacy",
      "pii",
      "security",
      "mcp",
      "data-protection"
    ],
    "id": "pii-tokenization",
    "slug": "pii-tokenization",
    "updated_at": "2026-01-05",
    "excerpt": "\n## Problem"
  },
  {
    "title": "Oracle and Worker Multi-Model Approach",
    "status": "emerging",
    "authors": [
      "Nikola Balic (@nibzard)"
    ],
    "based_on": [
      "Sourcegraph Team"
    ],
    "category": "Orchestration & Control",
    "source": "https://youtu.be/hAEmt-FMyHA?si=6iKcGnTavdQlQKUZ",
    "tags": [
      "multi-model",
      "cost-optimization",
      "strategic-reasoning",
      "architecture"
    ],
    "id": "oracle-and-worker-multi-model-approach",
    "slug": "oracle-and-worker-multi-model",
    "updated_at": "2026-01-05",
    "excerpt": "\n## Problem\nRelying on a single AI model creates a trade-off between capability and cost. High-performance models are expensive for routine tasks, while cost-effective models may lack the reasoning po"
  },
  {
    "title": "Curated Code Context Window",
    "status": "validated-in-production",
    "authors": [
      "Nikola Balic (@nibzard)"
    ],
    "based_on": [
      "Anonymous Speaker (Open Source Agent RL Talk)",
      "Will Brown (Prime Intellect Talk)",
      "Thorsten Ball"
    ],
    "category": "Context & Memory",
    "source": "https://www.youtube.com/watch?v=Xkwok_XXQgw",
    "tags": [
      "context-management",
      "code-agent",
      "file-selection",
      "noise-reduction"
    ],
    "id": "curated-code-context-window",
    "slug": "curated-code-context-window",
    "updated_at": "2026-01-05",
    "excerpt": "\n## Problem"
  },
  {
    "title": "CLI-First Skill Design",
    "status": "emerging",
    "authors": [
      "Lucas Carlson"
    ],
    "based_on": [
      "Anthropic (Claude Code)",
      "Unix Philosophy"
    ],
    "category": "Tool Use & Environment",
    "source": "https://github.com/anthropics/claude-code",
    "tags": [
      "cli",
      "skills",
      "shell",
      "dual-use",
      "composability",
      "unix-philosophy"
    ],
    "id": "cli-first-skill-design",
    "slug": "cli-first-skill-design",
    "updated_at": "2026-01-05",
    "excerpt": "\n## Problem"
  },
  {
    "title": "Progressive Complexity Escalation",
    "status": "emerging",
    "authors": [
      "Nikola Balic (@nibzard)"
    ],
    "based_on": [
      "Vercel AI Team"
    ],
    "category": "Orchestration & Control",
    "source": "https://vercel.com/blog/what-we-learned-building-agents-at-vercel",
    "tags": [
      "capabilities",
      "gradual-rollout",
      "risk-management",
      "evolution",
      "adaptive-systems",
      "complexity-management"
    ],
    "id": "progressive-complexity-escalation",
    "slug": "progressive-complexity-escalation",
    "updated_at": "2026-01-05",
    "excerpt": "\n## Problem"
  },
  {
    "title": "Conditional Parallel Tool Execution",
    "status": "validated-in-production",
    "authors": [
      "Nikola Balic (@nibzard)"
    ],
    "based_on": [
      "Gerred Dillon ('Building an Agentic System')"
    ],
    "category": "Orchestration & Control",
    "source": "https://gerred.github.io/building-an-agentic-system/parallel-tool-execution.html",
    "tags": [
      "parallel execution",
      "tool orchestration",
      "read-only tools",
      "stateful tools",
      "agent efficiency",
      "agent safety",
      "concurrency control",
      "task scheduling"
    ],
    "id": "conditional-parallel-tool-execution",
    "slug": "parallel-tool-execution",
    "updated_at": "2026-01-05",
    "excerpt": "\n## Problem"
  },
  {
    "title": "LLM Observability",
    "status": "proposed",
    "authors": [
      "Nikola Balic (@nibzard)"
    ],
    "based_on": [
      "Will Larson (Imprint)"
    ],
    "category": "Reliability & Eval",
    "source": "https://lethain.com/agents-logging/",
    "tags": [
      "observability",
      "logging",
      "debugging",
      "tracing",
      "datadog",
      "langsmith",
      "spans",
      "monitoring",
      "llmops"
    ],
    "id": "llm-observability",
    "slug": "llm-observability",
    "updated_at": "2026-01-13",
    "excerpt": "\n## Problem"
  },
  {
    "title": "Multi-Platform Communication Aggregation",
    "status": "emerging",
    "authors": [
      "Lucas Carlson"
    ],
    "based_on": [
      "Anthropic (Claude Code)"
    ],
    "category": "Tool Use & Environment",
    "source": "https://github.com/anthropics/claude-code",
    "tags": [
      "search",
      "aggregation",
      "parallel",
      "communication",
      "unified-interface"
    ],
    "id": "multi-platform-communication-aggregation",
    "slug": "multi-platform-communication-aggregation",
    "updated_at": "2026-01-05",
    "excerpt": "\n## Problem"
  },
  {
    "title": "Code-Over-API Pattern",
    "status": "established",
    "authors": [
      "Nikola Balic (@nibzard)"
    ],
    "based_on": [
      "Anthropic Engineering Team"
    ],
    "category": "Tool Use & Environment",
    "source": "https://www.anthropic.com/engineering/code-execution-with-mcp",
    "tags": [
      "token-optimization",
      "code-execution",
      "data-processing",
      "mcp"
    ],
    "id": "code-over-api-pattern",
    "slug": "code-over-api-pattern",
    "updated_at": "2026-01-05",
    "excerpt": "\n## Problem"
  },
  {
    "title": "Agent Reinforcement Fine-Tuning (Agent RFT)",
    "status": "emerging",
    "authors": [
      "Nikola Balic (@nibzard)"
    ],
    "based_on": [
      "Will Brown (OpenAI)",
      "Theo (OpenAI Solutions Architect)"
    ],
    "category": "Learning & Adaptation",
    "source": "https://youtu.be/1s_7RMG4O4U",
    "tags": [
      "reinforcement-learning",
      "fine-tuning",
      "tool-use",
      "multi-step-rl",
      "agent-training",
      "exploration"
    ],
    "id": "agent-reinforcement-fine-tuning-agent-rft",
    "slug": "agent-reinforcement-fine-tuning",
    "updated_at": "2026-01-05",
    "excerpt": "\n## Problem"
  },
  {
    "title": "Merged Code + Language Skill Model",
    "status": "emerging",
    "authors": [
      "Nikola Balic (@nibzard)"
    ],
    "based_on": [
      "Anonymous Speaker (Open Source Agent RL Talk)",
      "Will Brown (Prime Intellect Talk)"
    ],
    "category": "Reliability & Eval",
    "source": "https://www.youtube.com/watch?v=Xkwok_XXQgw",
    "tags": [
      "model-merging",
      "transfer-learning",
      "coding-agent",
      "multilingual"
    ],
    "id": "merged-code-language-skill-model",
    "slug": "merged-code-language-skill-model",
    "updated_at": "2026-01-05",
    "excerpt": "\n## Problem"
  },
  {
    "title": "Hybrid LLM/Code Workflow Coordinator",
    "status": "proposed",
    "authors": [
      "Nikola Balic (@nibzard)"
    ],
    "based_on": [
      "Will Larson (Imprint)"
    ],
    "category": "Orchestration & Control",
    "source": "https://lethain.com/agents-coordinators/",
    "tags": [
      "hybrid",
      "llm-driven",
      "code-driven",
      "coordinator",
      "determinism",
      "workflow-orchestration",
      "progressive-enhancement"
    ],
    "id": "hybrid-llmcode-workflow-coordinator",
    "slug": "hybrid-llm-code-workflow-coordinator",
    "updated_at": "2026-01-13",
    "excerpt": "\n## Problem"
  },
  {
    "title": "Agent-Driven Research",
    "status": "established",
    "authors": [
      "Nikola Balic (@nibzard)"
    ],
    "based_on": [
      "Danny Tarlow",
      "Connie Fan"
    ],
    "category": "Orchestration & Control",
    "source": "https://www.youtube.com/watch?v=u85G2aV_5rQ",
    "tags": [
      "research",
      "information retrieval",
      "tool use",
      "iterative process",
      "autonomous search"
    ],
    "id": "agent-driven-research",
    "slug": "agent-driven-research",
    "updated_at": "2026-01-05",
    "excerpt": "\n## Problem\nTraditional research methods often lack the ability to adapt search strategies based on emerging results, limiting efficiency and potential discoveries."
  },
  {
    "title": "Disposable Scaffolding Over Durable Features",
    "status": "best-practice",
    "authors": [
      "Nikola Balic (@nibzard)"
    ],
    "based_on": [
      "Thorsten Ball (Sourcegraph)"
    ],
    "category": "Orchestration & Control",
    "source": "https://www.sourcegraph.com",
    "tags": [
      "bitter-lesson",
      "temporary-tooling",
      "model-centric",
      "adaptability",
      "future-proofing"
    ],
    "id": "disposable-scaffolding-over-durable-features",
    "slug": "disposable-scaffolding-over-durable-features",
    "updated_at": "2026-01-05",
    "excerpt": "\n## Problem"
  },
  {
    "title": "Egress Lockdown (No-Exfiltration Channel)",
    "status": "established",
    "authors": [
      "Nikola Balic (@nibzard)"
    ],
    "based_on": [
      "Simon Willison (observation)",
      "Multiple vendor incident reports"
    ],
    "category": "Tool Use & Environment",
    "source": "https://simonwillison.net/2025/Jun/16/lethal-trifecta/",
    "tags": [
      "network-sandbox",
      "exfiltration",
      "outbound-controls",
      "security"
    ],
    "id": "egress-lockdown-no-exfiltration-channel",
    "slug": "egress-lockdown-no-exfiltration-channel",
    "updated_at": "2026-01-05",
    "excerpt": "\n## Problem\nEven with private-data access and untrusted inputs, attacks fail if the agent has **no way to transmit stolen data**. Many real-world fixes simply removed or filtered outbound channels."
  },
  {
    "title": "Compounding Engineering Pattern",
    "status": "emerging",
    "authors": [
      "Nikola Balic (@nibzard)"
    ],
    "based_on": [
      "Dan Shipper (Every)",
      "Every Engineering Team"
    ],
    "category": "Learning & Adaptation",
    "source": "https://every.to/podcast/transcript-how-to-use-claude-code-like-the-people-who-built-it",
    "tags": [
      "learning",
      "feedback-loops",
      "codification",
      "prompts",
      "slash-commands",
      "onboarding",
      "knowledge-sharing"
    ],
    "id": "compounding-engineering-pattern",
    "slug": "compounding-engineering-pattern",
    "updated_at": "2026-01-05",
    "excerpt": "\n## Problem"
  },
  {
    "title": "Visual AI Multimodal Integration",
    "status": "emerging",
    "authors": [
      "Nikola Balic (@nibzard)"
    ],
    "based_on": [
      "Andrew Ng",
      "OpenAI",
      "Anthropic",
      "Google"
    ],
    "category": "Tool Use & Environment",
    "source": "https://openai.com/research/gpt-4v-system-card",
    "tags": [
      "multimodal",
      "vision",
      "video",
      "image-processing",
      "visual-understanding",
      "agent-capabilities"
    ],
    "id": "visual-ai-multimodal-integration",
    "slug": "visual-ai-multimodal-integration",
    "updated_at": "2026-01-05",
    "excerpt": "\n## Problem"
  },
  {
    "title": "Deterministic Security Scanning Build Loop",
    "status": "proposed",
    "authors": [
      "Nikola Balic (@nibzard)"
    ],
    "based_on": [
      "Geoffrey Huntley"
    ],
    "category": "Security & Safety",
    "source": "https://ghuntley.com/secure-codegen/",
    "tags": [
      "security",
      "deterministic",
      "build-loop",
      "backpressure",
      "static-analysis"
    ],
    "id": "deterministic-security-scanning-build-loop",
    "slug": "deterministic-security-scanning-build-loop",
    "updated_at": "2026-01-05",
    "excerpt": "\n## Problem"
  },
  {
    "title": "Action-Selector Pattern",
    "status": "emerging",
    "authors": [
      "Nikola Balic (@nibzard)"
    ],
    "based_on": [
      "Luca Beurer-Kellner et al. (2025)"
    ],
    "category": "Orchestration & Control",
    "source": "https://arxiv.org/abs/2506.08837",
    "tags": [
      "prompt-injection",
      "control-flow",
      "safety",
      "tool-use"
    ],
    "id": "action-selector-pattern",
    "slug": "action-selector-pattern",
    "updated_at": "2026-01-05",
    "excerpt": "\n## Problem\nUntrusted input can hijack an agent's reasoning once tool feedback re-enters the context window, leading to arbitrary, harmful actions."
  },
  {
    "title": "Workflow Evals with Mocked Tools",
    "status": "emerging",
    "authors": [
      "Nikola Balic (@nibzard)"
    ],
    "based_on": [
      "Will Larson (lethain.com)",
      "Sierra (chat/voice platform)"
    ],
    "category": "Reliability & Eval",
    "source": "https://lethain.com/agents-evals/",
    "tags": [
      "evals",
      "testing",
      "ci-cd",
      "mocked-tools",
      "simulations",
      "workflow-validation",
      "end-to-end-testing"
    ],
    "id": "workflow-evals-with-mocked-tools",
    "slug": "workflow-evals-with-mocked-tools",
    "updated_at": "2026-01-13",
    "excerpt": "\n## Problem"
  },
  {
    "title": "Memory Synthesis from Execution Logs",
    "status": "emerging",
    "authors": [
      "Nikola Balic (@nibzard)"
    ],
    "based_on": [
      "Anthropic Internal Users",
      "Claude Code Team"
    ],
    "category": "Context & Memory",
    "source": "https://every.to/podcast/transcript-how-to-use-claude-code-like-the-people-who-built-it",
    "tags": [
      "memory",
      "logs",
      "diary",
      "synthesis",
      "pattern-detection",
      "knowledge-extraction",
      "learning"
    ],
    "id": "memory-synthesis-from-execution-logs",
    "slug": "memory-synthesis-from-execution-logs",
    "updated_at": "2026-01-05",
    "excerpt": "\n## Problem"
  },
  {
    "title": "Lethal Trifecta Threat Model",
    "status": "best-practice",
    "authors": [
      "Nikola Balic (@nibzard)"
    ],
    "based_on": [
      "Simon Willison"
    ],
    "category": "Reliability & Eval",
    "source": "https://simonwillison.net/2025/Jun/16/lethal-trifecta/",
    "tags": [
      "security",
      "prompt-injection",
      "threat-model",
      "data-exfiltration"
    ],
    "id": "lethal-trifecta-threat-model",
    "slug": "lethal-trifecta-threat-model",
    "updated_at": "2026-01-05",
    "excerpt": "\n## Problem\nCombining three agent capabilities—\n1. **Access to private data**\n2. **Exposure to untrusted content**\n3. **Ability to externally communicate**"
  },
  {
    "title": "Multi-Model Orchestration for Complex Edits",
    "status": "validated-in-production",
    "authors": [
      "Nikola Balic (@nibzard)"
    ],
    "based_on": [
      "Aman Sanger (Cursor)"
    ],
    "category": "Orchestration & Control",
    "source": "https://www.youtube.com/watch?v=BGgsoIgbT_Y",
    "tags": [
      "multi-model",
      "code-generation",
      "code-editing",
      "retrieval",
      "pipeline",
      "complex-tasks"
    ],
    "id": "multi-model-orchestration-for-complex-edits",
    "slug": "multi-model-orchestration-for-complex-edits",
    "updated_at": "2026-01-05",
    "excerpt": "\n## Problem\nA single large language model, even if powerful, may not be optimally suited for all sub-tasks involved in a complex operation like multi-file code editing. Tasks such as understanding bro"
  },
  {
    "title": "Inference-Healed Code Review Reward",
    "status": "proposed",
    "authors": [
      "Nikola Balic (@nibzard)"
    ],
    "based_on": [
      "Anonymous Speaker (Open Source Agent RL Talk)",
      "Will Brown (Prime Intellect Talk)"
    ],
    "category": "Feedback Loops",
    "source": "https://www.youtube.com/watch?v=Xkwok_XXQgw",
    "tags": [
      "reward-modeling",
      "code-review",
      "inference-healing",
      "quality-assessment"
    ],
    "id": "inference-healed-code-review-reward",
    "slug": "inference-healed-code-review-reward",
    "updated_at": "2026-01-05",
    "excerpt": "\n## Problem"
  },
  {
    "title": "Iterative Multi-Agent Brainstorming",
    "status": "experimental-but-awesome",
    "authors": [
      "Nikola Balic (@nibzard)"
    ],
    "based_on": [
      "Boris Cherny (via Claude Code capability)"
    ],
    "category": "Orchestration & Control",
    "source": "https://www.nibzard.com/claude-code",
    "tags": [
      "multi-agent",
      "brainstorming",
      "parallel processing",
      "idea generation",
      "sub-agents",
      "collaborative ideation"
    ],
    "id": "iterative-multi-agent-brainstorming",
    "slug": "iterative-multi-agent-brainstorming",
    "updated_at": "2026-01-05",
    "excerpt": "\n## Problem\nFor complex problems or creative ideation, a single AI agent instance might get stuck in a local optimum or fail to explore a diverse range of solutions. Generating a breadth of ideas can "
  },
  {
    "title": "Variance-Based RL Sample Selection",
    "status": "emerging",
    "authors": [
      "Nikola Balic (@nibzard)"
    ],
    "based_on": [
      "Theo (OpenAI Solutions Architect)",
      "Prashant (OpenAI RFT Team)"
    ],
    "category": "Learning & Adaptation",
    "source": "https://youtu.be/1s_7RMG4O4U",
    "tags": [
      "reinforcement-learning",
      "sample-efficiency",
      "variance",
      "data-quality",
      "agent-rft"
    ],
    "id": "variance-based-rl-sample-selection",
    "slug": "variance-based-rl-sample-selection",
    "updated_at": "2026-01-05",
    "excerpt": "\n## Problem"
  },
  {
    "title": "Tool Use Steering via Prompting",
    "status": "best-practice",
    "authors": [
      "Nikola Balic (@nibzard)"
    ],
    "based_on": [
      "Boris Cherny (via Claude Code examples)"
    ],
    "category": "Tool Use & Environment",
    "source": "https://www.nibzard.com/claude-code",
    "tags": [
      "tool use",
      "prompting",
      "agent guidance",
      "custom tools",
      "cli",
      "natural language control"
    ],
    "id": "tool-use-steering-via-prompting",
    "slug": "tool-use-steering-via-prompting",
    "updated_at": "2026-01-05",
    "excerpt": "\n## Problem\nAI agents equipped with multiple tools (e.g., shell access, file system operations, web search, custom CLIs) need clear guidance on when, why, and how to use these tools effectively. Simpl"
  },
  {
    "title": "Dogfooding with Rapid Iteration for Agent Improvement",
    "status": "best-practice",
    "authors": [
      "Nikola Balic (@nibzard)"
    ],
    "based_on": [
      "Lukas Möller (Cursor)",
      "Aman Sanger (Cursor)"
    ],
    "category": "Feedback Loops",
    "source": "https://www.youtube.com/watch?v=BGgsoIgbT_Y",
    "tags": [
      "dogfooding",
      "iterative-development",
      "feedback-loop",
      "agent-improvement",
      "internal-testing",
      "product-development"
    ],
    "id": "dogfooding-with-rapid-iteration-for-agent-improvement",
    "slug": "dogfooding-with-rapid-iteration-for-agent-improvement",
    "updated_at": "2026-01-05",
    "excerpt": "\n## Problem\nDeveloping effective AI agents requires understanding real-world usage and quickly identifying areas for improvement. External feedback loops can be slow, and simulated environments may no"
  },
  {
    "title": "Autonomous Workflow Agent Architecture",
    "status": "established",
    "authors": [
      "Nikola Balic (@nibzard)"
    ],
    "based_on": [
      "Together AI Team"
    ],
    "category": "Orchestration & Control",
    "source": "https://www.together.ai/blog/ai-agents-to-automate-complex-engineering-tasks",
    "tags": [
      "workflow-automation",
      "containerization",
      "multi-agent",
      "engineering-tasks",
      "tmux",
      "error-recovery"
    ],
    "id": "autonomous-workflow-agent-architecture",
    "slug": "autonomous-workflow-agent-architecture",
    "updated_at": "2026-01-05",
    "excerpt": "\n## Problem"
  },
  {
    "title": "Memory Reinforcement Learning (MemRL)",
    "status": "proposed",
    "authors": [
      "Nikola Balic (@nibzard)"
    ],
    "based_on": [
      "Shengtao Zhang, Jiaqian Wang, et al. (Shanghai Jiao Tong University, Xidian University, MemTensor)"
    ],
    "category": "Learning & Adaptation",
    "source": "https://arxiv.org/html/2601.03192v1",
    "tags": [
      "reinforcement-learning",
      "episodic-memory",
      "self-evolution",
      "value-aware-retrieval",
      "runtime-learning",
      "stability-plasticity"
    ],
    "id": "memory-reinforcement-learning-memrl",
    "slug": "memory-reinforcement-learning-memrl",
    "updated_at": "2026-01-13",
    "excerpt": "\n## Problem"
  },
  {
    "title": "Spectrum of Control / Blended Initiative",
    "status": "validated-in-production",
    "authors": [
      "Nikola Balic (@nibzard)"
    ],
    "based_on": [
      "Aman Sanger (Cursor)"
    ],
    "category": "UX & Collaboration",
    "source": "https://www.youtube.com/watch?v=BGgsoIgbT_Y",
    "tags": [
      "human-agent-collaboration",
      "autonomy-spectrum",
      "interactive-control",
      "task-delegation",
      "code-editing",
      "ide-integration"
    ],
    "id": "spectrum-of-control-blended-initiative",
    "slug": "spectrum-of-control-blended-initiative",
    "updated_at": "2026-01-05",
    "excerpt": "\n## Problem\nAI agents for tasks like coding can offer various levels of assistance, from simple completions to complex, multi-step operations. A one-size-fits-all approach to agent autonomy doesn't ca"
  },
  {
    "title": "AI-Assisted Code Review / Verification",
    "status": "emerging",
    "authors": [
      "Nikola Balic (@nibzard)"
    ],
    "based_on": [
      "Aman Sanger (Cursor)"
    ],
    "category": "Feedback Loops",
    "source": "https://www.youtube.com/watch?v=BGgsoIgbT_Y",
    "tags": [
      "code-review",
      "verification",
      "quality-assurance",
      "human-ai-collaboration",
      "trust",
      "explainability",
      "software-quality"
    ],
    "id": "ai-assisted-code-review-verification",
    "slug": "ai-assisted-code-review-verification",
    "updated_at": "2026-01-05",
    "excerpt": "\n## Problem\nAs AI models generate increasing amounts of code, the bottleneck in software development shifts from code generation to code verification and review. Ensuring that AI-generated code is not"
  },
  {
    "title": "CriticGPT-Style Code Review",
    "status": "validated-in-production",
    "authors": [
      "Nikola Balic (@nibzard)"
    ],
    "based_on": [
      "OpenAI"
    ],
    "category": "Reliability & Eval",
    "source": "https://openai.com/research/criticgpt",
    "tags": [
      "evaluation",
      "code-review",
      "critique",
      "quality-assurance",
      "bug-detection",
      "gpt-4"
    ],
    "id": "criticgpt-style-code-review",
    "slug": "criticgpt-style-evaluation",
    "updated_at": "2026-01-05",
    "excerpt": "\n## Problem"
  },
  {
    "title": "Coding Agent CI Feedback Loop",
    "status": "best-practice",
    "authors": [
      "Nikola Balic (@nibzard)"
    ],
    "based_on": [
      "Quinn Slack (Concept)",
      "Will Brown (Prime Intellect Talk)"
    ],
    "category": "Feedback Loops",
    "source": "https://www.youtube.com/watch?v=Xkwok_XXQgw",
    "tags": [
      "CI",
      "coding-agent",
      "asynchronous",
      "test-driven",
      "feedback"
    ],
    "id": "coding-agent-ci-feedback-loop",
    "slug": "coding-agent-ci-feedback-loop",
    "updated_at": "2026-01-05",
    "excerpt": "\n## Problem"
  },
  {
    "title": "RLAIF (Reinforcement Learning from AI Feedback)",
    "status": "emerging",
    "authors": [
      "Nikola Balic (@nibzard)"
    ],
    "based_on": [
      "Anthropic",
      "Google DeepMind"
    ],
    "category": "Reliability & Eval",
    "source": "https://arxiv.org/abs/2212.08073",
    "tags": [
      "rlhf",
      "rlaif",
      "constitutional-ai",
      "synthetic-data",
      "feedback",
      "alignment",
      "evaluation"
    ],
    "id": "rlaif-reinforcement-learning-from-ai-feedback",
    "slug": "rlaif-reinforcement-learning-from-ai-feedback",
    "updated_at": "2026-01-05",
    "excerpt": "\n## Problem"
  },
  {
    "title": "Self-Rewriting Meta-Prompt Loop",
    "status": "emerging",
    "authors": [
      "Nikola Balic (@nibzard)"
    ],
    "based_on": [
      "Noah D. Goodman (Meta-Prompt)"
    ],
    "category": "Orchestration & Control",
    "source": "https://noahgoodman.substack.com/p/meta-prompt-a-simple-self-improving",
    "tags": [
      "meta-prompting",
      "self-improvement",
      "system-prompt",
      "reflection"
    ],
    "id": "self-rewriting-meta-prompt-loop",
    "slug": "self-rewriting-meta-prompt-loop",
    "updated_at": "2026-01-05",
    "excerpt": "\n## Problem\nStatic system prompts become stale or overly brittle as an agent encounters new tasks and edge-cases. Manually editing them is slow and error-prone."
  },
  {
    "title": "Proactive Trigger Vocabulary",
    "status": "emerging",
    "authors": [
      "Lucas Carlson"
    ],
    "based_on": [
      "Anthropic (Claude Code)"
    ],
    "category": "UX & Collaboration",
    "source": "https://github.com/anthropics/claude-code",
    "tags": [
      "ux",
      "triggers",
      "intent-detection",
      "skill-routing",
      "natural-language"
    ],
    "id": "proactive-trigger-vocabulary",
    "slug": "proactive-trigger-vocabulary",
    "updated_at": "2026-01-05",
    "excerpt": "\n## Problem"
  },
  {
    "title": "Progressive Autonomy with Model Evolution",
    "status": "best-practice",
    "authors": [
      "Nikola Balic (@nibzard)"
    ],
    "based_on": [
      "Boris Cherny (Anthropic)",
      "Claude Code Team"
    ],
    "category": "Orchestration & Control",
    "source": "https://every.to/podcast/transcript-how-to-use-claude-code-like-the-people-who-built-it",
    "tags": [
      "model-evolution",
      "scaffolding",
      "autonomy",
      "system-prompts",
      "capabilities",
      "model-intelligence"
    ],
    "id": "progressive-autonomy-with-model-evolution",
    "slug": "progressive-autonomy-with-model-evolution",
    "updated_at": "2026-01-05",
    "excerpt": "\n## Problem"
  },
  {
    "title": "Agent-First Tooling and Logging",
    "status": "emerging",
    "authors": [
      "Nikola Balic (@nibzard)"
    ],
    "based_on": [
      "Thorsten Ball (Sourcegraph)"
    ],
    "category": "Tool Use & Environment",
    "source": "https://www.sourcegraph.com",
    "tags": [
      "tool-design",
      "logging",
      "machine-readable",
      "observability",
      "agent-environment"
    ],
    "id": "agent-first-tooling-and-logging",
    "slug": "agent-first-tooling-and-logging",
    "updated_at": "2026-01-05",
    "excerpt": "\n## Problem"
  },
  {
    "title": "Progressive Disclosure for Large Files",
    "status": "emerging",
    "authors": [
      "Nikola Balic (@nibzard)"
    ],
    "based_on": [
      "Will Larson (lethain.com)"
    ],
    "category": "Context & Memory",
    "source": "https://lethain.com/agents-large-files/",
    "tags": [
      "progressive-disclosure",
      "large-files",
      "context-optimization",
      "file-management",
      "lazy-loading",
      "file-handling",
      "metadata"
    ],
    "id": "progressive-disclosure-for-large-files",
    "slug": "progressive-disclosure-large-files",
    "updated_at": "2026-01-13",
    "excerpt": "\n## Problem"
  },
  {
    "title": "Language Agent Tree Search (LATS)",
    "status": "emerging",
    "authors": [
      "Nikola Balic (@nibzard)"
    ],
    "based_on": [
      "Zhou et al.",
      "University of Illinois"
    ],
    "category": "Orchestration & Control",
    "source": "https://arxiv.org/abs/2310.04406",
    "tags": [
      "search",
      "monte-carlo",
      "tree-search",
      "reasoning",
      "planning",
      "reflection",
      "evaluation"
    ],
    "id": "language-agent-tree-search-lats",
    "slug": "language-agent-tree-search-lats",
    "updated_at": "2026-01-05",
    "excerpt": "\n## Problem"
  },
  {
    "title": "Agent-Assisted Scaffolding",
    "status": "validated-in-production",
    "authors": [
      "Nikola Balic (@nibzard)"
    ],
    "based_on": [
      "Lukas Möller (Cursor)"
    ],
    "category": "UX & Collaboration",
    "source": "https://www.youtube.com/watch?v=BGgsoIgbT_Y",
    "tags": [
      "code-generation",
      "bootstrapping",
      "scaffolding",
      "feature-development",
      "ide",
      "initial-setup"
    ],
    "id": "agent-assisted-scaffolding",
    "slug": "agent-assisted-scaffolding",
    "updated_at": "2026-01-05",
    "excerpt": "\n## Problem\nStarting a new feature, module, or codebase often involves writing a significant amount of boilerplate or foundational code. This can be time-consuming and repetitive for developers."
  },
  {
    "title": "Layered Configuration Context",
    "status": "established",
    "authors": [
      "Nikola Balic (@nibzard)"
    ],
    "based_on": [
      "Boris Cherny (via Claude Code)"
    ],
    "category": "Context & Memory",
    "source": "https://www.nibzard.com/claude-code",
    "tags": [
      "context management",
      "configuration",
      "scoped context",
      "automatic loading",
      "CLAUDE.md"
    ],
    "id": "layered-configuration-context",
    "slug": "layered-configuration-context",
    "updated_at": "2026-01-05",
    "excerpt": "\n## Problem\nAI agents require relevant context to perform effectively. Providing this context manually in every prompt is cumbersome, and a one-size-fits-all global context is often too broad or too n"
  },
  {
    "title": "Virtual Machine Operator Agent",
    "status": "established",
    "authors": [
      "Nikola Balic (@nibzard)"
    ],
    "based_on": [
      "Amjad Masad"
    ],
    "category": "Tool Use & Environment",
    "source": "https://www.nibzard.com/silent-revolution",
    "tags": [
      "computer operation",
      "virtual machine",
      "execution environment",
      "agent capability"
    ],
    "id": "virtual-machine-operator-agent",
    "slug": "virtual-machine-operator-agent",
    "updated_at": "2026-01-05",
    "excerpt": "\n## Problem\nAI agents need to perform complex tasks beyond simple code generation or text manipulation. They require the ability to interact with a full computer environment to execute code, manage sy"
  },
  {
    "title": "Seamless Background-to-Foreground Handoff",
    "status": "emerging",
    "authors": [
      "Nikola Balic (@nibzard)"
    ],
    "based_on": [
      "Aman Sanger (Cursor)"
    ],
    "category": "UX & Collaboration",
    "source": "https://www.youtube.com/watch?v=BGgsoIgbT_Y",
    "tags": [
      "background-agent",
      "human-in-the-loop",
      "task-handoff",
      "interactive-refinement",
      "agent-collaboration",
      "developer-workflow"
    ],
    "id": "seamless-background-to-foreground-handoff",
    "slug": "seamless-background-to-foreground-handoff",
    "updated_at": "2026-01-05",
    "excerpt": "\n## Problem\nWhile background agents can handle long-running, complex tasks autonomously, they might not achieve 100% correctness or perfectly match the user's nuanced intent. If an agent completes 90%"
  },
  {
    "title": "Opponent Processor / Multi-Agent Debate Pattern",
    "status": "emerging",
    "authors": [
      "Nikola Balic (@nibzard)"
    ],
    "based_on": [
      "Dan Shipper (Every)",
      "Reddit Community"
    ],
    "category": "Orchestration & Control",
    "source": "https://every.to/podcast/transcript-how-to-use-claude-code-like-the-people-who-built-it",
    "tags": [
      "multi-agent",
      "debate",
      "adversarial",
      "bias-reduction",
      "uncorrelated-context",
      "validation"
    ],
    "id": "opponent-processor-multi-agent-debate-pattern",
    "slug": "opponent-processor-multi-agent-debate",
    "updated_at": "2026-01-05",
    "excerpt": "\n## Problem"
  },
  {
    "title": "Iterative Prompt & Skill Refinement",
    "status": "proposed",
    "authors": [
      "Nikola Balic (@nibzard)"
    ],
    "based_on": [
      "Will Larson (Imprint)"
    ],
    "category": "Feedback Loops",
    "source": "https://lethain.com/agents-iterative-refinement/",
    "tags": [
      "refinement",
      "iteration",
      "prompts",
      "skills",
      "feedback",
      "multi-mechanism",
      "continuous-improvement",
      "dashboards"
    ],
    "id": "iterative-prompt-skill-refinement",
    "slug": "iterative-prompt-skill-refinement",
    "updated_at": "2026-01-13",
    "excerpt": "\n## Problem"
  },
  {
    "title": "Dynamic Context Injection",
    "status": "established",
    "authors": [
      "Nikola Balic (@nibzard)"
    ],
    "based_on": [
      "Boris Cherny (via Claude Code)"
    ],
    "category": "Context & Memory",
    "source": "https://www.nibzard.com/claude-code",
    "tags": [
      "context management",
      "dynamic context",
      "lazy loading",
      "slash commands",
      "at-mention",
      "interactive context"
    ],
    "id": "dynamic-context-injection",
    "slug": "dynamic-context-injection",
    "updated_at": "2026-01-05",
    "excerpt": "\n## Problem"
  },
  {
    "title": "Tool Capability Compartmentalization",
    "status": "emerging",
    "authors": [
      "Nikola Balic (@nibzard)"
    ],
    "based_on": [
      "Simon Willison (MCP critique)"
    ],
    "category": "Orchestration & Control",
    "source": "https://simonwillison.net/2025/Jun/16/lethal-trifecta/",
    "tags": [
      "capability-segregation",
      "least-privilege",
      "tool-permissions"
    ],
    "id": "tool-capability-compartmentalization",
    "slug": "tool-capability-compartmentalization",
    "updated_at": "2026-01-05",
    "excerpt": "\n## Problem\nModel Context Protocol (MCP) encourages \"mix-and-match\" tools—often combining private-data readers, web fetchers, and writers in a single callable unit. This amplifies the lethality of pro"
  },
  {
    "title": "Agentic Search Over Vector Embeddings",
    "status": "best-practice",
    "authors": [
      "Nikola Balic (@nibzard)"
    ],
    "based_on": [
      "Cat Wu (Anthropic)",
      "Boris Cherny (Anthropic)"
    ],
    "category": "Tool Use & Environment",
    "source": "https://every.to/podcast/transcript-how-to-use-claude-code-like-the-people-who-built-it",
    "tags": [
      "search",
      "vector-embeddings",
      "bash",
      "grep",
      "RAG",
      "agentic-RAG",
      "maintenance"
    ],
    "id": "agentic-search-over-vector-embeddings",
    "slug": "agentic-search-over-vector-embeddings",
    "updated_at": "2026-01-05",
    "excerpt": "\n## Problem"
  },
  {
    "title": "Subagent Compilation Checker",
    "status": "emerging",
    "authors": [
      "Nikola Balic (@nibzard)"
    ],
    "based_on": [
      "Anonymous Speaker (Open Source Agent RL Talk)",
      "Will Brown (Prime Intellect Talk)"
    ],
    "category": "Tool Use & Environment",
    "source": "https://www.youtube.com/watch?v=Xkwok_XXQgw",
    "tags": [
      "subagent",
      "compilation",
      "modularity",
      "error-isolation"
    ],
    "id": "subagent-compilation-checker",
    "slug": "subagent-compilation-checker",
    "updated_at": "2026-01-05",
    "excerpt": "\n## Problem"
  },
  {
    "title": "Rich Feedback Loops > Perfect Prompts",
    "status": "validated-in-production",
    "authors": [
      "Nikola Balic (@nibzard)"
    ],
    "based_on": [
      "Thorsten Ball",
      "Quinn Slack"
    ],
    "category": "Feedback Loops",
    "source": "https://www.nibzard.com/ampcode",
    "tags": [
      "feedback",
      "testing",
      "reliability"
    ],
    "id": "rich-feedback-loops-perfect-prompts",
    "slug": "rich-feedback-loops",
    "updated_at": "2026-01-05",
    "excerpt": "\n## Problem\nPolishing a single prompt can't cover every edge-case; agents need ground truth to self-correct."
  },
  {
    "title": "AI-Accelerated Learning and Skill Development",
    "status": "validated-in-production",
    "authors": [
      "Nikola Balic (@nibzard)"
    ],
    "based_on": [
      "Lukas Möller (Cursor)",
      "Alex Albert (Anthropic)",
      "Jacob Jackson (Cursor)"
    ],
    "category": "UX & Collaboration",
    "source": "https://www.youtube.com/watch?v=BGgsoIgbT_Y",
    "tags": [
      "developer-productivity",
      "learning",
      "skill-acquisition",
      "iteration",
      "feedback",
      "taste-development",
      "education",
      "junior-developer"
    ],
    "id": "ai-accelerated-learning-and-skill-development",
    "slug": "ai-accelerated-learning-and-skill-development",
    "updated_at": "2026-01-05",
    "excerpt": "\n## Problem\nDeveloping strong software engineering skills, including \"taste\" for clean and effective code, traditionally requires extensive experience, trial-and-error, and mentorship, which can be a "
  },
  {
    "title": "Latent Demand Product Discovery",
    "status": "best-practice",
    "authors": [
      "Nikola Balic (@nibzard)"
    ],
    "based_on": [
      "Boris Cherny (Anthropic)",
      "Meta Product Teams"
    ],
    "category": "UX & Collaboration",
    "source": "https://every.to/podcast/transcript-how-to-use-claude-code-like-the-people-who-built-it",
    "tags": [
      "product-discovery",
      "extensibility",
      "hackable-products",
      "power-users",
      "latent-demand"
    ],
    "id": "latent-demand-product-discovery",
    "slug": "latent-demand-product-discovery",
    "updated_at": "2026-01-05",
    "excerpt": "\n## Problem"
  },
  {
    "title": "Agent SDK for Programmatic Control",
    "status": "emerging",
    "authors": [
      "Nikola Balic (@nibzard)"
    ],
    "based_on": [
      "Anthropic (Claude Code SDK example)"
    ],
    "category": "Tool Use & Environment",
    "source": "https://www.nibzard.com/claude-code",
    "tags": [
      "sdk",
      "automation",
      "ci/cd",
      "programmatic access",
      "scripting",
      "api",
      "headless agent"
    ],
    "id": "agent-sdk-for-programmatic-control",
    "slug": "agent-sdk-for-programmatic-control",
    "updated_at": "2026-01-05",
    "excerpt": "\n## Problem\nInteractive terminal or chat interfaces are suitable for many agent tasks, but not for all. Integrating agent capabilities into automated workflows (e.g., CI/CD pipelines, scheduled jobs, "
  },
  {
    "title": "Dual LLM Pattern",
    "status": "emerging",
    "authors": [
      "Nikola Balic (@nibzard)"
    ],
    "based_on": [
      "Simon Willison (orig.)",
      "Luca Beurer-Kellner et al. (2025)"
    ],
    "category": "Orchestration & Control",
    "source": "https://arxiv.org/abs/2506.08837",
    "tags": [
      "privilege-separation",
      "quarantined-llm",
      "symbolic-variables"
    ],
    "id": "dual-llm-pattern",
    "slug": "dual-llm-pattern",
    "updated_at": "2026-01-05",
    "excerpt": "\n## Problem\nA privileged agent that both sees untrusted text **and** wields tools can be coerced into dangerous calls."
  },
  {
    "title": "Plan-Then-Execute Pattern",
    "status": "emerging",
    "authors": [
      "Nikola Balic (@nibzard)"
    ],
    "based_on": [
      "Luca Beurer-Kellner et al. (2025)"
    ],
    "category": "Orchestration & Control",
    "source": "https://arxiv.org/abs/2506.08837",
    "tags": [
      "planning",
      "control-flow-integrity",
      "prompt-injection"
    ],
    "id": "plan-then-execute-pattern",
    "slug": "plan-then-execute-pattern",
    "updated_at": "2026-01-05",
    "excerpt": "\n## Problem\nIf tool outputs can alter the *choice* of later actions, injected instructions may redirect the agent toward malicious steps."
  },
  {
    "title": "Parallel Tool Call Learning",
    "status": "emerging",
    "authors": [
      "Nikola Balic (@nibzard)"
    ],
    "based_on": [
      "Sam Pretty (Cognition)",
      "Will Brown (OpenAI)"
    ],
    "category": "Orchestration & Control",
    "source": "https://youtu.be/1s_7RMG4O4U",
    "tags": [
      "parallelization",
      "latency-optimization",
      "tool-use",
      "reinforcement-learning",
      "performance"
    ],
    "id": "parallel-tool-call-learning",
    "slug": "parallel-tool-call-learning",
    "updated_at": "2026-01-05",
    "excerpt": "\n## Problem"
  },
  {
    "title": "Dynamic Code Injection (On-Demand File Fetch)",
    "status": "established",
    "authors": [
      "Nikola Balic (@nibzard)"
    ],
    "based_on": [
      "Internal AI Dev Team"
    ],
    "category": "Tool Use & Environment",
    "source": "Internal Practice",
    "tags": [
      "file-injection",
      "at-mention",
      "slash-commands",
      "IDE-integration"
    ],
    "id": "dynamic-code-injection-on-demand-file-fetch",
    "slug": "dynamic-code-injection-on-demand-file-fetch",
    "updated_at": "2026-01-05",
    "excerpt": "\n## Problem"
  },
  {
    "title": "Inference-Time Scaling",
    "status": "emerging",
    "authors": [
      "Nikola Balic (@nibzard)"
    ],
    "based_on": [
      "Google DeepMind",
      "OpenAI"
    ],
    "category": "Orchestration & Control",
    "source": "https://deepmind.google/research/",
    "tags": [
      "scaling",
      "inference",
      "compute",
      "reasoning",
      "performance",
      "o1-model",
      "test-time-compute"
    ],
    "id": "inference-time-scaling",
    "slug": "inference-time-scaling",
    "updated_at": "2026-01-05",
    "excerpt": "\n## Problem"
  },
  {
    "title": "Verbose Reasoning Transparency",
    "status": "best-practice",
    "authors": [
      "Nikola Balic (@nibzard)"
    ],
    "based_on": [
      "Boris Cherny (via Claude Code)"
    ],
    "category": "UX & Collaboration",
    "source": "https://www.nibzard.com/claude-code",
    "tags": [
      "explainability",
      "debugging",
      "transparency",
      "agent reasoning",
      "verbose mode",
      "introspection"
    ],
    "id": "verbose-reasoning-transparency",
    "slug": "verbose-reasoning-transparency",
    "updated_at": "2026-01-05",
    "excerpt": "\n## Problem\nAI agents, especially those using complex models or multiple tools, can sometimes behave like \"black boxes.\" Users may not understand why an agent made a particular decision, chose a speci"
  },
  {
    "title": "Distributed Execution with Cloud Workers",
    "status": "emerging",
    "authors": [
      "Nikola Balic (@nibzard)"
    ],
    "based_on": [
      "Dexter Horthy (HumanLayer)"
    ],
    "category": "Orchestration & Control",
    "source": "https://claude.com/blog/building-companies-with-claude-code",
    "tags": [
      "distributed-systems",
      "parallelization",
      "cloud",
      "worktrees",
      "scalability",
      "team-coordination"
    ],
    "id": "distributed-execution-with-cloud-workers",
    "slug": "distributed-execution-cloud-workers",
    "updated_at": "2026-01-05",
    "excerpt": "\n## Problem"
  },
  {
    "title": "Background Agent with CI Feedback",
    "status": "validated-in-production",
    "authors": [
      "Nikola Balic (@nibzard)"
    ],
    "based_on": [
      "Quinn Slack"
    ],
    "category": "Feedback Loops",
    "source": "https://ampcode.com/manual#background",
    "tags": [
      "asynchronous",
      "ci",
      "feedback"
    ],
    "id": "background-agent-with-ci-feedback",
    "slug": "background-agent-ci",
    "updated_at": "2026-01-05",
    "excerpt": "\n## Problem\nLong-running tasks tie up the editor and require developers to babysit the agent."
  },
  {
    "title": "Feature List as Immutable Contract",
    "status": "emerging",
    "authors": [
      "Nikola Balic (@nibzard)"
    ],
    "based_on": [
      "Anthropic Engineering Team"
    ],
    "category": "Orchestration & Control",
    "source": "https://www.anthropic.com/engineering/effective-harnesses-for-long-running-agents",
    "tags": [
      "scope-control",
      "acceptance-criteria",
      "anti-scope-creep",
      "long-running-agents",
      "task-management"
    ],
    "id": "feature-list-as-immutable-contract",
    "slug": "feature-list-as-immutable-contract",
    "updated_at": "2026-01-05",
    "excerpt": "\n## Problem"
  },
  {
    "title": "Abstracted Code Representation for Review",
    "status": "proposed",
    "authors": [
      "Nikola Balic (@nibzard)"
    ],
    "based_on": [
      "Aman Sanger (Cursor, referencing Michael Grinich)"
    ],
    "category": "UX & Collaboration",
    "source": "https://www.youtube.com/watch?v=BGgsoIgbT_Y",
    "tags": [
      "code-review",
      "verification",
      "abstraction",
      "pseudocode",
      "intent-based-review",
      "explainability",
      "software-quality",
      "human-ai-interface"
    ],
    "id": "abstracted-code-representation-for-review",
    "slug": "abstracted-code-representation-for-review",
    "updated_at": "2026-01-05",
    "excerpt": "\n## Problem\nReviewing large volumes of AI-generated code line-by-line can be tedious, error-prone, and inefficient. Human reviewers are often more interested in verifying the high-level intent and log"
  },
  {
    "title": "Dual-Use Tool Design",
    "status": "best-practice",
    "authors": [
      "Nikola Balic (@nibzard)"
    ],
    "based_on": [
      "Boris Cherny (Anthropic)",
      "Claude Code Team"
    ],
    "category": "Tool Use & Environment",
    "source": "https://every.to/podcast/transcript-how-to-use-claude-code-like-the-people-who-built-it",
    "tags": [
      "tools",
      "ux",
      "slash-commands",
      "hooks",
      "human-ai-collaboration",
      "consistency"
    ],
    "id": "dual-use-tool-design",
    "slug": "dual-use-tool-design",
    "updated_at": "2026-01-05",
    "excerpt": "\n## Problem"
  },
  {
    "title": "Patch Steering via Prompted Tool Selection",
    "status": "best-practice",
    "authors": [
      "Nikola Balic (@nibzard)"
    ],
    "based_on": [
      "Boris Cherny (Claude Code Concepts)",
      "Will Brown (Prime Intellect Talk)"
    ],
    "category": "Tool Use & Environment",
    "source": "https://www.youtube.com/watch?v=Xkwok_XXQgw",
    "tags": [
      "patching",
      "prompt-steering",
      "tool-selection",
      "coding-agent"
    ],
    "id": "patch-steering-via-prompted-tool-selection",
    "slug": "patch-steering-via-prompted-tool-selection",
    "updated_at": "2026-01-05",
    "excerpt": "\n## Problem"
  },
  {
    "title": "Sub-Agent Spawning",
    "status": "validated-in-production",
    "authors": [
      "Nikola Balic (@nibzard)"
    ],
    "based_on": [
      "Quinn Slack",
      "Thorsten Ball",
      "Will Larson (lethain.com)"
    ],
    "category": "Orchestration & Control",
    "source": "https://www.nibzard.com/ampcode",
    "tags": [
      "orchestration",
      "context",
      "scalability",
      "subagents",
      "yaml-configuration",
      "virtual-files"
    ],
    "id": "sub-agent-spawning",
    "slug": "sub-agent-spawning",
    "updated_at": "2026-01-13",
    "excerpt": "\n## Problem"
  },
  {
    "title": "LLM-Friendly API Design",
    "status": "emerging",
    "authors": [
      "Nikola Balic (@nibzard)"
    ],
    "based_on": [
      "Lukas Möller (Cursor)"
    ],
    "category": "Tool Use & Environment",
    "source": "https://www.youtube.com/watch?v=BGgsoIgbT_Y",
    "tags": [
      "api-design",
      "llm-interaction",
      "tool-use",
      "system-design",
      "code-structure",
      "agent-compatibility"
    ],
    "id": "llm-friendly-api-design",
    "slug": "llm-friendly-api-design",
    "updated_at": "2026-01-05",
    "excerpt": "\n## Problem\nFor AI agents to reliably and effectively use tools, especially APIs or internal libraries, the design of these interfaces matters. APIs designed solely for human consumption might be ambi"
  },
  {
    "title": "Curated File Context Window",
    "status": "best-practice",
    "authors": [
      "Nikola Balic (@nibzard)"
    ],
    "based_on": [
      "Internal AI Dev Team"
    ],
    "category": "Context & Memory",
    "source": "Internal Practice",
    "tags": [
      "code-context",
      "file-scope",
      "relevance",
      "memory-management"
    ],
    "id": "curated-file-context-window",
    "slug": "curated-file-context-window",
    "updated_at": "2026-01-05",
    "excerpt": "\n## Problem"
  },
  {
    "title": "Progressive Tool Discovery",
    "status": "established",
    "authors": [
      "Nikola Balic (@nibzard)"
    ],
    "based_on": [
      "Anthropic Engineering Team"
    ],
    "category": "Tool Use & Environment",
    "source": "https://www.anthropic.com/engineering/code-execution-with-mcp",
    "tags": [
      "mcp",
      "tool-discovery",
      "context-optimization",
      "lazy-loading"
    ],
    "id": "progressive-tool-discovery",
    "slug": "progressive-tool-discovery",
    "updated_at": "2026-01-05",
    "excerpt": "\n## Problem"
  },
  {
    "title": "Three-Stage Perception Architecture",
    "status": "proposed",
    "authors": [
      "Nikola Balic (@nibzard)"
    ],
    "based_on": [
      "AI Architecture Community"
    ],
    "category": "Orchestration & Control",
    "source": "https://www.oreilly.com/library/view/software-architecture-patterns/9781491971437/",
    "tags": [
      "architecture",
      "perception",
      "processing",
      "action",
      "pipeline",
      "modular-design"
    ],
    "id": "three-stage-perception-architecture",
    "slug": "three-stage-perception-architecture",
    "updated_at": "2026-01-05",
    "excerpt": "\n## Problem"
  },
  {
    "title": "Extended Coherence Work Sessions",
    "status": "rapidly-improving",
    "authors": [
      "Nikola Balic (@nibzard)"
    ],
    "based_on": [
      "Amjad Masad (observation)"
    ],
    "category": "Reliability & Eval",
    "source": "https://www.nibzard.com/silent-revolution",
    "tags": [
      "coherence",
      "long-running tasks",
      "agent capability",
      "llm",
      "complex projects"
    ],
    "id": "extended-coherence-work-sessions",
    "slug": "extended-coherence-work-sessions",
    "updated_at": "2026-01-05",
    "excerpt": "\n## Problem\nEarly AI agents and models often suffered from a short \"coherence window,\" meaning they could only maintain focus and context for a few minutes before their performance degraded significan"
  },
  {
    "title": "Episodic Memory Retrieval & Injection",
    "status": "validated-in-production",
    "authors": [
      "Nikola Balic (@nibzard)"
    ],
    "based_on": [
      "Cursor AI (MCP)",
      "Windsurf Flows"
    ],
    "category": "Context & Memory",
    "source": "https://forum.cursor.com/t/agentic-memory-management-for-cursor/78021",
    "tags": [
      "episodic-memory",
      "vector-db",
      "retrieval-augmented",
      "context-hint"
    ],
    "id": "episodic-memory-retrieval-injection",
    "slug": "episodic-memory-retrieval-injection",
    "updated_at": "2026-01-05",
    "excerpt": "\n## Problem\nStateless calls make agents forget prior decisions, causing repetition and shallow reasoning."
  },
  {
    "title": "Self-Discover: LLM Self-Composed Reasoning Structures",
    "status": "emerging",
    "authors": [
      "Nikola Balic (@nibzard)"
    ],
    "based_on": [
      "Google DeepMind",
      "USC"
    ],
    "category": "Feedback Loops",
    "source": "https://arxiv.org/abs/2402.03620",
    "tags": [
      "reasoning",
      "self-improvement",
      "meta-learning",
      "problem-solving",
      "task-specific",
      "optimization"
    ],
    "id": "self-discover-llm-self-composed-reasoning-structures",
    "slug": "self-discover-reasoning-structures",
    "updated_at": "2026-01-05",
    "excerpt": "\n## Problem"
  },
  {
    "title": "Discrete Phase Separation",
    "status": "emerging",
    "authors": [
      "Nikola Balic (@nibzard)"
    ],
    "based_on": [
      "Sam Stettner (Ambral)"
    ],
    "category": "Orchestration & Control",
    "source": "https://claude.com/blog/building-companies-with-claude-code",
    "tags": [
      "orchestration",
      "planning",
      "research",
      "context-management",
      "multi-model"
    ],
    "id": "discrete-phase-separation",
    "slug": "discrete-phase-separation",
    "updated_at": "2026-01-05",
    "excerpt": "\n## Problem"
  },
  {
    "title": "Explicit Posterior-Sampling Planner",
    "status": "emerging",
    "authors": [
      "Nikola Balic (@nibzard)"
    ],
    "based_on": [
      "Dilip Arumugam",
      "Thomas L. Griffiths"
    ],
    "category": "Orchestration & Control",
    "source": "https://arxiv.org/abs/2504.20997",
    "tags": [
      "RL",
      "PSRL",
      "exploration",
      "planning",
      "decision-making"
    ],
    "id": "explicit-posterior-sampling-planner",
    "slug": "explicit-posterior-sampling-planner",
    "updated_at": "2026-01-05",
    "excerpt": "\n## Problem\nAgents that rely on ad-hoc heuristics explore poorly, wasting tokens and API calls on dead ends."
  },
  {
    "title": "Inversion of Control",
    "status": "validated-in-production",
    "authors": [
      "Nikola Balic (@nibzard)"
    ],
    "based_on": [
      "Quinn Slack",
      "Thorsten Ball"
    ],
    "category": "Orchestration & Control",
    "source": "https://www.nibzard.com/ampcode",
    "tags": [
      "orchestration",
      "autonomy",
      "control"
    ],
    "id": "inversion-of-control",
    "slug": "inversion-of-control",
    "updated_at": "2026-01-05",
    "excerpt": "\n## Problem\nTraditional \"prompt-as-puppeteer\" workflows force humans to spell out every step, limiting scale and creativity."
  },
  {
    "title": "Versioned Constitution Governance",
    "status": "emerging",
    "authors": [
      "Nikola Balic (@nibzard)"
    ],
    "based_on": [
      "Hiveism (self-alignment loop)",
      "Anthropic (Constitutional AI)"
    ],
    "category": "Reliability & Eval",
    "source": "https://substack.com/home/post/p-161422949?utm_campaign=post&utm_medium=web",
    "tags": [
      "constitution",
      "alignment",
      "governance",
      "signed-commits",
      "policy"
    ],
    "id": "versioned-constitution-governance",
    "slug": "versioned-constitution-governance",
    "updated_at": "2026-01-05",
    "excerpt": "\n## Problem\nWhen an agent rewrites its own \"constitution,\" it may accidentally violate safety or regress on alignment objectives if changes aren't reviewed."
  },
  {
    "title": "Agent-Powered Codebase Q&A / Onboarding",
    "status": "validated-in-production",
    "authors": [
      "Nikola Balic (@nibzard)"
    ],
    "based_on": [
      "Lukas Möller (Cursor)",
      "Aman Sanger (Cursor)"
    ],
    "category": "Context & Memory",
    "source": "https://www.youtube.com/watch?v=BGgsoIgbT_Y",
    "tags": [
      "code-understanding",
      "onboarding",
      "q&a",
      "retrieval",
      "search",
      "context-awareness",
      "knowledge-base"
    ],
    "id": "agent-powered-codebase-qa-onboarding",
    "slug": "agent-powered-codebase-qa-onboarding",
    "updated_at": "2026-01-05",
    "excerpt": "\n## Problem\nUnderstanding a large or unfamiliar codebase can be a significant challenge for developers, especially when onboarding to a new project or trying to debug a complex system. Manually search"
  }
]