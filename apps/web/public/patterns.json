[
  {
    "title": "Reflection Loop",
    "status": "established",
    "authors": [
      "Nikola Balic (@nibzard)"
    ],
    "based_on": [
      "Shinn et al. (2023)"
    ],
    "category": "Feedback Loops",
    "source": "https://arxiv.org/abs/2303.11366",
    "tags": [
      "self-feedback",
      "iterative-improvement",
      "evaluation"
    ],
    "slug": "reflection",
    "id": "reflection-loop",
    "summary": "Generative models may produce subpar output if they never review or critique their own work.",
    "updated_at": "2026-01-05",
    "excerpt": "\n## Problem\nGenerative models may produce subpar output if they never review or critique their own work."
  },
  {
    "title": "Continuous Autonomous Task Loop Pattern",
    "status": "established",
    "authors": [
      "Nikola Balic (@nibzard)"
    ],
    "based_on": [
      "Internal Practice"
    ],
    "category": "Orchestration & Control",
    "source": "https://gist.github.com/nibzard/a97ef0a1919328bcbc6a224a5d2cfc78",
    "tags": [
      "autonomous-execution",
      "task-loop",
      "rate-limiting",
      "git-automation",
      "cli-driven",
      "stream-processing"
    ],
    "slug": "continuous-autonomous-task-loop-pattern",
    "id": "continuous-autonomous-task-loop-pattern",
    "summary": "Continuous autonomous loop that handles task selection, execution, and completion without human intervention, with intelligent rate limit handling and automated git management.",
    "updated_at": "2026-01-05",
    "excerpt": "\n## Problem"
  },
  {
    "title": "Tool Use Incentivization via Reward Shaping",
    "status": "emerging",
    "authors": [
      "Nikola Balic (@nibzard)"
    ],
    "based_on": [
      "Will Brown (Prime Intellect Talk)"
    ],
    "category": "Feedback Loops",
    "source": "https://www.youtube.com/watch?v=Xkwok_XXQgw",
    "tags": [
      "tool-use",
      "reward-shaping",
      "coding-agent",
      "RL"
    ],
    "slug": "tool-use-incentivization-via-reward-shaping",
    "id": "tool-use-incentivization-via-reward-shaping",
    "summary": "Provide dense, shaped rewards for every intermediate tool invocation to encourage coding agents to use compilers, linters, and test runners instead of relying solely on internal reasoning tokens.",
    "updated_at": "2026-01-05",
    "excerpt": "\n## Problem"
  },
  {
    "title": "Asynchronous Coding Agent Pipeline",
    "status": "proposed",
    "authors": [
      "Nikola Balic (@nibzard)"
    ],
    "based_on": [
      "Will Brown (Prime Intellect Talk)"
    ],
    "category": "Reliability & Eval",
    "source": "https://www.youtube.com/watch?v=Xkwok_XXQgw",
    "tags": [
      "asynchronous",
      "pipeline",
      "code-agent",
      "parallelism"
    ],
    "slug": "asynchronous-coding-agent-pipeline",
    "id": "asynchronous-coding-agent-pipeline",
    "summary": "Decouple inference, tool execution, and learning into parallel asynchronous components communicating via message queues to maximize GPU utilization and eliminate compute bubbles from synchronous tool calls.",
    "updated_at": "2026-01-05",
    "excerpt": "\n## Problem"
  },
  {
    "title": "Agent-Friendly Workflow Design",
    "status": "best-practice",
    "authors": [
      "Nikola Balic (@nibzard)"
    ],
    "based_on": [
      "Amjad Masad"
    ],
    "category": "UX & Collaboration",
    "source": "https://www.nibzard.com/silent-revolution",
    "tags": [
      "human-agent collaboration",
      "workflow design",
      "agent autonomy",
      "task decomposition",
      "HCI"
    ],
    "slug": "agent-friendly-workflow-design",
    "id": "agent-friendly-workflow-design",
    "summary": "Consciously design workflows with clear goals, appropriate autonomy, structured I/O, and feedback loops to maximize agent performance by aligning tasks with AI strengths.",
    "updated_at": "2026-01-05",
    "excerpt": "\n## Problem\nSimply providing an AI agent with a task is often not enough for optimal performance. If workflows are too rigid, or if humans micromanage the agent's technical decisions, the agent may st"
  },
  {
    "title": "Isolated VM per RL Rollout",
    "status": "emerging",
    "authors": [
      "Nikola Balic (@nibzard)"
    ],
    "based_on": [
      "Sam Pretty (Cognition)",
      "Devon Engineering Team"
    ],
    "category": "Security & Safety",
    "source": "https://youtu.be/1s_7RMG4O4U",
    "tags": [
      "isolation",
      "security",
      "reinforcement-learning",
      "infrastructure",
      "state-management",
      "agent-rft"
    ],
    "slug": "isolated-vm-per-rl-rollout",
    "id": "isolated-vm-per-rl-rollout",
    "summary": "Spin up an isolated virtual machine for each RL rollout to prevent cross-contamination between parallel agent executions, ensuring safe training with destructive tool access.",
    "updated_at": "2026-01-05",
    "excerpt": "\n## Problem"
  },
  {
    "title": "No-Token-Limit Magic",
    "status": "experimental-but-awesome",
    "authors": [
      "Nikola Balic (@nibzard)"
    ],
    "based_on": [
      "Thorsten Ball",
      "Quinn Slack"
    ],
    "category": "Reliability & Eval",
    "source": "https://www.nibzard.com/ampcode",
    "tags": [
      "performance",
      "cost",
      "experimentation"
    ],
    "slug": "no-token-limit-magic",
    "id": "no-token-limit-magic",
    "summary": "Aggressive prompt compression to save tokens stifles reasoning depth and self-correction.",
    "updated_at": "2026-01-05",
    "excerpt": "\n## Problem\nAggressive prompt compression to save tokens stifles reasoning depth and self-correction."
  },
  {
    "title": "Human-in-the-Loop Approval Framework",
    "status": "validated-in-production",
    "authors": [
      "Nikola Balic (@nibzard)"
    ],
    "based_on": [
      "Dexter Horthy (HumanLayer)"
    ],
    "category": "UX & Collaboration",
    "source": "https://claude.com/blog/building-companies-with-claude-code",
    "tags": [
      "human-oversight",
      "safety",
      "approvals",
      "risk-management",
      "collaboration",
      "slack-integration"
    ],
    "slug": "human-in-loop-approval-framework",
    "id": "human-in-the-loop-approval-framework",
    "summary": "Systematically insert human approval gates for designated high-risk functions while maintaining agent autonomy for safe operations, with multi-channel approval interfaces and comprehensive audit trails.",
    "updated_at": "2026-01-05",
    "excerpt": "\n## Problem"
  },
  {
    "title": "Stop Hook Auto-Continue Pattern",
    "status": "emerging",
    "authors": [
      "Nikola Balic (@nibzard)"
    ],
    "based_on": [
      "Boris Cherny (Anthropic)",
      "Claude Code Users"
    ],
    "category": "Orchestration & Control",
    "source": "https://every.to/podcast/transcript-how-to-use-claude-code-like-the-people-who-built-it",
    "tags": [
      "hooks",
      "automation",
      "testing",
      "determinism",
      "success-criteria",
      "continuous-execution"
    ],
    "slug": "stop-hook-auto-continue-pattern",
    "id": "stop-hook-auto-continue-pattern",
    "summary": "Use stop hooks to programmatically check success criteria after each agent turn, automatically continuing execution until the task is genuinely complete, enabling true task completion without manual intervention.",
    "updated_at": "2026-01-05",
    "excerpt": "\n## Problem"
  },
  {
    "title": "Structured Output Specification",
    "status": "established",
    "authors": [
      "Nikola Balic (@nibzard)"
    ],
    "based_on": [
      "Vercel AI Team"
    ],
    "category": "Reliability & Eval",
    "source": "https://vercel.com/blog/what-we-learned-building-agents-at-vercel",
    "tags": [
      "structured-output",
      "schema",
      "validation",
      "reliability",
      "type-safety",
      "integration"
    ],
    "slug": "structured-output-specification",
    "id": "structured-output-specification",
    "summary": "Constrain agent outputs using deterministic schemas that enforce structured, machine-readable results, enabling reliable validation, parsing, and integration with downstream systems.",
    "updated_at": "2026-01-05",
    "excerpt": "\n## Problem"
  },
  {
    "title": "Shell Command Contextualization",
    "status": "established",
    "authors": [
      "Nikola Balic (@nibzard)"
    ],
    "based_on": [
      "Boris Cherny (via Claude Code)"
    ],
    "category": "Tool Use & Environment",
    "source": "https://www.nibzard.com/claude-code",
    "tags": [
      "shell integration",
      "context management",
      "local execution",
      "bash",
      "cli",
      "interactive tools"
    ],
    "slug": "shell-command-contextualization",
    "id": "shell-command-contextualization",
    "summary": "Provide a mechanism (e.g., `!` prefix) to execute shell commands locally and automatically inject both the command and output into the agent's context for seamless integration.",
    "updated_at": "2026-01-05",
    "excerpt": "\n## Problem\nWhen an AI agent interacts with a local development environment, it often needs to execute shell commands (e.g., run linters, check git status, list files) and then use the output of these"
  },
  {
    "title": "Context-Minimization Pattern",
    "status": "emerging",
    "authors": [
      "Nikola Balic (@nibzard)"
    ],
    "based_on": [
      "Luca Beurer-Kellner et al. (2025)"
    ],
    "category": "Context & Memory",
    "source": "https://arxiv.org/abs/2506.08837",
    "tags": [
      "context-hygiene",
      "taint-removal",
      "prompt-injection"
    ],
    "slug": "context-minimization-pattern",
    "id": "context-minimization-pattern",
    "summary": "User-supplied or tainted text lingers in the conversation, enabling it to influence later generations.",
    "updated_at": "2026-01-05",
    "excerpt": "\n## Problem\nUser-supplied or tainted text lingers in the conversation, enabling it to influence later generations."
  },
  {
    "title": "Code Mode MCP Tool Interface Improvement Pattern",
    "status": "established",
    "authors": [
      "Nikola Balic (@nibzard)"
    ],
    "based_on": [
      "Cloudflare Team"
    ],
    "category": "Tool Use & Environment",
    "source": "https://blog.cloudflare.com/code-mode/",
    "tags": [
      "tool-interface",
      "code-generation",
      "sandboxing",
      "mcp",
      "mcp-improvement",
      "typescript",
      "v8-isolates",
      "token-optimization"
    ],
    "slug": "code-first-tool-interface-pattern",
    "id": "code-mode-mcp-tool-interface-improvement-pattern",
    "summary": "LLMs generate TypeScript code to orchestrate MCP tools in ephemeral V8 isolates, eliminating token-heavy round-trips and enabling efficient multi-step workflows with 10x+ token savings.",
    "updated_at": "2026-01-05",
    "excerpt": "\n## Problem"
  },
  {
    "title": "Filesystem-Based Agent State",
    "status": "established",
    "authors": [
      "Nikola Balic (@nibzard)"
    ],
    "based_on": [
      "Anthropic Engineering Team"
    ],
    "category": "Context & Memory",
    "source": "https://www.anthropic.com/engineering/code-execution-with-mcp",
    "tags": [
      "state-management",
      "persistence",
      "resumption",
      "long-running-tasks"
    ],
    "slug": "filesystem-based-agent-state",
    "id": "filesystem-based-agent-state",
    "summary": "Agents persist intermediate results and working state to files, creating durable checkpoints that enable workflow resumption, recovery from failures, and support for long-running tasks.",
    "updated_at": "2026-01-05",
    "excerpt": "\n## Problem"
  },
  {
    "title": "Anti-Reward-Hacking Grader Design",
    "status": "emerging",
    "authors": [
      "Nikola Balic (@nibzard)"
    ],
    "based_on": [
      "Rogo Engineering Team",
      "Will Brown (OpenAI)"
    ],
    "category": "Reliability & Eval",
    "source": "https://youtu.be/1s_7RMG4O4U",
    "tags": [
      "reward-hacking",
      "grading",
      "reinforcement-learning",
      "adversarial-robustness",
      "agent-rft"
    ],
    "slug": "anti-reward-hacking-grader-design",
    "id": "anti-reward-hacking-grader-design",
    "summary": "Design reward functions with multi-criteria evaluation and iterative hardening to prevent models from gaming graders, ensuring training rewards align with actual task quality.",
    "updated_at": "2026-01-05",
    "excerpt": "\n## Problem"
  },
  {
    "title": "Team-Shared Agent Configuration as Code",
    "status": "best-practice",
    "authors": [
      "Nikola Balic (@nibzard)"
    ],
    "based_on": [
      "Boris Cherny (Anthropic)",
      "Enterprise Claude Code Users"
    ],
    "category": "UX & Collaboration",
    "source": "https://every.to/podcast/transcript-how-to-use-claude-code-like-the-people-who-built-it",
    "tags": [
      "configuration",
      "version-control",
      "team-collaboration",
      "permissions",
      "consistency",
      "onboarding"
    ],
    "slug": "team-shared-agent-configuration",
    "id": "team-shared-agent-configuration-as-code",
    "summary": "Check agent configuration into version control as code, enabling consistent behavior across teams, faster onboarding, and collaborative improvement through PRs and code review.",
    "updated_at": "2026-01-05",
    "excerpt": "\n## Problem"
  },
  {
    "title": "Self-Critique Evaluator Loop",
    "status": "emerging",
    "authors": [
      "Nikola Balic (@nibzard)"
    ],
    "based_on": [
      "Meta AI (Self-Taught Evaluators)"
    ],
    "category": "Feedback Loops",
    "source": "https://arxiv.org/abs/2408.02666",
    "tags": [
      "self-critique",
      "evaluator",
      "reward-model",
      "synthetic-data"
    ],
    "slug": "self-critique-evaluator-loop",
    "id": "self-critique-evaluator-loop",
    "summary": "Human preference labels are costly and quickly become outdated as base models improve.",
    "updated_at": "2026-01-05",
    "excerpt": "\n## Problem\nHuman preference labels are costly and quickly become outdated as base models improve."
  },
  {
    "title": "CLI-Native Agent Orchestration",
    "status": "proposed",
    "authors": [
      "Nikola Balic (@nibzard)"
    ],
    "based_on": [
      "Jory Pestorious"
    ],
    "category": "Tool Use & Environment",
    "source": "http://jorypestorious.com/blog/ai-engineer-spec/",
    "tags": [
      "cli",
      "automation",
      "local-dev",
      "headless"
    ],
    "slug": "cli-native-agent-orchestration",
    "id": "cli-native-agent-orchestration",
    "summary": "Web chat UIs are awkward for repeat runs, local file edits, or scripting inside CI pipelines.",
    "updated_at": "2026-01-05",
    "excerpt": "\n## Problem\nWeb chat UIs are awkward for repeat runs, local file edits, or scripting inside CI pipelines."
  },
  {
    "title": "Democratization of Tooling via Agents",
    "status": "emerging",
    "authors": [
      "Nikola Balic (@nibzard)"
    ],
    "based_on": [
      "Jacob Jackson (Cursor)",
      "Alex Albert (Anthropic)"
    ],
    "category": "UX & Collaboration",
    "source": "https://www.youtube.com/watch?v=BGgsoIgbT_Y",
    "tags": [
      "no-code",
      "low-code",
      "citizen-developer",
      "tool-creation",
      "business-users",
      "automation",
      "custom-software"
    ],
    "slug": "democratization-of-tooling-via-agents",
    "id": "democratization-of-tooling-via-agents",
    "summary": "Empower non-technical users to create custom software tools and scripts using AI agents, lowering the barrier to software development and enabling domain experts to build their own productivity solutions.",
    "updated_at": "2026-01-05",
    "excerpt": "\n## Problem\nMany individuals in non-software engineering roles (e.g., sales, marketing, operations, communications) could benefit from custom software tools, scripts, or dashboards tailored to their s"
  },
  {
    "title": "Chain-of-Thought Monitoring & Interruption",
    "status": "emerging",
    "authors": [
      "Nikola Balic (@nibzard)"
    ],
    "based_on": [
      "Tanner Jones (Vulcan)"
    ],
    "category": "UX & Collaboration",
    "source": "https://claude.com/blog/building-companies-with-claude-code",
    "tags": [
      "monitoring",
      "intervention",
      "debugging",
      "reasoning",
      "ux"
    ],
    "slug": "chain-of-thought-monitoring-interruption",
    "id": "chain-of-thought-monitoring-interruption",
    "summary": "Implement active surveillance of agent reasoning with capability to interrupt and redirect before completing flawed execution sequences, preventing wasted time on fundamentally wrong approaches.",
    "updated_at": "2026-01-05",
    "excerpt": "\n## Problem"
  },
  {
    "title": "Swarm Migration Pattern",
    "status": "validated-in-production",
    "authors": [
      "Nikola Balic (@nibzard)"
    ],
    "based_on": [
      "Boris Cherny (Anthropic)",
      "Anthropic Internal Users"
    ],
    "category": "Orchestration & Control",
    "source": "https://every.to/podcast/transcript-how-to-use-claude-code-like-the-people-who-built-it",
    "tags": [
      "swarm",
      "map-reduce",
      "migration",
      "parallelization",
      "sub-agents",
      "scalability",
      "framework-migration"
    ],
    "slug": "swarm-migration-pattern",
    "id": "swarm-migration-pattern",
    "summary": "Main agent orchestrates 10+ parallel subagents working simultaneously on independent migration chunks, achieving 10x+ speedup for large-scale framework upgrades, lint rule rollouts, and API migrations.",
    "updated_at": "2026-01-05",
    "excerpt": "\n## Problem"
  },
  {
    "title": "Code-Then-Execute Pattern",
    "status": "emerging",
    "authors": [
      "Nikola Balic (@nibzard)"
    ],
    "based_on": [
      "DeepMind CaMeL (orig.)",
      "Luca Beurer-Kellner et al. (2025)"
    ],
    "category": "Tool Use & Environment",
    "source": "https://arxiv.org/abs/2506.08837",
    "tags": [
      "dsl",
      "sandbox",
      "program-synthesis",
      "auditability"
    ],
    "slug": "code-then-execute-pattern",
    "id": "code-then-execute-pattern",
    "summary": "Plan lists are opaque; we want full data-flow analysis and taint tracking.",
    "updated_at": "2026-01-05",
    "excerpt": "\n## Problem\nPlan lists are opaque; we want **full data-flow analysis** and taint tracking."
  },
  {
    "title": "Skill Library Evolution",
    "status": "established",
    "authors": [
      "Nikola Balic (@nibzard)"
    ],
    "based_on": [
      "Anthropic Engineering Team",
      "Will Larson (Imprint)",
      "Amp (Nicolay)"
    ],
    "category": "Learning & Adaptation",
    "source": "https://www.anthropic.com/engineering/code-execution-with-mcp",
    "tags": [
      "code-reuse",
      "skills",
      "learning",
      "capabilities",
      "evolution",
      "progressive-disclosure",
      "on-demand-loading",
      "mcp",
      "lazy-loading"
    ],
    "slug": "skill-library-evolution",
    "id": "skill-library-evolution",
    "summary": "Agents persist working code implementations as reusable skills that evolve into well-documented capabilities over time, building organizational knowledge and reducing redundant problem-solving across sessions.",
    "updated_at": "2026-01-13",
    "excerpt": "\n## Problem"
  },
  {
    "title": "LLM Map-Reduce Pattern",
    "status": "emerging",
    "authors": [
      "Nikola Balic (@nibzard)"
    ],
    "based_on": [
      "Luca Beurer-Kellner et al. (2025)"
    ],
    "category": "Orchestration & Control",
    "source": "https://arxiv.org/abs/2506.08837",
    "tags": [
      "map-reduce",
      "sub-agents",
      "isolation",
      "untrusted-data"
    ],
    "slug": "llm-map-reduce-pattern",
    "id": "llm-map-reduce-pattern",
    "summary": "Injecting a single poisoned document can manipulate global reasoning if all data is processed in one context.",
    "updated_at": "2026-01-05",
    "excerpt": "\n## Problem\nInjecting a single poisoned document can manipulate global reasoning if all data is processed in one context."
  },
  {
    "title": "Graph of Thoughts (GoT)",
    "status": "emerging",
    "authors": [
      "Nikola Balic (@nibzard)"
    ],
    "based_on": [
      "Besta et al.",
      "ETH Zurich"
    ],
    "category": "Feedback Loops",
    "source": "https://arxiv.org/abs/2308.09687",
    "tags": [
      "reasoning",
      "graph-based",
      "problem-solving",
      "thought-exploration",
      "backtracking",
      "aggregation"
    ],
    "slug": "graph-of-thoughts",
    "id": "graph-of-thoughts-got",
    "summary": "Extend reasoning frameworks by representing thoughts as a directed graph with nodes, edges, and arbitrary relationships, enabling complex operations like branching, aggregation, refinement, and looping for problems with interdependencies.",
    "updated_at": "2026-01-05",
    "excerpt": "\n## Problem"
  },
  {
    "title": "Context Window Anxiety Management",
    "status": "emerging",
    "authors": [
      "Nikola Balic (@nibzard)"
    ],
    "based_on": [
      "Cognition AI (2025)"
    ],
    "category": "Context & Memory",
    "source": "https://cognition.ai/blog/devin-sonnet-4-5-lessons-and-challenges",
    "tags": [
      "context-anxiety",
      "token-management",
      "premature-completion",
      "model-behavior"
    ],
    "slug": "context-window-anxiety-management",
    "id": "context-window-anxiety-management",
    "summary": "Models like Claude Sonnet 4.5 exhibit \"context anxiety\"—becoming aware of approaching context limits and proactively summarizing or closing tasks prematurely—manageable through strategic context budgeting and aggressive counter-prompting.",
    "updated_at": "2026-01-05",
    "excerpt": "\n## Problem\nModels like Claude Sonnet 4.5 exhibit \"context anxiety\"—they become aware of approaching context window limits and proactively summarize progress or make decisive moves to close tasks, eve"
  },
  {
    "title": "Multi-Platform Webhook Triggers",
    "status": "emerging",
    "authors": [
      "Nikola Balic (@nibzard)"
    ],
    "based_on": [
      "Will Larson (lethain.com)"
    ],
    "category": "Tool Use & Environment",
    "source": "https://lethain.com/agents-triggers/",
    "tags": [
      "webhooks",
      "triggers",
      "integrations",
      "slack",
      "notion",
      "jira",
      "scheduled-events",
      "event-driven"
    ],
    "slug": "multi-platform-webhook-triggers",
    "id": "multi-platform-webhook-triggers",
    "summary": "Implement multi-platform webhook triggers (Notion, Slack, Jira, reacji, scheduled events) to allow external SaaS tools to automatically initiate agent workflows, enabling low-friction, reactive automation from existing platforms.",
    "updated_at": "2026-01-13",
    "excerpt": "\n## Problem"
  },
  {
    "title": "Tree-of-Thought Reasoning",
    "status": "established",
    "authors": [
      "Nikola Balic (@nibzard)"
    ],
    "based_on": [
      "Yao et al. (2023)"
    ],
    "category": "Orchestration & Control",
    "source": "https://arxiv.org/abs/2305.10601",
    "tags": [
      "branching",
      "deliberate-reasoning",
      "search"
    ],
    "slug": "tree-of-thought-reasoning",
    "id": "tree-of-thought-reasoning",
    "summary": "Linear chain-of-thought reasoning can get stuck on complex problems, missing alternative approaches or failing to backtrack.",
    "updated_at": "2026-01-05",
    "excerpt": "\n## Problem\nLinear chain-of-thought reasoning can get stuck on complex problems, missing alternative approaches or failing to backtrack."
  },
  {
    "title": "Specification-Driven Agent Development",
    "status": "proposed",
    "authors": [
      "Nikola Balic (@nibzard)"
    ],
    "based_on": [
      "Jory Pestorious (AI Engineer World's Fair 2025)"
    ],
    "category": "Orchestration & Control",
    "source": "http://jorypestorious.com/blog/ai-engineer-spec/",
    "tags": [
      "spec-first",
      "scaffolding",
      "contract",
      "requirements"
    ],
    "slug": "specification-driven-agent-development",
    "id": "specification-driven-agent-development",
    "summary": "Hand-crafted prompts or loose user stories leave room for ambiguity; agents can wander, over-interpret, or produce code that conflicts with stakeholder intent.",
    "updated_at": "2026-01-05",
    "excerpt": "\n## Problem\nHand-crafted prompts or loose user stories leave room for ambiguity; agents can wander, over-interpret, or produce code that conflicts with stakeholder intent."
  },
  {
    "title": "Proactive Agent State Externalization",
    "status": "emerging",
    "authors": [
      "Nikola Balic (@nibzard)"
    ],
    "based_on": [
      "Cognition AI (2025)"
    ],
    "category": "Context & Memory",
    "source": "https://cognition.ai/blog/devin-sonnet-4-5-lessons-and-challenges",
    "tags": [
      "state-externalization",
      "memory-management",
      "self-documentation",
      "note-taking"
    ],
    "slug": "proactive-agent-state-externalization",
    "id": "proactive-agent-state-externalization",
    "summary": "Modern models like Claude Sonnet 4.5 proactively externalize state through self-generated notes—enhanced through guided frameworks, hybrid memory architecture, and progressive state building to capture decision rationale and knowledge gaps.",
    "updated_at": "2026-01-05",
    "excerpt": "\n## Problem\nModern models like Claude Sonnet 4.5 proactively attempt to externalize their state by writing summaries and notes (e.g., `CHANGELOG.md`, `SUMMARY.md`) to the file system without explicit "
  },
  {
    "title": "Initializer-Maintainer Dual Agent Architecture",
    "status": "emerging",
    "authors": [
      "Nikola Balic (@nibzard)"
    ],
    "based_on": [
      "Anthropic Engineering Team"
    ],
    "category": "Orchestration & Control",
    "source": "https://www.anthropic.com/engineering/effective-harnesses-for-long-running-agents",
    "tags": [
      "long-running-agents",
      "session-handoff",
      "lifecycle-specialization",
      "project-bootstrap",
      "incremental-development"
    ],
    "slug": "initializer-maintainer-dual-agent",
    "id": "initializer-maintainer-dual-agent-architecture",
    "summary": "Two-agent architecture with lifecycle-specialized responsibilities: Initializer creates comprehensive foundation once, Maintainer executes incremental development with session bootstrapping rituals to prevent context loss.",
    "updated_at": "2026-01-05",
    "excerpt": "\n## Problem"
  },
  {
    "title": "Spec-As-Test Feedback Loop",
    "status": "proposed",
    "authors": [
      "Nikola Balic (@nibzard)"
    ],
    "based_on": [
      "Jory Pestorious"
    ],
    "category": "Feedback Loops",
    "source": "http://jorypestorious.com/blog/ai-engineer-spec/",
    "tags": [
      "validation",
      "drift-detection",
      "continuous-testing"
    ],
    "slug": "spec-as-test-feedback-loop",
    "id": "spec-as-test-feedback-loop",
    "summary": "Even in spec-first projects, implementations can drift as code evolves and the spec changes (or vice-versa). Silent divergence erodes trust.",
    "updated_at": "2026-01-05",
    "excerpt": "\n## Problem\nEven in spec-first projects, implementations can drift as code evolves and the spec changes (or vice-versa). Silent divergence erodes trust."
  },
  {
    "title": "PII Tokenization",
    "status": "established",
    "authors": [
      "Nikola Balic (@nibzard)"
    ],
    "based_on": [
      "Anthropic Engineering Team"
    ],
    "category": "Security & Safety",
    "source": "https://www.anthropic.com/engineering/code-execution-with-mcp",
    "tags": [
      "privacy",
      "pii",
      "security",
      "mcp",
      "data-protection"
    ],
    "slug": "pii-tokenization",
    "id": "pii-tokenization",
    "summary": "Implement interception layer in MCP client that automatically tokenizes PII before reaching model and untokenizes for tool calls, enabling agents to orchestrate sensitive workflows without exposing raw data to LLM.",
    "updated_at": "2026-01-05",
    "excerpt": "\n## Problem"
  },
  {
    "title": "Oracle and Worker Multi-Model Approach",
    "status": "emerging",
    "authors": [
      "Nikola Balic (@nibzard)"
    ],
    "based_on": [
      "Sourcegraph Team"
    ],
    "category": "Orchestration & Control",
    "source": "https://youtu.be/hAEmt-FMyHA?si=6iKcGnTavdQlQKUZ",
    "tags": [
      "multi-model",
      "cost-optimization",
      "strategic-reasoning",
      "architecture"
    ],
    "slug": "oracle-and-worker-multi-model",
    "id": "oracle-and-worker-multi-model-approach",
    "summary": "Relying on a single AI model creates a trade-off between capability and cost. High-performance models are expensive for routine tasks, while cost-effective models may lack the reasoning power for complex problems.",
    "updated_at": "2026-01-05",
    "excerpt": "\n## Problem\nRelying on a single AI model creates a trade-off between capability and cost. High-performance models are expensive for routine tasks, while cost-effective models may lack the reasoning po"
  },
  {
    "title": "Curated Code Context Window",
    "status": "validated-in-production",
    "authors": [
      "Nikola Balic (@nibzard)"
    ],
    "based_on": [
      "Anonymous Speaker (Open Source Agent RL Talk)",
      "Will Brown (Prime Intellect Talk)",
      "Thorsten Ball"
    ],
    "category": "Context & Memory",
    "source": "https://www.youtube.com/watch?v=Xkwok_XXQgw",
    "tags": [
      "context-management",
      "code-agent",
      "file-selection",
      "noise-reduction"
    ],
    "slug": "curated-code-context-window",
    "id": "curated-code-context-window",
    "summary": "Maintain minimal, high-signal code context using search subagents to identify and inject only relevant modules, preventing model overwhelm, reducing token usage, and improving reasoning clarity by excluding unrelated code.",
    "updated_at": "2026-01-05",
    "excerpt": "\n## Problem"
  },
  {
    "title": "CLI-First Skill Design",
    "status": "emerging",
    "authors": [
      "Lucas Carlson"
    ],
    "based_on": [
      "Anthropic (Claude Code)",
      "Unix Philosophy"
    ],
    "category": "Tool Use & Environment",
    "source": "https://github.com/anthropics/claude-code",
    "tags": [
      "cli",
      "skills",
      "shell",
      "dual-use",
      "composability",
      "unix-philosophy"
    ],
    "slug": "cli-first-skill-design",
    "id": "cli-first-skill-design",
    "summary": "Design all skills as CLI tools first for dual-use by humans and agents, enabling manual debugging, programmatic invocation, composition with Unix tools, and transparent shell-based execution without building separate interfaces.",
    "updated_at": "2026-01-05",
    "excerpt": "\n## Problem"
  },
  {
    "title": "Progressive Complexity Escalation",
    "status": "emerging",
    "authors": [
      "Nikola Balic (@nibzard)"
    ],
    "based_on": [
      "Vercel AI Team"
    ],
    "category": "Orchestration & Control",
    "source": "https://vercel.com/blog/what-we-learned-building-agents-at-vercel",
    "tags": [
      "capabilities",
      "gradual-rollout",
      "risk-management",
      "evolution",
      "adaptive-systems",
      "complexity-management"
    ],
    "slug": "progressive-complexity-escalation",
    "id": "progressive-complexity-escalation",
    "summary": "Start agents with low-complexity, high-reliability tasks and progressively unlock more complex capabilities as models improve and trust is established, matching task complexity to current model capabilities for risk mitigation.",
    "updated_at": "2026-01-05",
    "excerpt": "\n## Problem"
  },
  {
    "title": "Conditional Parallel Tool Execution",
    "status": "validated-in-production",
    "authors": [
      "Nikola Balic (@nibzard)"
    ],
    "based_on": [
      "Gerred Dillon ('Building an Agentic System')"
    ],
    "category": "Orchestration & Control",
    "source": "https://gerred.github.io/building-an-agentic-system/parallel-tool-execution.html",
    "tags": [
      "parallel execution",
      "tool orchestration",
      "read-only tools",
      "stateful tools",
      "agent efficiency",
      "agent safety",
      "concurrency control",
      "task scheduling"
    ],
    "slug": "parallel-tool-execution",
    "id": "conditional-parallel-tool-execution",
    "summary": "Execute read-only tools concurrently for speed while serializing state-modifying tools for safety, balancing performance optimization with race condition prevention through intelligent tool classification and orchestration.",
    "updated_at": "2026-01-05",
    "excerpt": "\n## Problem"
  },
  {
    "title": "LLM Observability",
    "status": "proposed",
    "authors": [
      "Nikola Balic (@nibzard)"
    ],
    "based_on": [
      "Will Larson (Imprint)"
    ],
    "category": "Reliability & Eval",
    "source": "https://lethain.com/agents-logging/",
    "tags": [
      "observability",
      "logging",
      "debugging",
      "tracing",
      "datadog",
      "langsmith",
      "spans",
      "monitoring",
      "llmops"
    ],
    "slug": "llm-observability",
    "id": "llm-observability",
    "summary": "Integrate LLM observability platforms for span-level tracing of agent workflows, providing visual UI debugging, workflow linking, and aggregate metrics to enable fast navigation of complex multi-step executions.",
    "updated_at": "2026-01-13",
    "excerpt": "\n## Problem"
  },
  {
    "title": "Multi-Platform Communication Aggregation",
    "status": "emerging",
    "authors": [
      "Lucas Carlson"
    ],
    "based_on": [
      "Anthropic (Claude Code)"
    ],
    "category": "Tool Use & Environment",
    "source": "https://github.com/anthropics/claude-code",
    "tags": [
      "search",
      "aggregation",
      "parallel",
      "communication",
      "unified-interface"
    ],
    "slug": "multi-platform-communication-aggregation",
    "id": "multi-platform-communication-aggregation",
    "summary": "Create unified search interface that queries all communication platforms in parallel and aggregates results into consistent format, enabling single-query cross-platform search with minimal latency through parallel execution.",
    "updated_at": "2026-01-05",
    "excerpt": "\n## Problem"
  },
  {
    "title": "Code-Over-API Pattern",
    "status": "established",
    "authors": [
      "Nikola Balic (@nibzard)"
    ],
    "based_on": [
      "Anthropic Engineering Team"
    ],
    "category": "Tool Use & Environment",
    "source": "https://www.anthropic.com/engineering/code-execution-with-mcp",
    "tags": [
      "token-optimization",
      "code-execution",
      "data-processing",
      "mcp"
    ],
    "slug": "code-over-api-pattern",
    "id": "code-over-api-pattern",
    "summary": "Agents write and execute code that processes data in execution environment instead of making direct API calls, dramatically reducing token consumption by keeping intermediate data out of context window (150K → 2K tokens).",
    "updated_at": "2026-01-05",
    "excerpt": "\n## Problem"
  },
  {
    "title": "Agent Reinforcement Fine-Tuning (Agent RFT)",
    "status": "emerging",
    "authors": [
      "Nikola Balic (@nibzard)"
    ],
    "based_on": [
      "Will Brown (OpenAI)",
      "Theo (OpenAI Solutions Architect)"
    ],
    "category": "Learning & Adaptation",
    "source": "https://youtu.be/1s_7RMG4O4U",
    "tags": [
      "reinforcement-learning",
      "fine-tuning",
      "tool-use",
      "multi-step-rl",
      "agent-training",
      "exploration"
    ],
    "slug": "agent-reinforcement-fine-tuning",
    "id": "agent-reinforcement-fine-tuning-agent-rft",
    "summary": "Train model weights end-to-end on agentic tasks via reinforcement learning with real tool calls and custom reward signals, optimizing for domain-specific tool use efficiency and multi-step reasoning performance.",
    "updated_at": "2026-01-05",
    "excerpt": "\n## Problem"
  },
  {
    "title": "Merged Code + Language Skill Model",
    "status": "emerging",
    "authors": [
      "Nikola Balic (@nibzard)"
    ],
    "based_on": [
      "Anonymous Speaker (Open Source Agent RL Talk)",
      "Will Brown (Prime Intellect Talk)"
    ],
    "category": "Reliability & Eval",
    "source": "https://www.youtube.com/watch?v=Xkwok_XXQgw",
    "tags": [
      "model-merging",
      "transfer-learning",
      "coding-agent",
      "multilingual"
    ],
    "slug": "merged-code-language-skill-model",
    "id": "merged-code-language-skill-model",
    "summary": "Decentralized training with model merging—train language and code specialists independently then combine via weight averaging—enabling parallel R&D without massive centralized compute while preserving both skill sets.",
    "updated_at": "2026-01-05",
    "excerpt": "\n## Problem"
  },
  {
    "title": "Hybrid LLM/Code Workflow Coordinator",
    "status": "proposed",
    "authors": [
      "Nikola Balic (@nibzard)"
    ],
    "based_on": [
      "Will Larson (Imprint)"
    ],
    "category": "Orchestration & Control",
    "source": "https://lethain.com/agents-coordinators/",
    "tags": [
      "hybrid",
      "llm-driven",
      "code-driven",
      "coordinator",
      "determinism",
      "workflow-orchestration",
      "progressive-enhancement"
    ],
    "slug": "hybrid-llm-code-workflow-coordinator",
    "id": "hybrid-llmcode-workflow-coordinator",
    "summary": "Configurable coordinator supporting both LLM-driven (flexible, fast iteration) and code-driven (deterministic, code review) workflows, enabling progressive enhancement from prototype to production-ready systems.",
    "updated_at": "2026-01-13",
    "excerpt": "\n## Problem"
  },
  {
    "title": "Agent-Driven Research",
    "status": "established",
    "authors": [
      "Nikola Balic (@nibzard)"
    ],
    "based_on": [
      "Danny Tarlow",
      "Connie Fan"
    ],
    "category": "Orchestration & Control",
    "source": "https://www.youtube.com/watch?v=u85G2aV_5rQ",
    "tags": [
      "research",
      "information retrieval",
      "tool use",
      "iterative process",
      "autonomous search"
    ],
    "slug": "agent-driven-research",
    "id": "agent-driven-research",
    "summary": "## Problem\nTraditional research methods often lack the ability to adapt search strategies based on emerging results, limiting efficiency and potential discoveries.",
    "updated_at": "2026-01-05",
    "excerpt": "\n## Problem\nTraditional research methods often lack the ability to adapt search strategies based on emerging results, limiting efficiency and potential discoveries."
  },
  {
    "title": "Disposable Scaffolding Over Durable Features",
    "status": "best-practice",
    "authors": [
      "Nikola Balic (@nibzard)"
    ],
    "based_on": [
      "Thorsten Ball (Sourcegraph)"
    ],
    "category": "Orchestration & Control",
    "source": "https://www.sourcegraph.com",
    "tags": [
      "bitter-lesson",
      "temporary-tooling",
      "model-centric",
      "adaptability",
      "future-proofing"
    ],
    "slug": "disposable-scaffolding-over-durable-features",
    "id": "disposable-scaffolding-over-durable-features",
    "summary": "Treat most code around models as temporary, lightweight scaffolding rather than durable features, prioritizing speed and adaptability to avoid over-engineering solutions that next model generations may render obsolete.",
    "updated_at": "2026-01-05",
    "excerpt": "\n## Problem"
  },
  {
    "title": "Egress Lockdown (No-Exfiltration Channel)",
    "status": "established",
    "authors": [
      "Nikola Balic (@nibzard)"
    ],
    "based_on": [
      "Simon Willison (observation)",
      "Multiple vendor incident reports"
    ],
    "category": "Tool Use & Environment",
    "source": "https://simonwillison.net/2025/Jun/16/lethal-trifecta/",
    "tags": [
      "network-sandbox",
      "exfiltration",
      "outbound-controls",
      "security"
    ],
    "slug": "egress-lockdown-no-exfiltration-channel",
    "id": "egress-lockdown-no-exfiltration-channel",
    "summary": "Even with private-data access and untrusted inputs, attacks fail if the agent has no way to transmit stolen data—implement egress firewall allowing only specific domains while filtering or stripping outbound content.",
    "updated_at": "2026-01-05",
    "excerpt": "\n## Problem\nEven with private-data access and untrusted inputs, attacks fail if the agent has **no way to transmit stolen data**. Many real-world fixes simply removed or filtered outbound channels."
  },
  {
    "title": "Compounding Engineering Pattern",
    "status": "emerging",
    "authors": [
      "Nikola Balic (@nibzard)"
    ],
    "based_on": [
      "Dan Shipper (Every)",
      "Every Engineering Team"
    ],
    "category": "Learning & Adaptation",
    "source": "https://every.to/podcast/transcript-how-to-use-claude-code-like-the-people-who-built-it",
    "tags": [
      "learning",
      "feedback-loops",
      "codification",
      "prompts",
      "slash-commands",
      "onboarding",
      "knowledge-sharing"
    ],
    "slug": "compounding-engineering-pattern",
    "id": "compounding-engineering-pattern",
    "summary": "Codify all learnings from each feature into reusable prompts, slash commands, subagents, and hooks—making each feature easier to build by creating increasingly \"self-teaching\" codebase that accelerates productivity over time.",
    "updated_at": "2026-01-05",
    "excerpt": "\n## Problem"
  },
  {
    "title": "Visual AI Multimodal Integration",
    "status": "emerging",
    "authors": [
      "Nikola Balic (@nibzard)"
    ],
    "based_on": [
      "Andrew Ng",
      "OpenAI",
      "Anthropic",
      "Google"
    ],
    "category": "Tool Use & Environment",
    "source": "https://openai.com/research/gpt-4v-system-card",
    "tags": [
      "multimodal",
      "vision",
      "video",
      "image-processing",
      "visual-understanding",
      "agent-capabilities"
    ],
    "slug": "visual-ai-multimodal-integration",
    "id": "visual-ai-multimodal-integration",
    "summary": "Integrate large multimodal models for visual understanding—enabling agents to process images, videos, screenshots alongside text for tasks like UI debugging, document processing, video analysis, and security monitoring.",
    "updated_at": "2026-01-05",
    "excerpt": "\n## Problem"
  },
  {
    "title": "Deterministic Security Scanning Build Loop",
    "status": "proposed",
    "authors": [
      "Nikola Balic (@nibzard)"
    ],
    "based_on": [
      "Geoffrey Huntley"
    ],
    "category": "Security & Safety",
    "source": "https://ghuntley.com/secure-codegen/",
    "tags": [
      "security",
      "deterministic",
      "build-loop",
      "backpressure",
      "static-analysis"
    ],
    "slug": "deterministic-security-scanning-build-loop",
    "id": "deterministic-security-scanning-build-loop",
    "summary": "Implement deterministic security validation through build loop with two-phase approach: non-deterministic generation followed by deterministic backpressure from integrated SAST/DAST tools that must pass before code completion.",
    "updated_at": "2026-01-05",
    "excerpt": "\n## Problem"
  },
  {
    "title": "Action-Selector Pattern",
    "status": "emerging",
    "authors": [
      "Nikola Balic (@nibzard)"
    ],
    "based_on": [
      "Luca Beurer-Kellner et al. (2025)"
    ],
    "category": "Orchestration & Control",
    "source": "https://arxiv.org/abs/2506.08837",
    "tags": [
      "prompt-injection",
      "control-flow",
      "safety",
      "tool-use"
    ],
    "slug": "action-selector-pattern",
    "id": "action-selector-pattern",
    "summary": "## Problem\nUntrusted input can hijack an agent's reasoning once tool feedback re-enters the context window, leading to arbitrary, harmful actions.",
    "updated_at": "2026-01-05",
    "excerpt": "\n## Problem\nUntrusted input can hijack an agent's reasoning once tool feedback re-enters the context window, leading to arbitrary, harmful actions."
  },
  {
    "title": "Workflow Evals with Mocked Tools",
    "status": "emerging",
    "authors": [
      "Nikola Balic (@nibzard)"
    ],
    "based_on": [
      "Will Larson (lethain.com)",
      "Sierra (chat/voice platform)"
    ],
    "category": "Reliability & Eval",
    "source": "https://lethain.com/agents-evals/",
    "tags": [
      "evals",
      "testing",
      "ci-cd",
      "mocked-tools",
      "simulations",
      "workflow-validation",
      "end-to-end-testing"
    ],
    "slug": "workflow-evals-with-mocked-tools",
    "id": "workflow-evals-with-mocked-tools",
    "summary": "TODO: Add a concise summary for \"Workflow Evals with Mocked Tools\" describing the pattern's purpose and key benefits.",
    "updated_at": "2026-01-13",
    "excerpt": "\n## Problem"
  },
  {
    "title": "Memory Synthesis from Execution Logs",
    "status": "emerging",
    "authors": [
      "Nikola Balic (@nibzard)"
    ],
    "based_on": [
      "Anthropic Internal Users",
      "Claude Code Team"
    ],
    "category": "Context & Memory",
    "source": "https://every.to/podcast/transcript-how-to-use-claude-code-like-the-people-who-built-it",
    "tags": [
      "memory",
      "logs",
      "diary",
      "synthesis",
      "pattern-detection",
      "knowledge-extraction",
      "learning"
    ],
    "slug": "memory-synthesis-from-execution-logs",
    "id": "memory-synthesis-from-execution-logs",
    "summary": "TODO: Add a concise summary for \"Memory Synthesis from Execution Logs\" describing the pattern's purpose and key benefits.",
    "updated_at": "2026-01-05",
    "excerpt": "\n## Problem"
  },
  {
    "title": "Lethal Trifecta Threat Model",
    "status": "best-practice",
    "authors": [
      "Nikola Balic (@nibzard)"
    ],
    "based_on": [
      "Simon Willison"
    ],
    "category": "Reliability & Eval",
    "source": "https://simonwillison.net/2025/Jun/16/lethal-trifecta/",
    "tags": [
      "security",
      "prompt-injection",
      "threat-model",
      "data-exfiltration"
    ],
    "slug": "lethal-trifecta-threat-model",
    "id": "lethal-trifecta-threat-model",
    "summary": "Combining three agent capabilities—access to private data, exposure to untrusted content, and ability to externally communicate—creates a straightforward path for prompt-injection attackers to steal sensitive information.",
    "updated_at": "2026-01-05",
    "excerpt": "\n## Problem\nCombining three agent capabilities—\n1. **Access to private data**\n2. **Exposure to untrusted content**\n3. **Ability to externally communicate**"
  },
  {
    "title": "Multi-Model Orchestration for Complex Edits",
    "status": "validated-in-production",
    "authors": [
      "Nikola Balic (@nibzard)"
    ],
    "based_on": [
      "Aman Sanger (Cursor)"
    ],
    "category": "Orchestration & Control",
    "source": "https://www.youtube.com/watch?v=BGgsoIgbT_Y",
    "tags": [
      "multi-model",
      "code-generation",
      "code-editing",
      "retrieval",
      "pipeline",
      "complex-tasks"
    ],
    "slug": "multi-model-orchestration-for-complex-edits",
    "id": "multi-model-orchestration-for-complex-edits",
    "summary": "TODO: Add a concise summary for \"Multi-Model Orchestration for Complex Edits\" describing the pattern's purpose and key benefits.",
    "updated_at": "2026-01-05",
    "excerpt": "\n## Problem\nA single large language model, even if powerful, may not be optimally suited for all sub-tasks involved in a complex operation like multi-file code editing. Tasks such as understanding bro"
  },
  {
    "title": "Inference-Healed Code Review Reward",
    "status": "proposed",
    "authors": [
      "Nikola Balic (@nibzard)"
    ],
    "based_on": [
      "Anonymous Speaker (Open Source Agent RL Talk)",
      "Will Brown (Prime Intellect Talk)"
    ],
    "category": "Feedback Loops",
    "source": "https://www.youtube.com/watch?v=Xkwok_XXQgw",
    "tags": [
      "reward-modeling",
      "code-review",
      "inference-healing",
      "quality-assessment"
    ],
    "slug": "inference-healed-code-review-reward",
    "id": "inference-healed-code-review-reward",
    "summary": "TODO: Add a concise summary for \"Inference-Healed Code Review Reward\" describing the pattern's purpose and key benefits.",
    "updated_at": "2026-01-05",
    "excerpt": "\n## Problem"
  },
  {
    "title": "Iterative Multi-Agent Brainstorming",
    "status": "experimental-but-awesome",
    "authors": [
      "Nikola Balic (@nibzard)"
    ],
    "based_on": [
      "Boris Cherny (via Claude Code capability)"
    ],
    "category": "Orchestration & Control",
    "source": "https://www.nibzard.com/claude-code",
    "tags": [
      "multi-agent",
      "brainstorming",
      "parallel processing",
      "idea generation",
      "sub-agents",
      "collaborative ideation"
    ],
    "slug": "iterative-multi-agent-brainstorming",
    "id": "iterative-multi-agent-brainstorming",
    "summary": "## Problem\nFor complex problems or creative ideation, a single AI agent instance might get stuck in a local optimum or fail to explore a diverse range of solutions. Generating a breadth of ideas can be challenging for a sequential, monolithic process.",
    "updated_at": "2026-01-05",
    "excerpt": "\n## Problem\nFor complex problems or creative ideation, a single AI agent instance might get stuck in a local optimum or fail to explore a diverse range of solutions. Generating a breadth of ideas can "
  },
  {
    "title": "Variance-Based RL Sample Selection",
    "status": "emerging",
    "authors": [
      "Nikola Balic (@nibzard)"
    ],
    "based_on": [
      "Theo (OpenAI Solutions Architect)",
      "Prashant (OpenAI RFT Team)"
    ],
    "category": "Learning & Adaptation",
    "source": "https://youtu.be/1s_7RMG4O4U",
    "tags": [
      "reinforcement-learning",
      "sample-efficiency",
      "variance",
      "data-quality",
      "agent-rft"
    ],
    "slug": "variance-based-rl-sample-selection",
    "id": "variance-based-rl-sample-selection",
    "summary": "TODO: Add a concise summary for \"Variance-Based RL Sample Selection\" describing the pattern's purpose and key benefits.",
    "updated_at": "2026-01-05",
    "excerpt": "\n## Problem"
  },
  {
    "title": "Tool Use Steering via Prompting",
    "status": "best-practice",
    "authors": [
      "Nikola Balic (@nibzard)"
    ],
    "based_on": [
      "Boris Cherny (via Claude Code examples)"
    ],
    "category": "Tool Use & Environment",
    "source": "https://www.nibzard.com/claude-code",
    "tags": [
      "tool use",
      "prompting",
      "agent guidance",
      "custom tools",
      "cli",
      "natural language control"
    ],
    "slug": "tool-use-steering-via-prompting",
    "id": "tool-use-steering-via-prompting",
    "summary": "TODO: Add a concise summary for \"Tool Use Steering via Prompting\" describing the pattern's purpose and key benefits.",
    "updated_at": "2026-01-05",
    "excerpt": "\n## Problem\nAI agents equipped with multiple tools (e.g., shell access, file system operations, web search, custom CLIs) need clear guidance on when, why, and how to use these tools effectively. Simpl"
  },
  {
    "title": "Dogfooding with Rapid Iteration for Agent Improvement",
    "status": "best-practice",
    "authors": [
      "Nikola Balic (@nibzard)"
    ],
    "based_on": [
      "Lukas Möller (Cursor)",
      "Aman Sanger (Cursor)"
    ],
    "category": "Feedback Loops",
    "source": "https://www.youtube.com/watch?v=BGgsoIgbT_Y",
    "tags": [
      "dogfooding",
      "iterative-development",
      "feedback-loop",
      "agent-improvement",
      "internal-testing",
      "product-development"
    ],
    "slug": "dogfooding-with-rapid-iteration-for-agent-improvement",
    "id": "dogfooding-with-rapid-iteration-for-agent-improvement",
    "summary": "## Problem\nDeveloping effective AI agents requires understanding real-world usage and quickly identifying areas for improvement. External feedback loops can be slow, and simulated environments may not capture all nuances.",
    "updated_at": "2026-01-05",
    "excerpt": "\n## Problem\nDeveloping effective AI agents requires understanding real-world usage and quickly identifying areas for improvement. External feedback loops can be slow, and simulated environments may no"
  },
  {
    "title": "Autonomous Workflow Agent Architecture",
    "status": "established",
    "authors": [
      "Nikola Balic (@nibzard)"
    ],
    "based_on": [
      "Together AI Team"
    ],
    "category": "Orchestration & Control",
    "source": "https://www.together.ai/blog/ai-agents-to-automate-complex-engineering-tasks",
    "tags": [
      "workflow-automation",
      "containerization",
      "multi-agent",
      "engineering-tasks",
      "tmux",
      "error-recovery"
    ],
    "slug": "autonomous-workflow-agent-architecture",
    "id": "autonomous-workflow-agent-architecture",
    "summary": "TODO: Add a concise summary for \"Autonomous Workflow Agent Architecture\" describing the pattern's purpose and key benefits.",
    "updated_at": "2026-01-05",
    "excerpt": "\n## Problem"
  },
  {
    "title": "Memory Reinforcement Learning (MemRL)",
    "status": "proposed",
    "authors": [
      "Nikola Balic (@nibzard)"
    ],
    "based_on": [
      "Shengtao Zhang, Jiaqian Wang, et al. (Shanghai Jiao Tong University, Xidian University, MemTensor)"
    ],
    "category": "Learning & Adaptation",
    "source": "https://arxiv.org/html/2601.03192v1",
    "tags": [
      "reinforcement-learning",
      "episodic-memory",
      "self-evolution",
      "value-aware-retrieval",
      "runtime-learning",
      "stability-plasticity"
    ],
    "slug": "memory-reinforcement-learning-memrl",
    "id": "memory-reinforcement-learning-memrl",
    "summary": "TODO: Add a concise summary for \"Memory Reinforcement Learning (MemRL)\" describing the pattern's purpose and key benefits.",
    "updated_at": "2026-01-13",
    "excerpt": "\n## Problem"
  },
  {
    "title": "Spectrum of Control / Blended Initiative",
    "status": "validated-in-production",
    "authors": [
      "Nikola Balic (@nibzard)"
    ],
    "based_on": [
      "Aman Sanger (Cursor)"
    ],
    "category": "UX & Collaboration",
    "source": "https://www.youtube.com/watch?v=BGgsoIgbT_Y",
    "tags": [
      "human-agent-collaboration",
      "autonomy-spectrum",
      "interactive-control",
      "task-delegation",
      "code-editing",
      "ide-integration"
    ],
    "slug": "spectrum-of-control-blended-initiative",
    "id": "spectrum-of-control-blended-initiative",
    "summary": "Design human-agent interaction supporting autonomy spectrum from tab completion (low) to background agents creating entire PRs (high), enabling seamless switching between direct control and task delegation based on complexity and user familiarity.",
    "updated_at": "2026-01-05",
    "excerpt": "\n## Problem\nAI agents for tasks like coding can offer various levels of assistance, from simple completions to complex, multi-step operations. A one-size-fits-all approach to agent autonomy doesn't ca"
  },
  {
    "title": "AI-Assisted Code Review / Verification",
    "status": "emerging",
    "authors": [
      "Nikola Balic (@nibzard)"
    ],
    "based_on": [
      "Aman Sanger (Cursor)"
    ],
    "category": "Feedback Loops",
    "source": "https://www.youtube.com/watch?v=BGgsoIgbT_Y",
    "tags": [
      "code-review",
      "verification",
      "quality-assurance",
      "human-ai-collaboration",
      "trust",
      "explainability",
      "software-quality"
    ],
    "slug": "ai-assisted-code-review-verification",
    "id": "ai-assisted-code-review-verification",
    "summary": "TODO: Add a concise summary for \"AI-Assisted Code Review / Verification\" describing the pattern's purpose and key benefits.",
    "updated_at": "2026-01-05",
    "excerpt": "\n## Problem\nAs AI models generate increasing amounts of code, the bottleneck in software development shifts from code generation to code verification and review. Ensuring that AI-generated code is not"
  },
  {
    "title": "CriticGPT-Style Code Review",
    "status": "validated-in-production",
    "authors": [
      "Nikola Balic (@nibzard)"
    ],
    "based_on": [
      "OpenAI"
    ],
    "category": "Reliability & Eval",
    "source": "https://openai.com/research/criticgpt",
    "tags": [
      "evaluation",
      "code-review",
      "critique",
      "quality-assurance",
      "bug-detection",
      "gpt-4"
    ],
    "slug": "criticgpt-style-evaluation",
    "id": "criticgpt-style-code-review",
    "summary": "TODO: Add a concise summary for \"CriticGPT-Style Code Review\" describing the pattern's purpose and key benefits.",
    "updated_at": "2026-01-05",
    "excerpt": "\n## Problem"
  },
  {
    "title": "Coding Agent CI Feedback Loop",
    "status": "best-practice",
    "authors": [
      "Nikola Balic (@nibzard)"
    ],
    "based_on": [
      "Quinn Slack (Concept)",
      "Will Brown (Prime Intellect Talk)"
    ],
    "category": "Feedback Loops",
    "source": "https://www.youtube.com/watch?v=Xkwok_XXQgw",
    "tags": [
      "CI",
      "coding-agent",
      "asynchronous",
      "test-driven",
      "feedback"
    ],
    "slug": "coding-agent-ci-feedback-loop",
    "id": "coding-agent-ci-feedback-loop",
    "summary": "TODO: Add a concise summary for \"Coding Agent CI Feedback Loop\" describing the pattern's purpose and key benefits.",
    "updated_at": "2026-01-05",
    "excerpt": "\n## Problem"
  },
  {
    "title": "RLAIF (Reinforcement Learning from AI Feedback)",
    "status": "emerging",
    "authors": [
      "Nikola Balic (@nibzard)"
    ],
    "based_on": [
      "Anthropic",
      "Google DeepMind"
    ],
    "category": "Reliability & Eval",
    "source": "https://arxiv.org/abs/2212.08073",
    "tags": [
      "rlhf",
      "rlaif",
      "constitutional-ai",
      "synthetic-data",
      "feedback",
      "alignment",
      "evaluation"
    ],
    "slug": "rlaif-reinforcement-learning-from-ai-feedback",
    "id": "rlaif-reinforcement-learning-from-ai-feedback",
    "summary": "TODO: Add a concise summary for \"RLAIF (Reinforcement Learning from AI Feedback)\" describing the pattern's purpose and key benefits.",
    "updated_at": "2026-01-05",
    "excerpt": "\n## Problem"
  },
  {
    "title": "Self-Rewriting Meta-Prompt Loop",
    "status": "emerging",
    "authors": [
      "Nikola Balic (@nibzard)"
    ],
    "based_on": [
      "Noah D. Goodman (Meta-Prompt)"
    ],
    "category": "Orchestration & Control",
    "source": "https://noahgoodman.substack.com/p/meta-prompt-a-simple-self-improving",
    "tags": [
      "meta-prompting",
      "self-improvement",
      "system-prompt",
      "reflection"
    ],
    "slug": "self-rewriting-meta-prompt-loop",
    "id": "self-rewriting-meta-prompt-loop",
    "summary": "Static system prompts become stale or overly brittle as an agent encounters new tasks and edge-cases. Manually editing them is slow and error-prone.",
    "updated_at": "2026-01-05",
    "excerpt": "\n## Problem\nStatic system prompts become stale or overly brittle as an agent encounters new tasks and edge-cases. Manually editing them is slow and error-prone."
  },
  {
    "title": "Proactive Trigger Vocabulary",
    "status": "emerging",
    "authors": [
      "Lucas Carlson"
    ],
    "based_on": [
      "Anthropic (Claude Code)"
    ],
    "category": "UX & Collaboration",
    "source": "https://github.com/anthropics/claude-code",
    "tags": [
      "ux",
      "triggers",
      "intent-detection",
      "skill-routing",
      "natural-language"
    ],
    "slug": "proactive-trigger-vocabulary",
    "id": "proactive-trigger-vocabulary",
    "summary": "TODO: Add a concise summary for \"Proactive Trigger Vocabulary\" describing the pattern's purpose and key benefits.",
    "updated_at": "2026-01-05",
    "excerpt": "\n## Problem"
  },
  {
    "title": "Progressive Autonomy with Model Evolution",
    "status": "best-practice",
    "authors": [
      "Nikola Balic (@nibzard)"
    ],
    "based_on": [
      "Boris Cherny (Anthropic)",
      "Claude Code Team"
    ],
    "category": "Orchestration & Control",
    "source": "https://every.to/podcast/transcript-how-to-use-claude-code-like-the-people-who-built-it",
    "tags": [
      "model-evolution",
      "scaffolding",
      "autonomy",
      "system-prompts",
      "capabilities",
      "model-intelligence"
    ],
    "slug": "progressive-autonomy-with-model-evolution",
    "id": "progressive-autonomy-with-model-evolution",
    "summary": "TODO: Add a concise summary for \"Progressive Autonomy with Model Evolution\" describing the pattern's purpose and key benefits.",
    "updated_at": "2026-01-05",
    "excerpt": "\n## Problem"
  },
  {
    "title": "Agent-First Tooling and Logging",
    "status": "emerging",
    "authors": [
      "Nikola Balic (@nibzard)"
    ],
    "based_on": [
      "Thorsten Ball (Sourcegraph)"
    ],
    "category": "Tool Use & Environment",
    "source": "https://www.sourcegraph.com",
    "tags": [
      "tool-design",
      "logging",
      "machine-readable",
      "observability",
      "agent-environment"
    ],
    "slug": "agent-first-tooling-and-logging",
    "id": "agent-first-tooling-and-logging",
    "summary": "TODO: Add a concise summary for \"Agent-First Tooling and Logging\" describing the pattern's purpose and key benefits.",
    "updated_at": "2026-01-05",
    "excerpt": "\n## Problem"
  },
  {
    "title": "Progressive Disclosure for Large Files",
    "status": "emerging",
    "authors": [
      "Nikola Balic (@nibzard)"
    ],
    "based_on": [
      "Will Larson (lethain.com)"
    ],
    "category": "Context & Memory",
    "source": "https://lethain.com/agents-large-files/",
    "tags": [
      "progressive-disclosure",
      "large-files",
      "context-optimization",
      "file-management",
      "lazy-loading",
      "file-handling",
      "metadata"
    ],
    "slug": "progressive-disclosure-large-files",
    "id": "progressive-disclosure-for-large-files",
    "summary": "TODO: Add a concise summary for \"Progressive Disclosure for Large Files\" describing the pattern's purpose and key benefits.",
    "updated_at": "2026-01-13",
    "excerpt": "\n## Problem"
  },
  {
    "title": "Language Agent Tree Search (LATS)",
    "status": "emerging",
    "authors": [
      "Nikola Balic (@nibzard)"
    ],
    "based_on": [
      "Zhou et al.",
      "University of Illinois"
    ],
    "category": "Orchestration & Control",
    "source": "https://arxiv.org/abs/2310.04406",
    "tags": [
      "search",
      "monte-carlo",
      "tree-search",
      "reasoning",
      "planning",
      "reflection",
      "evaluation"
    ],
    "slug": "language-agent-tree-search-lats",
    "id": "language-agent-tree-search-lats",
    "summary": "TODO: Add a concise summary for \"Language Agent Tree Search (LATS)\" describing the pattern's purpose and key benefits.",
    "updated_at": "2026-01-05",
    "excerpt": "\n## Problem"
  },
  {
    "title": "Agent-Assisted Scaffolding",
    "status": "validated-in-production",
    "authors": [
      "Nikola Balic (@nibzard)"
    ],
    "based_on": [
      "Lukas Möller (Cursor)"
    ],
    "category": "UX & Collaboration",
    "source": "https://www.youtube.com/watch?v=BGgsoIgbT_Y",
    "tags": [
      "code-generation",
      "bootstrapping",
      "scaffolding",
      "feature-development",
      "ide",
      "initial-setup"
    ],
    "slug": "agent-assisted-scaffolding",
    "id": "agent-assisted-scaffolding",
    "summary": "## Problem\nStarting a new feature, module, or codebase often involves writing a significant amount of boilerplate or foundational code. This can be time-consuming and repetitive for developers.",
    "updated_at": "2026-01-05",
    "excerpt": "\n## Problem\nStarting a new feature, module, or codebase often involves writing a significant amount of boilerplate or foundational code. This can be time-consuming and repetitive for developers."
  },
  {
    "title": "Layered Configuration Context",
    "status": "established",
    "authors": [
      "Nikola Balic (@nibzard)"
    ],
    "based_on": [
      "Boris Cherny (via Claude Code)"
    ],
    "category": "Context & Memory",
    "source": "https://www.nibzard.com/claude-code",
    "tags": [
      "context management",
      "configuration",
      "scoped context",
      "automatic loading",
      "CLAUDE.md"
    ],
    "slug": "layered-configuration-context",
    "id": "layered-configuration-context",
    "summary": "TODO: Add a concise summary for \"Layered Configuration Context\" describing the pattern's purpose and key benefits.",
    "updated_at": "2026-01-05",
    "excerpt": "\n## Problem\nAI agents require relevant context to perform effectively. Providing this context manually in every prompt is cumbersome, and a one-size-fits-all global context is often too broad or too n"
  },
  {
    "title": "Virtual Machine Operator Agent",
    "status": "established",
    "authors": [
      "Nikola Balic (@nibzard)"
    ],
    "based_on": [
      "Amjad Masad"
    ],
    "category": "Tool Use & Environment",
    "source": "https://www.nibzard.com/silent-revolution",
    "tags": [
      "computer operation",
      "virtual machine",
      "execution environment",
      "agent capability"
    ],
    "slug": "virtual-machine-operator-agent",
    "id": "virtual-machine-operator-agent",
    "summary": "## Problem\nAI agents need to perform complex tasks beyond simple code generation or text manipulation. They require the ability to interact with a full computer environment to execute code, manage system resources, install software, and operate various applications.",
    "updated_at": "2026-01-05",
    "excerpt": "\n## Problem\nAI agents need to perform complex tasks beyond simple code generation or text manipulation. They require the ability to interact with a full computer environment to execute code, manage sy"
  },
  {
    "title": "Seamless Background-to-Foreground Handoff",
    "status": "emerging",
    "authors": [
      "Nikola Balic (@nibzard)"
    ],
    "based_on": [
      "Aman Sanger (Cursor)"
    ],
    "category": "UX & Collaboration",
    "source": "https://www.youtube.com/watch?v=BGgsoIgbT_Y",
    "tags": [
      "background-agent",
      "human-in-the-loop",
      "task-handoff",
      "interactive-refinement",
      "agent-collaboration",
      "developer-workflow"
    ],
    "slug": "seamless-background-to-foreground-handoff",
    "id": "seamless-background-to-foreground-handoff",
    "summary": "TODO: Add a concise summary for \"Seamless Background-to-Foreground Handoff\" describing the pattern's purpose and key benefits.",
    "updated_at": "2026-01-05",
    "excerpt": "\n## Problem\nWhile background agents can handle long-running, complex tasks autonomously, they might not achieve 100% correctness or perfectly match the user's nuanced intent. If an agent completes 90%"
  },
  {
    "title": "Opponent Processor / Multi-Agent Debate Pattern",
    "status": "emerging",
    "authors": [
      "Nikola Balic (@nibzard)"
    ],
    "based_on": [
      "Dan Shipper (Every)",
      "Reddit Community"
    ],
    "category": "Orchestration & Control",
    "source": "https://every.to/podcast/transcript-how-to-use-claude-code-like-the-people-who-built-it",
    "tags": [
      "multi-agent",
      "debate",
      "adversarial",
      "bias-reduction",
      "uncorrelated-context",
      "validation"
    ],
    "slug": "opponent-processor-multi-agent-debate",
    "id": "opponent-processor-multi-agent-debate-pattern",
    "summary": "TODO: Add a concise summary for \"Opponent Processor / Multi-Agent Debate Pattern\" describing the pattern's purpose and key benefits.",
    "updated_at": "2026-01-05",
    "excerpt": "\n## Problem"
  },
  {
    "title": "Iterative Prompt & Skill Refinement",
    "status": "proposed",
    "authors": [
      "Nikola Balic (@nibzard)"
    ],
    "based_on": [
      "Will Larson (Imprint)"
    ],
    "category": "Feedback Loops",
    "source": "https://lethain.com/agents-iterative-refinement/",
    "tags": [
      "refinement",
      "iteration",
      "prompts",
      "skills",
      "feedback",
      "multi-mechanism",
      "continuous-improvement",
      "dashboards"
    ],
    "slug": "iterative-prompt-skill-refinement",
    "id": "iterative-prompt-skill-refinement",
    "summary": "TODO: Add a concise summary for \"Iterative Prompt & Skill Refinement\" describing the pattern's purpose and key benefits.",
    "updated_at": "2026-01-13",
    "excerpt": "\n## Problem"
  },
  {
    "title": "Dynamic Context Injection",
    "status": "established",
    "authors": [
      "Nikola Balic (@nibzard)"
    ],
    "based_on": [
      "Boris Cherny (via Claude Code)"
    ],
    "category": "Context & Memory",
    "source": "https://www.nibzard.com/claude-code",
    "tags": [
      "context management",
      "dynamic context",
      "lazy loading",
      "slash commands",
      "at-mention",
      "interactive context"
    ],
    "slug": "dynamic-context-injection",
    "id": "dynamic-context-injection",
    "summary": "TODO: Add a concise summary for \"Dynamic Context Injection\" describing the pattern's purpose and key benefits.",
    "updated_at": "2026-01-05",
    "excerpt": "\n## Problem"
  },
  {
    "title": "Tool Capability Compartmentalization",
    "status": "emerging",
    "authors": [
      "Nikola Balic (@nibzard)"
    ],
    "based_on": [
      "Simon Willison (MCP critique)"
    ],
    "category": "Orchestration & Control",
    "source": "https://simonwillison.net/2025/Jun/16/lethal-trifecta/",
    "tags": [
      "capability-segregation",
      "least-privilege",
      "tool-permissions"
    ],
    "slug": "tool-capability-compartmentalization",
    "id": "tool-capability-compartmentalization",
    "summary": "## Problem\nModel Context Protocol (MCP) encourages \"mix-and-match\" tools—often combining private-data readers, web fetchers, and writers in a single callable unit. This amplifies the lethality of prompt-injection chains.",
    "updated_at": "2026-01-05",
    "excerpt": "\n## Problem\nModel Context Protocol (MCP) encourages \"mix-and-match\" tools—often combining private-data readers, web fetchers, and writers in a single callable unit. This amplifies the lethality of pro"
  },
  {
    "title": "Agentic Search Over Vector Embeddings",
    "status": "best-practice",
    "authors": [
      "Nikola Balic (@nibzard)"
    ],
    "based_on": [
      "Cat Wu (Anthropic)",
      "Boris Cherny (Anthropic)"
    ],
    "category": "Tool Use & Environment",
    "source": "https://every.to/podcast/transcript-how-to-use-claude-code-like-the-people-who-built-it",
    "tags": [
      "search",
      "vector-embeddings",
      "bash",
      "grep",
      "RAG",
      "agentic-RAG",
      "maintenance"
    ],
    "slug": "agentic-search-over-vector-embeddings",
    "id": "agentic-search-over-vector-embeddings",
    "summary": "TODO: Add a concise summary for \"Agentic Search Over Vector Embeddings\" describing the pattern's purpose and key benefits.",
    "updated_at": "2026-01-05",
    "excerpt": "\n## Problem"
  },
  {
    "title": "Subagent Compilation Checker",
    "status": "emerging",
    "authors": [
      "Nikola Balic (@nibzard)"
    ],
    "based_on": [
      "Anonymous Speaker (Open Source Agent RL Talk)",
      "Will Brown (Prime Intellect Talk)"
    ],
    "category": "Tool Use & Environment",
    "source": "https://www.youtube.com/watch?v=Xkwok_XXQgw",
    "tags": [
      "subagent",
      "compilation",
      "modularity",
      "error-isolation"
    ],
    "slug": "subagent-compilation-checker",
    "id": "subagent-compilation-checker",
    "summary": "TODO: Add a concise summary for \"Subagent Compilation Checker\" describing the pattern's purpose and key benefits.",
    "updated_at": "2026-01-05",
    "excerpt": "\n## Problem"
  },
  {
    "title": "Rich Feedback Loops > Perfect Prompts",
    "status": "validated-in-production",
    "authors": [
      "Nikola Balic (@nibzard)"
    ],
    "based_on": [
      "Thorsten Ball",
      "Quinn Slack"
    ],
    "category": "Feedback Loops",
    "source": "https://www.nibzard.com/ampcode",
    "tags": [
      "feedback",
      "testing",
      "reliability"
    ],
    "slug": "rich-feedback-loops",
    "id": "rich-feedback-loops-perfect-prompts",
    "summary": "## Problem\nPolishing a single prompt can't cover every edge-case; agents need ground truth to self-correct.",
    "updated_at": "2026-01-05",
    "excerpt": "\n## Problem\nPolishing a single prompt can't cover every edge-case; agents need ground truth to self-correct."
  },
  {
    "title": "AI-Accelerated Learning and Skill Development",
    "status": "validated-in-production",
    "authors": [
      "Nikola Balic (@nibzard)"
    ],
    "based_on": [
      "Lukas Möller (Cursor)",
      "Alex Albert (Anthropic)",
      "Jacob Jackson (Cursor)"
    ],
    "category": "UX & Collaboration",
    "source": "https://www.youtube.com/watch?v=BGgsoIgbT_Y",
    "tags": [
      "developer-productivity",
      "learning",
      "skill-acquisition",
      "iteration",
      "feedback",
      "taste-development",
      "education",
      "junior-developer"
    ],
    "slug": "ai-accelerated-learning-and-skill-development",
    "id": "ai-accelerated-learning-and-skill-development",
    "summary": "## Problem\nDeveloping strong software engineering skills, including \"taste\" for clean and effective code, traditionally requires extensive experience, trial-and-error, and mentorship, which can be a slow process, especially for junior developers.",
    "updated_at": "2026-01-05",
    "excerpt": "\n## Problem\nDeveloping strong software engineering skills, including \"taste\" for clean and effective code, traditionally requires extensive experience, trial-and-error, and mentorship, which can be a "
  },
  {
    "title": "Latent Demand Product Discovery",
    "status": "best-practice",
    "authors": [
      "Nikola Balic (@nibzard)"
    ],
    "based_on": [
      "Boris Cherny (Anthropic)",
      "Meta Product Teams"
    ],
    "category": "UX & Collaboration",
    "source": "https://every.to/podcast/transcript-how-to-use-claude-code-like-the-people-who-built-it",
    "tags": [
      "product-discovery",
      "extensibility",
      "hackable-products",
      "power-users",
      "latent-demand"
    ],
    "slug": "latent-demand-product-discovery",
    "id": "latent-demand-product-discovery",
    "summary": "TODO: Add a concise summary for \"Latent Demand Product Discovery\" describing the pattern's purpose and key benefits.",
    "updated_at": "2026-01-05",
    "excerpt": "\n## Problem"
  },
  {
    "title": "Agent SDK for Programmatic Control",
    "status": "emerging",
    "authors": [
      "Nikola Balic (@nibzard)"
    ],
    "based_on": [
      "Anthropic (Claude Code SDK example)"
    ],
    "category": "Tool Use & Environment",
    "source": "https://www.nibzard.com/claude-code",
    "tags": [
      "sdk",
      "automation",
      "ci/cd",
      "programmatic access",
      "scripting",
      "api",
      "headless agent"
    ],
    "slug": "agent-sdk-for-programmatic-control",
    "id": "agent-sdk-for-programmatic-control",
    "summary": "TODO: Add a concise summary for \"Agent SDK for Programmatic Control\" describing the pattern's purpose and key benefits.",
    "updated_at": "2026-01-05",
    "excerpt": "\n## Problem\nInteractive terminal or chat interfaces are suitable for many agent tasks, but not for all. Integrating agent capabilities into automated workflows (e.g., CI/CD pipelines, scheduled jobs, "
  },
  {
    "title": "Dual LLM Pattern",
    "status": "emerging",
    "authors": [
      "Nikola Balic (@nibzard)"
    ],
    "based_on": [
      "Simon Willison (orig.)",
      "Luca Beurer-Kellner et al. (2025)"
    ],
    "category": "Orchestration & Control",
    "source": "https://arxiv.org/abs/2506.08837",
    "tags": [
      "privilege-separation",
      "quarantined-llm",
      "symbolic-variables"
    ],
    "slug": "dual-llm-pattern",
    "id": "dual-llm-pattern",
    "summary": "A privileged agent that both sees untrusted text **and** wields tools can be coerced into dangerous calls.",
    "updated_at": "2026-01-05",
    "excerpt": "\n## Problem\nA privileged agent that both sees untrusted text **and** wields tools can be coerced into dangerous calls."
  },
  {
    "title": "Plan-Then-Execute Pattern",
    "status": "emerging",
    "authors": [
      "Nikola Balic (@nibzard)"
    ],
    "based_on": [
      "Luca Beurer-Kellner et al. (2025)"
    ],
    "category": "Orchestration & Control",
    "source": "https://arxiv.org/abs/2506.08837",
    "tags": [
      "planning",
      "control-flow-integrity",
      "prompt-injection"
    ],
    "slug": "plan-then-execute-pattern",
    "id": "plan-then-execute-pattern",
    "summary": "## Problem\nIf tool outputs can alter the *choice* of later actions, injected instructions may redirect the agent toward malicious steps.",
    "updated_at": "2026-01-05",
    "excerpt": "\n## Problem\nIf tool outputs can alter the *choice* of later actions, injected instructions may redirect the agent toward malicious steps."
  },
  {
    "title": "Parallel Tool Call Learning",
    "status": "emerging",
    "authors": [
      "Nikola Balic (@nibzard)"
    ],
    "based_on": [
      "Sam Pretty (Cognition)",
      "Will Brown (OpenAI)"
    ],
    "category": "Orchestration & Control",
    "source": "https://youtu.be/1s_7RMG4O4U",
    "tags": [
      "parallelization",
      "latency-optimization",
      "tool-use",
      "reinforcement-learning",
      "performance"
    ],
    "slug": "parallel-tool-call-learning",
    "id": "parallel-tool-call-learning",
    "summary": "TODO: Add a concise summary for \"Parallel Tool Call Learning\" describing the pattern's purpose and key benefits.",
    "updated_at": "2026-01-05",
    "excerpt": "\n## Problem"
  },
  {
    "title": "Dynamic Code Injection (On-Demand File Fetch)",
    "status": "established",
    "authors": [
      "Nikola Balic (@nibzard)"
    ],
    "based_on": [
      "Internal AI Dev Team"
    ],
    "category": "Tool Use & Environment",
    "source": "Internal Practice",
    "tags": [
      "file-injection",
      "at-mention",
      "slash-commands",
      "IDE-integration"
    ],
    "slug": "dynamic-code-injection-on-demand-file-fetch",
    "id": "dynamic-code-injection-on-demand-file-fetch",
    "summary": "TODO: Add a concise summary for \"Dynamic Code Injection (On-Demand File Fetch)\" describing the pattern's purpose and key benefits.",
    "updated_at": "2026-01-05",
    "excerpt": "\n## Problem"
  },
  {
    "title": "Inference-Time Scaling",
    "status": "emerging",
    "authors": [
      "Nikola Balic (@nibzard)"
    ],
    "based_on": [
      "Google DeepMind",
      "OpenAI"
    ],
    "category": "Orchestration & Control",
    "source": "https://deepmind.google/research/",
    "tags": [
      "scaling",
      "inference",
      "compute",
      "reasoning",
      "performance",
      "o1-model",
      "test-time-compute"
    ],
    "slug": "inference-time-scaling",
    "id": "inference-time-scaling",
    "summary": "TODO: Add a concise summary for \"Inference-Time Scaling\" describing the pattern's purpose and key benefits.",
    "updated_at": "2026-01-05",
    "excerpt": "\n## Problem"
  },
  {
    "title": "Verbose Reasoning Transparency",
    "status": "best-practice",
    "authors": [
      "Nikola Balic (@nibzard)"
    ],
    "based_on": [
      "Boris Cherny (via Claude Code)"
    ],
    "category": "UX & Collaboration",
    "source": "https://www.nibzard.com/claude-code",
    "tags": [
      "explainability",
      "debugging",
      "transparency",
      "agent reasoning",
      "verbose mode",
      "introspection"
    ],
    "slug": "verbose-reasoning-transparency",
    "id": "verbose-reasoning-transparency",
    "summary": "TODO: Add a concise summary for \"Verbose Reasoning Transparency\" describing the pattern's purpose and key benefits.",
    "updated_at": "2026-01-05",
    "excerpt": "\n## Problem\nAI agents, especially those using complex models or multiple tools, can sometimes behave like \"black boxes.\" Users may not understand why an agent made a particular decision, chose a speci"
  },
  {
    "title": "Distributed Execution with Cloud Workers",
    "status": "emerging",
    "authors": [
      "Nikola Balic (@nibzard)"
    ],
    "based_on": [
      "Dexter Horthy (HumanLayer)"
    ],
    "category": "Orchestration & Control",
    "source": "https://claude.com/blog/building-companies-with-claude-code",
    "tags": [
      "distributed-systems",
      "parallelization",
      "cloud",
      "worktrees",
      "scalability",
      "team-coordination"
    ],
    "slug": "distributed-execution-cloud-workers",
    "id": "distributed-execution-with-cloud-workers",
    "summary": "TODO: Add a concise summary for \"Distributed Execution with Cloud Workers\" describing the pattern's purpose and key benefits.",
    "updated_at": "2026-01-05",
    "excerpt": "\n## Problem"
  },
  {
    "title": "Background Agent with CI Feedback",
    "status": "validated-in-production",
    "authors": [
      "Nikola Balic (@nibzard)"
    ],
    "based_on": [
      "Quinn Slack"
    ],
    "category": "Feedback Loops",
    "source": "https://ampcode.com/manual#background",
    "tags": [
      "asynchronous",
      "ci",
      "feedback"
    ],
    "slug": "background-agent-ci",
    "id": "background-agent-with-ci-feedback",
    "summary": "## Problem\nLong-running tasks tie up the editor and require developers to babysit the agent.",
    "updated_at": "2026-01-05",
    "excerpt": "\n## Problem\nLong-running tasks tie up the editor and require developers to babysit the agent."
  },
  {
    "title": "Feature List as Immutable Contract",
    "status": "emerging",
    "authors": [
      "Nikola Balic (@nibzard)"
    ],
    "based_on": [
      "Anthropic Engineering Team"
    ],
    "category": "Orchestration & Control",
    "source": "https://www.anthropic.com/engineering/effective-harnesses-for-long-running-agents",
    "tags": [
      "scope-control",
      "acceptance-criteria",
      "anti-scope-creep",
      "long-running-agents",
      "task-management"
    ],
    "slug": "feature-list-as-immutable-contract",
    "id": "feature-list-as-immutable-contract",
    "summary": "TODO: Add a concise summary for \"Feature List as Immutable Contract\" describing the pattern's purpose and key benefits.",
    "updated_at": "2026-01-05",
    "excerpt": "\n## Problem"
  },
  {
    "title": "Abstracted Code Representation for Review",
    "status": "proposed",
    "authors": [
      "Nikola Balic (@nibzard)"
    ],
    "based_on": [
      "Aman Sanger (Cursor, referencing Michael Grinich)"
    ],
    "category": "UX & Collaboration",
    "source": "https://www.youtube.com/watch?v=BGgsoIgbT_Y",
    "tags": [
      "code-review",
      "verification",
      "abstraction",
      "pseudocode",
      "intent-based-review",
      "explainability",
      "software-quality",
      "human-ai-interface"
    ],
    "slug": "abstracted-code-representation-for-review",
    "id": "abstracted-code-representation-for-review",
    "summary": "TODO: Add a concise summary for \"Abstracted Code Representation for Review\" describing the pattern's purpose and key benefits.",
    "updated_at": "2026-01-05",
    "excerpt": "\n## Problem\nReviewing large volumes of AI-generated code line-by-line can be tedious, error-prone, and inefficient. Human reviewers are often more interested in verifying the high-level intent and log"
  },
  {
    "title": "Dual-Use Tool Design",
    "status": "best-practice",
    "authors": [
      "Nikola Balic (@nibzard)"
    ],
    "based_on": [
      "Boris Cherny (Anthropic)",
      "Claude Code Team"
    ],
    "category": "Tool Use & Environment",
    "source": "https://every.to/podcast/transcript-how-to-use-claude-code-like-the-people-who-built-it",
    "tags": [
      "tools",
      "ux",
      "slash-commands",
      "hooks",
      "human-ai-collaboration",
      "consistency"
    ],
    "slug": "dual-use-tool-design",
    "id": "dual-use-tool-design",
    "summary": "TODO: Add a concise summary for \"Dual-Use Tool Design\" describing the pattern's purpose and key benefits.",
    "updated_at": "2026-01-05",
    "excerpt": "\n## Problem"
  },
  {
    "title": "Patch Steering via Prompted Tool Selection",
    "status": "best-practice",
    "authors": [
      "Nikola Balic (@nibzard)"
    ],
    "based_on": [
      "Boris Cherny (Claude Code Concepts)",
      "Will Brown (Prime Intellect Talk)"
    ],
    "category": "Tool Use & Environment",
    "source": "https://www.youtube.com/watch?v=Xkwok_XXQgw",
    "tags": [
      "patching",
      "prompt-steering",
      "tool-selection",
      "coding-agent"
    ],
    "slug": "patch-steering-via-prompted-tool-selection",
    "id": "patch-steering-via-prompted-tool-selection",
    "summary": "TODO: Add a concise summary for \"Patch Steering via Prompted Tool Selection\" describing the pattern's purpose and key benefits.",
    "updated_at": "2026-01-05",
    "excerpt": "\n## Problem"
  },
  {
    "title": "Sub-Agent Spawning",
    "status": "validated-in-production",
    "authors": [
      "Nikola Balic (@nibzard)"
    ],
    "based_on": [
      "Quinn Slack",
      "Thorsten Ball",
      "Will Larson (lethain.com)"
    ],
    "category": "Orchestration & Control",
    "source": "https://www.nibzard.com/ampcode",
    "tags": [
      "orchestration",
      "context",
      "scalability",
      "subagents",
      "yaml-configuration",
      "virtual-files"
    ],
    "slug": "sub-agent-spawning",
    "id": "sub-agent-spawning",
    "summary": "TODO: Add a concise summary for \"Sub-Agent Spawning\" describing the pattern's purpose and key benefits.",
    "updated_at": "2026-01-13",
    "excerpt": "\n## Problem"
  },
  {
    "title": "LLM-Friendly API Design",
    "status": "emerging",
    "authors": [
      "Nikola Balic (@nibzard)"
    ],
    "based_on": [
      "Lukas Möller (Cursor)"
    ],
    "category": "Tool Use & Environment",
    "source": "https://www.youtube.com/watch?v=BGgsoIgbT_Y",
    "tags": [
      "api-design",
      "llm-interaction",
      "tool-use",
      "system-design",
      "code-structure",
      "agent-compatibility"
    ],
    "slug": "llm-friendly-api-design",
    "id": "llm-friendly-api-design",
    "summary": "TODO: Add a concise summary for \"LLM-Friendly API Design\" describing the pattern's purpose and key benefits.",
    "updated_at": "2026-01-05",
    "excerpt": "\n## Problem\nFor AI agents to reliably and effectively use tools, especially APIs or internal libraries, the design of these interfaces matters. APIs designed solely for human consumption might be ambi"
  },
  {
    "title": "Curated File Context Window",
    "status": "best-practice",
    "authors": [
      "Nikola Balic (@nibzard)"
    ],
    "based_on": [
      "Internal AI Dev Team"
    ],
    "category": "Context & Memory",
    "source": "Internal Practice",
    "tags": [
      "code-context",
      "file-scope",
      "relevance",
      "memory-management"
    ],
    "slug": "curated-file-context-window",
    "id": "curated-file-context-window",
    "summary": "TODO: Add a concise summary for \"Curated File Context Window\" describing the pattern's purpose and key benefits.",
    "updated_at": "2026-01-05",
    "excerpt": "\n## Problem"
  },
  {
    "title": "Progressive Tool Discovery",
    "status": "established",
    "authors": [
      "Nikola Balic (@nibzard)"
    ],
    "based_on": [
      "Anthropic Engineering Team"
    ],
    "category": "Tool Use & Environment",
    "source": "https://www.anthropic.com/engineering/code-execution-with-mcp",
    "tags": [
      "mcp",
      "tool-discovery",
      "context-optimization",
      "lazy-loading"
    ],
    "slug": "progressive-tool-discovery",
    "id": "progressive-tool-discovery",
    "summary": "TODO: Add a concise summary for \"Progressive Tool Discovery\" describing the pattern's purpose and key benefits.",
    "updated_at": "2026-01-05",
    "excerpt": "\n## Problem"
  },
  {
    "title": "Three-Stage Perception Architecture",
    "status": "proposed",
    "authors": [
      "Nikola Balic (@nibzard)"
    ],
    "based_on": [
      "AI Architecture Community"
    ],
    "category": "Orchestration & Control",
    "source": "https://www.oreilly.com/library/view/software-architecture-patterns/9781491971437/",
    "tags": [
      "architecture",
      "perception",
      "processing",
      "action",
      "pipeline",
      "modular-design"
    ],
    "slug": "three-stage-perception-architecture",
    "id": "three-stage-perception-architecture",
    "summary": "TODO: Add a concise summary for \"Three-Stage Perception Architecture\" describing the pattern's purpose and key benefits.",
    "updated_at": "2026-01-05",
    "excerpt": "\n## Problem"
  },
  {
    "title": "Extended Coherence Work Sessions",
    "status": "rapidly-improving",
    "authors": [
      "Nikola Balic (@nibzard)"
    ],
    "based_on": [
      "Amjad Masad (observation)"
    ],
    "category": "Reliability & Eval",
    "source": "https://www.nibzard.com/silent-revolution",
    "tags": [
      "coherence",
      "long-running tasks",
      "agent capability",
      "llm",
      "complex projects"
    ],
    "slug": "extended-coherence-work-sessions",
    "id": "extended-coherence-work-sessions",
    "summary": "TODO: Add a concise summary for \"Extended Coherence Work Sessions\" describing the pattern's purpose and key benefits.",
    "updated_at": "2026-01-05",
    "excerpt": "\n## Problem\nEarly AI agents and models often suffered from a short \"coherence window,\" meaning they could only maintain focus and context for a few minutes before their performance degraded significan"
  },
  {
    "title": "Episodic Memory Retrieval & Injection",
    "status": "validated-in-production",
    "authors": [
      "Nikola Balic (@nibzard)"
    ],
    "based_on": [
      "Cursor AI (MCP)",
      "Windsurf Flows"
    ],
    "category": "Context & Memory",
    "source": "https://forum.cursor.com/t/agentic-memory-management-for-cursor/78021",
    "tags": [
      "episodic-memory",
      "vector-db",
      "retrieval-augmented",
      "context-hint"
    ],
    "slug": "episodic-memory-retrieval-injection",
    "id": "episodic-memory-retrieval-injection",
    "summary": "Stateless calls make agents forget prior decisions, causing repetition and shallow reasoning.",
    "updated_at": "2026-01-05",
    "excerpt": "\n## Problem\nStateless calls make agents forget prior decisions, causing repetition and shallow reasoning."
  },
  {
    "title": "Self-Discover: LLM Self-Composed Reasoning Structures",
    "status": "emerging",
    "authors": [
      "Nikola Balic (@nibzard)"
    ],
    "based_on": [
      "Google DeepMind",
      "USC"
    ],
    "category": "Feedback Loops",
    "source": "https://arxiv.org/abs/2402.03620",
    "tags": [
      "reasoning",
      "self-improvement",
      "meta-learning",
      "problem-solving",
      "task-specific",
      "optimization"
    ],
    "slug": "self-discover-reasoning-structures",
    "id": "self-discover-llm-self-composed-reasoning-structures",
    "summary": "TODO: Add a concise summary for \"Self-Discover: LLM Self-Composed Reasoning Structures\" describing the pattern's purpose and key benefits.",
    "updated_at": "2026-01-05",
    "excerpt": "\n## Problem"
  },
  {
    "title": "Discrete Phase Separation",
    "status": "emerging",
    "authors": [
      "Nikola Balic (@nibzard)"
    ],
    "based_on": [
      "Sam Stettner (Ambral)"
    ],
    "category": "Orchestration & Control",
    "source": "https://claude.com/blog/building-companies-with-claude-code",
    "tags": [
      "orchestration",
      "planning",
      "research",
      "context-management",
      "multi-model"
    ],
    "slug": "discrete-phase-separation",
    "id": "discrete-phase-separation",
    "summary": "TODO: Add a concise summary for \"Discrete Phase Separation\" describing the pattern's purpose and key benefits.",
    "updated_at": "2026-01-05",
    "excerpt": "\n## Problem"
  },
  {
    "title": "Explicit Posterior-Sampling Planner",
    "status": "emerging",
    "authors": [
      "Nikola Balic (@nibzard)"
    ],
    "based_on": [
      "Dilip Arumugam",
      "Thomas L. Griffiths"
    ],
    "category": "Orchestration & Control",
    "source": "https://arxiv.org/abs/2504.20997",
    "tags": [
      "RL",
      "PSRL",
      "exploration",
      "planning",
      "decision-making"
    ],
    "slug": "explicit-posterior-sampling-planner",
    "id": "explicit-posterior-sampling-planner",
    "summary": "Agents that rely on ad-hoc heuristics explore poorly, wasting tokens and API calls on dead ends.",
    "updated_at": "2026-01-05",
    "excerpt": "\n## Problem\nAgents that rely on ad-hoc heuristics explore poorly, wasting tokens and API calls on dead ends."
  },
  {
    "title": "Inversion of Control",
    "status": "validated-in-production",
    "authors": [
      "Nikola Balic (@nibzard)"
    ],
    "based_on": [
      "Quinn Slack",
      "Thorsten Ball"
    ],
    "category": "Orchestration & Control",
    "source": "https://www.nibzard.com/ampcode",
    "tags": [
      "orchestration",
      "autonomy",
      "control"
    ],
    "slug": "inversion-of-control",
    "id": "inversion-of-control",
    "summary": "Traditional \"prompt-as-puppeteer\" workflows force humans to spell out every step, limiting scale and creativity.",
    "updated_at": "2026-01-05",
    "excerpt": "\n## Problem\nTraditional \"prompt-as-puppeteer\" workflows force humans to spell out every step, limiting scale and creativity."
  },
  {
    "title": "Versioned Constitution Governance",
    "status": "emerging",
    "authors": [
      "Nikola Balic (@nibzard)"
    ],
    "based_on": [
      "Hiveism (self-alignment loop)",
      "Anthropic (Constitutional AI)"
    ],
    "category": "Reliability & Eval",
    "source": "https://substack.com/home/post/p-161422949?utm_campaign=post&utm_medium=web",
    "tags": [
      "constitution",
      "alignment",
      "governance",
      "signed-commits",
      "policy"
    ],
    "slug": "versioned-constitution-governance",
    "id": "versioned-constitution-governance",
    "summary": "## Problem\nWhen an agent rewrites its own \"constitution,\" it may accidentally violate safety or regress on alignment objectives if changes aren't reviewed.",
    "updated_at": "2026-01-05",
    "excerpt": "\n## Problem\nWhen an agent rewrites its own \"constitution,\" it may accidentally violate safety or regress on alignment objectives if changes aren't reviewed."
  },
  {
    "title": "Agent-Powered Codebase Q&A / Onboarding",
    "status": "validated-in-production",
    "authors": [
      "Nikola Balic (@nibzard)"
    ],
    "based_on": [
      "Lukas Möller (Cursor)",
      "Aman Sanger (Cursor)"
    ],
    "category": "Context & Memory",
    "source": "https://www.youtube.com/watch?v=BGgsoIgbT_Y",
    "tags": [
      "code-understanding",
      "onboarding",
      "q&a",
      "retrieval",
      "search",
      "context-awareness",
      "knowledge-base"
    ],
    "slug": "agent-powered-codebase-qa-onboarding",
    "id": "agent-powered-codebase-qa-onboarding",
    "summary": "## Problem\nUnderstanding a large or unfamiliar codebase can be a significant challenge for developers, especially when onboarding to a new project or trying to debug a complex system. Manually searching and tracing code paths is time-consuming.",
    "updated_at": "2026-01-05",
    "excerpt": "\n## Problem\nUnderstanding a large or unfamiliar codebase can be a significant challenge for developers, especially when onboarding to a new project or trying to debug a complex system. Manually search"
  }
]