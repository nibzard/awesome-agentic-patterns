{
  "title": "Rich Feedback Loops > Perfect Prompts",
  "status": "validated-in-production",
  "authors": [
    "Nikola Balic (@nibzard)"
  ],
  "based_on": [
    "Thorsten Ball",
    "Quinn Slack"
  ],
  "category": "Feedback Loops",
  "source": "https://www.nibzard.com/ampcode",
  "tags": [
    "feedback",
    "testing",
    "reliability"
  ],
  "id": "rich-feedback-loops-perfect-prompts",
  "slug": "rich-feedback-loops",
  "updated_at": "2026-01-05",
  "body": "\n## Problem\nPolishing a single prompt can't cover every edge-case; agents need ground truth to self-correct.\n\n## Solution\nExpose **iterative, machine-readable feedback**—compiler errors, test failures, linter output, screenshots—after every tool call.\nThe agent uses diagnostics to plan the next step, leading to emergent self-debugging.\n\nModern models like Claude Sonnet 4.5 are increasingly proactive in creating their own feedback loops by writing and executing short scripts and tests, even for seemingly simple verification tasks (e.g., using HTML inspection to verify React app behavior).\n\n## Example\n```mermaid\nsequenceDiagram\n  Agent->>CLI: go test ./...\n  CLI-->>Agent: FAIL pkg/auth auth_test.go:42 expected 200 got 500\n  Agent->>File: open auth.go\n  Agent->>File: patch route handler\n  Agent->>CLI: go test ./...\n  CLI-->>Agent: PASS 87/87 tests\n```\n\n## References\n\n* Raising An Agent - Episode 1 & 3 discussions on \"give it errors, not bigger prompts.\"\n* [Cognition AI: Devin & Claude Sonnet 4.5](https://cognition.ai/blog/devin-sonnet-4-5-lessons-and-challenges) - observes proactive testing behavior and custom script creation for feedback loops\n\n[Source](https://www.nibzard.com/ampcode)"
}