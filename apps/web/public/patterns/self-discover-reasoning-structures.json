{
  "title": "Self-Discover: LLM Self-Composed Reasoning Structures",
  "status": "emerging",
  "authors": [
    "Nikola Balic (@nibzard)"
  ],
  "based_on": [
    "Google DeepMind",
    "USC"
  ],
  "category": "Feedback Loops",
  "source": "https://arxiv.org/abs/2402.03620",
  "tags": [
    "reasoning",
    "self-improvement",
    "meta-learning",
    "problem-solving",
    "task-specific",
    "optimization"
  ],
  "id": "self-discover-llm-self-composed-reasoning-structures",
  "slug": "self-discover-reasoning-structures",
  "updated_at": "2026-01-05",
  "body": "\n## Problem\n\nDifferent reasoning tasks require different thinking strategies. While techniques like Chain-of-Thought (CoT) work well for some problems, they may be suboptimal for others. Current approaches typically use fixed reasoning patterns regardless of the specific problem at hand, leading to inefficient problem-solving and suboptimal performance on diverse tasks.\n\n## Solution\n\nSelf-Discover enables LLMs to automatically discover and compose task-specific reasoning structures. The process involves:\n\n1. **Task Analysis**: The LLM analyzes the problem to understand its requirements\n2. **Strategy Selection**: From a set of atomic reasoning modules (like \"break into steps\", \"think critically\", \"use examples\"), the LLM selects relevant ones\n3. **Structure Composition**: The selected modules are composed into a coherent reasoning structure tailored to the specific task\n4. **Execution**: The problem is solved using the self-discovered structure\n\nThis approach allows the model to adapt its reasoning strategy to match the problem's unique characteristics, leading to significant performance improvements.\n\n## Example\n\n```python\nclass SelfDiscoverAgent:\n    def __init__(self, llm):\n        self.llm = llm\n        self.reasoning_modules = [\n            \"Break the problem into smaller steps\",\n            \"Think about similar problems you've seen\",\n            \"Consider edge cases and exceptions\",\n            \"Work backwards from the desired outcome\",\n            \"Use concrete examples to test understanding\",\n            \"Identify key constraints and requirements\",\n            \"Consider multiple perspectives\",\n            \"Check for logical consistency\",\n            \"Simplify the problem first\",\n            \"Look for patterns\"\n        ]\n    \n    def discover_reasoning_structure(self, task):\n        # Step 1: Select relevant reasoning modules\n        selection_prompt = f\"\"\"\n        Task: {task}\n        \n        Available reasoning modules:\n        {self.format_modules(self.reasoning_modules)}\n        \n        Select 3-5 most relevant modules for solving this task.\n        Explain why each selected module is important for this problem.\n        \"\"\"\n        selected_modules = self.llm.generate(selection_prompt)\n        \n        # Step 2: Adapt modules to the task\n        adaptation_prompt = f\"\"\"\n        Task: {task}\n        Selected modules: {selected_modules}\n        \n        Adapt these generic modules into specific reasoning steps \n        tailored to this exact task. Make them concrete and actionable.\n        \"\"\"\n        adapted_modules = self.llm.generate(adaptation_prompt)\n        \n        # Step 3: Compose into reasoning structure\n        composition_prompt = f\"\"\"\n        Task: {task}\n        Adapted reasoning steps: {adapted_modules}\n        \n        Organize these into a coherent reasoning structure.\n        Define the order of operations and how steps connect.\n        Create a step-by-step reasoning plan.\n        \"\"\"\n        reasoning_structure = self.llm.generate(composition_prompt)\n        \n        return reasoning_structure\n    \n    def solve_with_structure(self, task, reasoning_structure):\n        solve_prompt = f\"\"\"\n        Task: {task}\n        \n        Use this reasoning structure to solve the problem:\n        {reasoning_structure}\n        \n        Follow each step carefully and show your work.\n        \"\"\"\n        return self.llm.generate(solve_prompt)\n    \n    def self_discover_solve(self, task):\n        # Discover optimal reasoning structure\n        structure = self.discover_reasoning_structure(task)\n        \n        # Solve using discovered structure\n        solution = self.solve_with_structure(task, structure)\n        \n        return {\n            'reasoning_structure': structure,\n            'solution': solution\n        }\n```\n\n```mermaid\nflowchart TD\n    A[Input Task] --> B[Analyze Task Requirements]\n    B --> C[Select Relevant Reasoning Modules]\n    C --> D[Adapt Modules to Specific Task]\n    D --> E[Compose Reasoning Structure]\n    E --> F[Execute with Structure]\n    F --> G[Solution]\n    \n    H[Module Library] --> C\n    \n    style E fill:#e1f5fe,stroke:#01579b,stroke-width:2px\n    style H fill:#fff3e0,stroke:#e65100,stroke-width:2px\n```\n\n## Benefits\n\n- **Task-Specific Optimization**: Reasoning approach matches problem requirements\n- **Performance Gains**: Up to 32% improvement over Chain-of-Thought on challenging benchmarks\n- **Interpretability**: Clear reasoning structure shows how the problem was approached\n- **Transferability**: Discovered structures can be reused for similar problems\n\n## Trade-offs\n\n**Pros:**\n- Significant performance improvements on diverse reasoning tasks\n- More efficient than trying all reasoning strategies\n- Creates reusable reasoning templates\n- Adapts to novel problem types\n\n**Cons:**\n- Additional overhead for structure discovery phase\n- Requires a diverse set of reasoning modules\n- May over-engineer simple problems\n- Structure quality depends on task analysis accuracy\n\n## References\n\n- [Self-Discover: Large Language Models Self-Compose Reasoning Structures (2024)](https://arxiv.org/abs/2402.03620)\n- [Google DeepMind Research Blog](https://deepmind.google/research/)"
}