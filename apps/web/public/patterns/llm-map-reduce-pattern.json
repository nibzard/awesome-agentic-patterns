{
  "title": "LLM Map-Reduce Pattern",
  "status": "emerging",
  "authors": [
    "Nikola Balic (@nibzard)"
  ],
  "based_on": [
    "Luca Beurer-Kellner et al. (2025)"
  ],
  "category": "Orchestration & Control",
  "source": "https://arxiv.org/abs/2506.08837",
  "tags": [
    "map-reduce",
    "sub-agents",
    "isolation",
    "untrusted-data"
  ],
  "id": "llm-map-reduce-pattern",
  "slug": "llm-map-reduce-pattern",
  "updated_at": "2026-01-05",
  "body": "\n## Problem\nInjecting a single poisoned document can manipulate global reasoning if all data is processed in one context.\n\n## Solution\nAdopt a **map-reduce workflow**:\n\n- **Map:** Spawn lightweight, *sandboxed* LLMs—each ingests one untrusted chunk and emits a constrained output (boolean, JSON schema, etc.).  \n- **Reduce:** Aggregate those safe summaries with either deterministic code or a privileged LLM that sees only sanitized fields.\n\n```pseudo\nresults = []\nfor doc in docs:\n    ok = SandboxLLM(\"Is this an invoice? (yes/no)\", doc)\n    results.append(ok)\nfinal = reduce(results)  # no raw docs enter this step\n```\n\n## How to use it\n\nFile triage, product-review summarizers, resume filters—any N-to-1 decision where each item's influence should stay local.\n\n## Trade-offs\n\n* **Pros:** A malicious item can't taint others; scalable parallelism.\n* **Cons:** Requires strict output validation; extra orchestration overhead.\n\n## References\n\n* Beurer-Kellner et al., §3.1 (3) LLM Map-Reduce."
}